(function(){const pages=[{"idx":0,"href":"/categories/","title":"Categories","content":""},{"idx":1,"href":"/posts/","title":"Posts","content":""},{"idx":2,"href":"/tags/","title":"Tags","content":""},{"idx":3,"href":"/tags/fintech/","title":"fintech","content":""},{"idx":4,"href":"/categories/fintech/","title":"fintech","content":""},{"idx":5,"href":"/tags/meetup/","title":"meetup","content":""},{"idx":6,"href":"/posts/fintech001/","title":"フィンテックエンジニア養成勉強会#2","content":" フィンテックエンジニア養成勉強会#2（共催:Fintech協会）\nキャッシュフリー経済で社会は再編成できるのか？  スマホ決済の次は触れない生体認証 コアアプリに集約される フィンテックでは型付けが絶対必要 サービス間のデータの受け渡しもスキームを固定する  フィンテックスタートアップ起業家としての心構え  ユーザー体験を提供する アメリカではフィンテック＝ブロックチェーンの活用 テクノロジーで新しい市場を生み出さなければ，巨大な事業に成長させられない 2019年現在はブロックチェーンはインフラになっていない テクノロジーファーストだけでは市場に受け入れられない テクノロジーだけがソリューションではない お客様と社会が求めているのを提供する Web系は自由、金融系はお硬い 規則自体を変える手もある  20代30代のキャリアに働きかける  ピボットでずらす軸とずらさない軸は何をしたいかで決める  前の技術と同じ部分と変えた部分   "},{"idx":7,"href":"/posts/think-about-2020-blockchain-industry/","title":"2020年のブロックチェーン業界を考える","content":"2020年のブロックチェーン業界を考える\n ビットコインは地道なスケーリングを行っている スクリプトレススクリプトはスクリプトで行っていることを署名に入れる マルチレイヤーで開発していく ビットコインはとても強固 JPモルガン，Libra，中国政府発行のコインはそれぞれ目的が違う  JPモルガンは為替ネットワーク Libraはバスケット通貨 中国政府は金融政策   "},{"idx":8,"href":"/tags/blockchain/","title":"blockchain","content":""},{"idx":9,"href":"/categories/blockchain/","title":"blockchain","content":""},{"idx":10,"href":"/categories/meetup/","title":"meetup","content":""},{"idx":11,"href":"/tags/HR/","title":"HR","content":""},{"idx":12,"href":"/tags/Lapras/","title":"Lapras","content":""},{"idx":13,"href":"/categories/Lapras/","title":"Lapras","content":""},{"idx":14,"href":"/tags/Meet-up/","title":"Meet up","content":""},{"idx":15,"href":"/categories/Meet-up/","title":"Meet-up","content":""},{"idx":16,"href":"/posts/lapras-meetup001/","title":"【2周年記念】LAPRAS HR Meetup 感謝祭","content":"【2周年記念】LAPRAS HR Meetup 感謝祭\n イベントは根気強く続けるとスケールする  はじめは人来ません  メートアップは最初に飲み食いすると良い  飲み食いして変える人も少なからずいらっしゃいますが  １つのテーマに絞ってその知見をひたすら押すとそれに興味がある強い人が集まる  サイバーテックさんはスカラーをひたすら押したら良い人材が来てくださった  リファラル資源のネットワークを拡げる トレジャーデータのエンジニアはめっちゃ優秀 スカウトメール送る前にGitHub・Twitterでいいねボタンを押す カジュアル面談では，  最初の合意形成が大切 Hard to getがとても重要  下調べをもう一歩先に進める  その時のカジュアル面談のゴールをきちんと決めておく   "},{"idx":17,"href":"/tags/Blockchain/","title":"Blockchain","content":""},{"idx":18,"href":"/categories/Blockchain/","title":"Blockchain","content":""},{"idx":19,"href":"/categories/Meetup/","title":"Meetup","content":""},{"idx":20,"href":"/tags/Oracle/","title":"Oracle","content":""},{"idx":21,"href":"/posts/blockchaingig005/","title":"Oracle Blockchain GIG#5","content":" Blockchain GIG #5\n ハッシュタグは#blockchaingig  Oracleさん ユースケース  食品のトレーサビリティ 貿易系 人事情報・学歴情報 サプライチェーンが多い コバルトのトレーサビリティ 医療情報の共有 サプライヤーの共有 GEのインターカンパニーの売掛・買掛をブロックチェーンで管理しよう  インテグレーション・見える化・ データーの連携レイヤーをブロックチェーンで使った 6週間で作れた   ベスプラ  チャネルとはサブネットワークに分けるもの ChannelとPeerの関係 Transient Data  台帳に含まれないようにChaincodeに引き渡せるデータ  Pravate Data Collection  プライベートデータを持つノードを事前に決めておく必要がある  暗号化  鍵交換問題 Transient Dataを使って共通鍵を引き渡す 暗号化アルゴリズムは稀代化する 誰をどの程度信頼するか  デフォルトではPeerにアクセスできれば台帳が読める Peerも結局のところOS上のプロセスの一つなので、ホストマシンをキチンとセキュアにする   アプリケーションとスマコン  スマコンをチェインコードという 台帳に全てを書こうとしない ワークフローはアプリケーションで行う  １企業内でのワークフローはアプリケーションで行う  スマコンは必ず決定論的にする ワールドステートの現在状態と引数のみに依存するようにする PushではなくてPullでスマコンを行うようにする  パフォーマンス  ネットワーク構成  Channelの構成  プライバシーの構成に応じてChannelを分ける  Peerの構成   World Stateへのアクセス  アクセスするデータの最小化  Read/WriteされるKeyを出来る限り最小にする 大規模クエリや分析などはオンチェーンでの処理には向かない  SQL Rich クエリは使えない  Oracle DB 20c  行をハッシュ値で繋いだTableです   富士通さん ミッション  ブロックチェーンをSEが使いやすい状態に仕立てて提供・運用すること PaaS化して自動運用 短期開発のため、システム/アプリケーションの開発に密に関わる  SEが躓くHyperledger Fabricの壁  複数のPeerにリクエストする必要がある スマコン(チェーンコード)の開発  データとストアとしてStateDB(KVS)を持つアプリケーションのようなもの 基本的には案件ごとに開発する必要がある どこまで考慮するば良いかの線引きが難しい   SEが躓かないための解決策  使用性向上機能を設ける  RESTサーバーを設ける ユースケース別チェーンコードを設ける   トラブル事例１(不自然な画面遷移)  スタンプラリーPoCのアプリ開発における事例\n アプリからトランザクションが複数投げられてた\n原因  クーポン・スタンプに対する認識の違い\n 来店前に用意するもの・来店後に用意するもの\n対策  １度のコールでメソッドを複数実行できるメソッドを追加した(バルク実行)\n 一度にバルク実行するメソッド群に依存会計が無いことが前提  アプリ側で吸収する\n 処理をまとめる発想を捨てて、違和感のない箇所に分散させる 違和感を消すために、同期・非同期で処理させる   テスト工程でエラーが発生する  遅いPeerでエラーが発生する\n ノードの配置はAnti-Affinityポリジーを守ってた Anti-Affinityポリシーとは可用性のためにノードを物理的に分散化させること\n原因  遅いPeerのトランザクションより先に速いPeerのトランザクションが処理さえる\n解決策 遅いPeerのために待ってあげる\n  RFTの時にお客様から  トランザクション・チェーンコード・ステート・ブロックを事前に説明する  開発リードタイム短縮も大事ですが  構想通りのブロックチェーンシステムが出来たか評価する No Block, No Life  LayerXさん DApps開発特有のハマりポイントご紹介  アプリ開発の1つのコンポーネントとして使う  アジェンダ  DAppsのアーキテクチャ全体像 Indexer イベント駆動のトランザクション実行 コントラクトデプロイのフロー UX  DAppsのアーキテクチャ全体像  サーバーが必要  MetaMask  Indexerが必要  コントラクト上にあるデータをDBなどにキャッシュする  二重実行されてないことを確認する indexing済みの次のブロックからログを取得する 取得したイベントのログの数だけループする  Quorum-indexer-DBの流れにする DB-APIにする  Quorum, indexer, API, DB, App  イベント駆動のトランザクション実行(ignitor)  トランザクションのイベント発火を起点として別のトランザクションを実行する トリガー専用のイベントを用意する 失敗専用のイベントを発火する。失敗をrevertとするのではなくて。  ignitorとindexerとの協調  ignitorとindexerを完全に独立させることはできない indexerは1ブロックに含まれるイベントをatomicにDBに保存しているので、  コントラクのデプロイフロー トランザクション実行中の状態をどうするか？  途中のAPIで表示処理する  ディスカッション 現実での紐付け問題はどうするか？ ブロックチェーンがはまるところは  需要と供給が公開される市場  "},{"idx":22,"href":"/tags/drive/","title":"drive","content":""},{"idx":23,"href":"/categories/drive/","title":"drive","content":""},{"idx":24,"href":"/posts/safe-drive/","title":"自動車安全運転5則","content":"  安全速度を必ず守る カーブの手前でスピードを落とす 交差点では必ず安全を確かめる 一時停止で横断歩道の安全を守る 飲酒運転を絶対にしない  自転車安全利用5則  自転車は，車道が原則，歩道は例外． 車道は左側を通行する 歩道は歩行者優先で，車道よりは徐行する． 安全ルールを守る． 子どもはヘルメットを着用する．  "},{"idx":25,"href":"/categories/dojin/","title":"dojin","content":""},{"idx":26,"href":"/tags/shimaya/","title":"shimaya","content":""},{"idx":27,"href":"/categories/techbook/","title":"techbook","content":""},{"idx":28,"href":"/posts/shimaya/","title":"しまや出版さんの工場見学に参加してきました．","content":" はじめに 私は技術書典7に初めて本を出す側として参加させて頂いた同人誌初心者です． そんな中，本の中身を充実させることに集中し過ぎて，本の外側には全く注意を向けることなく終わってしまいました．\nそこで，製本・印刷についても勉強してみようと思い，技術書同人誌博覧会さん主催の，株式会社しまや出版さんの印刷所見学ツアー（午前の部）に参加させて頂きました．\nしまや出版さんとは？  東京都足立区にある同人誌を専門とする出版屋さん． 東京でベスト3に入る歴史を持つ自費出版印刷所(昭和43年印刷業を開始)． 行政から優れた技術力を持つと認められた唯一の同人誌出版社(足立ブランド)．  しまや出版さんの良いところ 技術  オンデマンド印刷の機械が最上級品．  故にオフセット印刷と遜色が無いくらいオンデマンド印刷の本もきれい． 素人が見るとほとんどわからない．  新しい印刷技術に積極的に取り組んでいる．  様々なデザインパターンが可能．  紙・インク・トナー・型抜き・リング・PPなどの種類豊富．  人の手が随所に加わっているので，いろいろとカスタマイズが可能．   人  皆さん職人気質．  無理なカスタマイズも「一度試してみます！」と一度試してからキチンと回答して下さる．  カスタマイズの相談に真摯に対応して下さる．  受付のお姉さんとても親切．  従業員の方々を大切にしているホワイト企業．  従業員の方々きちんと挨拶して下さる．   環境保護  環境に優しい印刷・製本を行っている．  環境保護印刷マークのゴールドを取得． 環境負荷の大きいインク洗浄剤を使わないようにしている(その分人が頑張っている)．   その他  こういった見学会を一般で受けて下さるほど技術力に自信があるし，書き手を大切にしている． 社員猫さんかわいい．   しまや出版さんの欠点  締切が早い．  日曜日に即売会があるなら火曜日が締切日． ホワイトな仕事環境とのトレードオフ．   おわりに しまや出版さんの工場見学に参加できて本当に勉強になりました． 想像の30倍位製本・印刷にこだわることが出来てびっくりしました． 次は，箔押し・マットPP・表紙・帯・表紙のデザインに凝ってみようと思います． 技術書同人誌博覧会さん・株式会社しまや出版さん，今回はこのような貴重な機会を設けて下さり，本当にありがとうございました．\n"},{"idx":29,"href":"/tags/sleep/","title":"sleep","content":""},{"idx":30,"href":"/categories/sleep/","title":"sleep","content":""},{"idx":31,"href":"/posts/sleep/","title":"睡眠の機能","content":" あらゆる抽象度におけるホメオスタシス(恒常性維持機能)で必要な機能 脳機能システム  シナプスの可塑性(発達, 修理, 記憶の形成)を維持するために睡眠が必要  細胞免疫システム  睡眠が免疫機能維持に重要 寝不足は風邪をひいたり, 感染症になりやすい.  メタボリックシステム  寝不足はインシュリン作用が下がり, 高血圧になりやすい.   "},{"idx":32,"href":"/tags/5G/","title":"5G","content":""},{"idx":33,"href":"/categories/5G/","title":"5G","content":""},{"idx":34,"href":"/posts/5g-overview/","title":"5Gの概要","content":" 5Gとは次世代の通信規格ではなく基盤技術  高速通信  4GLTEの10〜100倍 2時間の4Kハイビジョン動画を3秒でダウンロード  低遅延  1/1000秒以下の低遅延 自動運転にリアルタイム対応  多数間通信  1km^2あたり100万台以上同時接続 1部屋で約100台以上接続可能でIoT対応  クラウド対応  5Gコアシステムがクラウドに最初から対応  並列人工知能前提  4Gまでのハードインフラと違いソフトウェアベースで人工知能対応 高速通信・低遅延・多数間通信などの処理を人工知能が行う  障害に対する高耐性  障害やサイバー攻撃に対応する高いレジリエンス   "},{"idx":35,"href":"/tags/overview/","title":"overview","content":""},{"idx":36,"href":"/categories/overview/","title":"overview","content":""},{"idx":37,"href":"/tags/techbook/","title":"techbook","content":""},{"idx":38,"href":"/posts/techbook-meetup/","title":"技術書典ミートアップ","content":" 用語説明  同人誌・・・自家製の本のこと  同人誌とは、同じ思考を持った人たちで作る本の一種である. 個人や仲間と一緒に作り上げる本のこと. えっちなのではないよ.  即売会・・・同人誌を頒布したりすること 頒布・・・ 同人誌を売って布教すること サークル・・・本を頒布する側  利益を上げるのが第一目的ではない. 普及するのが目的.  お客さん・・・本を購入する側  なぜ作るのか？  楽しいから  知らないことを気軽に知ることができて楽しい.  同好の士を増やすぞ！ 体験を共有したい！（成功・失敗を問わず, 俺屍）  どうやって作るのか？  印刷所に頼む  日光企画さんかねこのしっぽさん  コピー機で頑張って作る  sevenelevenさんのコピー機で一応作れる  電子書籍  QRコードで頒布する  紙の本がとても人気があります.  紙の本が売り切れたら電子書籍を売るパターンが多いそうです.   使うツールは？  Re:VIEWがオススメ. GitHubで差分を見やすく, mergeしやすい形式がオススメです. markdownよりもRe:VIEWを使うのが便利. md2review（markdown \u0026gt; Re:VIEW）  本が間に合わなかったら？  本がなくてブースに座るのは辛い思いをします. 6割でも出しましょう. 無断欠席は次回以降出禁になります.  必要な経費  一般(参加費7,000円)とパトロン(参加費20,000円)の抽選確率の違いはない.  パトロンは名誉職.  日光企画さんと猫の尻尾さんが公式の印刷会社さん  当日は印刷物がブースに届きます.   税金の処理  経済活動したら税金を払いましょう. 雑所得となります.  年間20万円以上の場合は申告義務があります.   本を作る技術  イベント申し込み, 印刷手配, 広報活動, 小銭 あの布屋で備品を購入する.  テーブルの上にかける布です.   アドバイス  無理に誰かと組む必要はない. 1人で店番は無理.  他の人のブースも見たい. トイレ, 昼食もしたい.  誰かにレビューを依頼するのは良い考え.  自分1人で書くと分かりづらい. 対象読者を見つけて読んでもらうの良い. 自分よりわかっている人に読んでもらうのも良い. 専門用語を使うかは考えどころ. 文化圏の違う人にも読んでもらう.  早めに書いて, 早めに入稿. 紙も電子も用意する.  技術書典6の参加の方から  紙の本の方が確かに売れる  8 : 2 で紙が購入される  タイトルは一発で分かりやすくする 初めての頒布は100部が確かに妥当 「広く浅い知識」より「狭く深い書籍」がニーズある 「収入を得るため」ではなく「知識共有と出会いを楽しむ」 サークルカットはキチンと書く  購入者にリーチするため   ほんとに平均100部売れるのか？  20万冊が持ち込まれて, 14万冊が持って帰ってられる. 技術書は安いので, 1,000円が安く感じる. お祭り気分で財布の紐が緩くなっている感じです. 1人平均14冊くらい購入されてる. 有名どころは2,000冊くらい売れる. 会社のイメージとマッチした技術書だと売れる.  会場に電源はありません. 抽選の方法は非公開ですが, 偏りはありません.  贔屓もありません.  描きたい気持ちを大切にしています.  書類に不備がある場合は落ちます.  表紙のイラストよりも, タイトルの分かり易さが大切. 1,000円はノールック購入されます.  2周目回ってきたときにその本があるとは限らないから. 1,000円は出しやすい.  改訂版をwebに無料で公開しても販売部数はあまり減らない. "},{"idx":39,"href":"/tags/docs/","title":"docs","content":""},{"idx":40,"href":"/categories/docs/","title":"docs","content":""},{"idx":41,"href":"/tags/documentation/","title":"documentation","content":""},{"idx":42,"href":"/categories/documentation/","title":"documentation","content":""},{"idx":43,"href":"/posts/documentation/","title":"ドキュメント作成ツール","content":" https://readthedocs.org https://www.sphinx-doc.org/en/master/ https://www.mkdocs.org  https://github.com/squidfunk/mkdocs-material  https://www.gitbook.com  "},{"idx":44,"href":"/tags/Hands-on/","title":"Hands-on","content":""},{"idx":45,"href":"/categories/Hands-on/","title":"Hands-on","content":""},{"idx":46,"href":"/tags/Tezos/","title":"Tezos","content":""},{"idx":47,"href":"/posts/tezos-hands-on/","title":"Tezosハンズオン","content":" Tezosとは  第3世代のブロックチェーン 2018-09: Mainnet開始 ペーパーで約束されたものをほぼ実装した. 財団がRandDにお金を出してる. PoS  Tezosの特徴  プロトコルはステークホルダーの物というのが第一の信条.  LPos: Liqid Proof of Stake オンチェーン・ガバナンス: 自己修正投票  安全第一  形式検証を用いている   DPoS Proof-of-Stake  トークン所有量に応じたブロック生成権が与えらえる.  ASICが必要ない 手数料が高騰しない 環境に良い  トークンを所有していないマイナーからプロトコルをステークホルダーに解放する.  Delegated PoS (委任PoS)  ステーク投票により選ばれた少数のノードにブロック生成権を与える. 権利を投票に使う. EOSが代表格 利点  PC持ってないステークホルダーも間接的にブロック生成に参加できる. ノード数を減らすことで合意形成効率を上げられる.  欠点  過度にノード数を減らすと分散性・安全性を損なう.   Liquid PoS (Tezos)  選ばれた少数のノードではなく, 誰でもベーキング(ブロック生成)できる. マーケティングにより, マイニングとは言わずにベーキングと言う. ベーカリー(ベーキングの委任を受ける業者のこと), ベーキング権(マイニングする権利), ベーキング(マイニングのこと)という. マイニングを少数ノードに牛耳られることなくステークホルダーに還元するためにLPoSを採用している. 現在450〜500くらいのノードがある. スピードは狙ってない. 現在は30〜40TPSくらい.  Liquid Democracy (PoSとDPoSの間の概念)  直接民主制(PoS)から代表民主制(DPos)へ. Liquid Democracy(LPoS)は直接民主制と代表民主制の中間の概念. Liquid Democracy(LPoS)は議題ごとに代議員を選ぶことができる. TezosはLiquid Democracy(LPoS)を採用している.  オンチェーンガバナンス ガバナンスとは  どうやって改良(フォーク)していくかの手続きのこと.  ソフトフォーク(後方互換) ハードフォーク(後方非互換)   ハードフォークのリスク  プロトコルのハードフォークはコミュニティのハードフォークも生む危険性がある.  DAOによるEthereumとEthereum Classicの分裂 Bitcoin Cashのハードフォークとハッシュ戦争  ガバナンスの目標  どうコミュニティの分裂を避け, プロトコルをスムーズに進化させていくか.   オンチェーン・ガバナンス  プロトコルをスムーズに進化せていくための手法. フォーク手続きがプロトコルに実装され, 過程が全てチェーン上に記録される.  プロトコル更新の提案 更新のテスト 採用投票 採用後の自動移行  プロトコルの所有権を開発者やカリスマからステークホルダーの物とした.  けれども投票で独裁化することできる. プロトコル自体も投票で決めることができるので.  危ないっちゃ危ない.  変更できる部分のプロトコルの分離  シェル(ハード寄りの部分)  オンチェーン・ガバナンスの対象外 ネットワーク通信, ストレージ等の実装  プロトコル(脳みその部分)  オンチェーン・ガバナンスの対象 トランザクションの意味やコンセンサスを定義   Tezosのオンチェーンガバナンス  プロトコル変更をコードとして提案, P2Pで配布する.  第1回投票: 提案の1つを選択 第2回投票: テストするか投票 テストが本番と並行して動かされる 第3回投票:   初めての修正  Gas Limitの変更 ステーキング参加条件の緩和(10000 -\u0026gt; 8000) 名称はAthenes(アテネ)  初めての修正後の課題  ノードの自動更新は成功したが, サードパーティのウォレットなどの一部が更新を知らなかった. 最短で3カ月ごとに更新される.  これは割と忙しい.   Tezosと安全性, 形式検証 形式検証  安全性を数理的に完全に証明する.  検証に適した関数型言語OCamlを採用 型システム, モデル検査, 定理証明を採用 以上をすべての分野に採用する ノード実装, スマートコントラクト   Tezosのスマートコントラクト  安全性を優先したデザイン VM: Michelson  静的型付け, 純粋関数型のスタックVM 人間でも一応読み書きできる  高級言語もある  Ligo, fi   ユースケース  Elevated Returns: 不動産のトークン化の基盤  不動産の証券化を行う.  Tezsure: ブロックチェーンを用いた簡易保険 Chorus Mobility: 自動運転車間の交通優先権取引 Viaz: P2P funding platform Decet: 農作物先物取引市場 etc\u0026hellip;  これから  エコシステム  ディスク使用量の改善 改良, 検証された高レベル言語, 形式検証ツール  プロトコル改訂  BFTコンセンサスの導入, PVSSによる乱数生成 zk-SNARKSの採用  セカンドレイヤー Marigold(:=plasma)  ブロックチェーンとは  台帳方式 分散環境 開かれたネットワーク  Paxosは閉じたネットワークでは合意形成ができる. 開かれたネットワークではSybil攻撃(成り済まし攻撃)があるのが問題. それを解決したのがSatoshi Nakamoto. ネットワークとは無関係の資源占有による制限を取り入れた. (PoW, PoS etc)  トークン  分散データベースを作りたかったけど, Sybil攻撃を防ぐために資源占有を促すためのインセンティブとして仮想通貨(トークン)が生まれた.  スマートコントラクト  安全性が超大事.   形式検証  数理的にプログラムが好ましい性質を持っていることを証明する. 静的型付け モデル検査 定理証明 産業的には, クリティカルシステムに使われてきた.  航空宇宙産業 原子力発電   Tezosの流れ  やりたいことをアカウント操作にする. 操作をP2Pネットワークに放流する. ベイカーが操作を取り込んでブロックを作る.  docker pull furuse/tezos-hands-on:2019-06-15 docker run furuse/tezos-hands-on:2019-06-15 curl -I https://tezos.com git clone https://gitlab.com/dailambda/docker-tezos-hands-on cd docker-tezos-hands-on git checkout master git pull ./tezos-client get balance for alice ./tezos-client add address jun tz1ZD7QcE3yWfj6v8pwfbKTgdb3HU1q8EMM4 ./tezos-client get balance for jun ./tezos-client list known addresses ./tezos-client transfer 111 from alice to jun ./tezos-client list known contracts Tezosのツール  http://node1.nyc.tezos.org.sg:8001 https://fi-code.com  "},{"idx":48,"href":"/tags/BiiLabs/","title":"BiiLabs","content":""},{"idx":49,"href":"/posts/biilabs-meetup/","title":"BiiLabs Meet up","content":" BiiLabsのミートアップ  IOTAに関する目新しいことは特になし. BiiLabsさんのミートアップだった.  IoTにDLTを応用してこんなこと出来ます. 便利なAPIを公開しております.   "},{"idx":50,"href":"/categories/application/","title":"application","content":""},{"idx":51,"href":"/tags/Angular/","title":"Angular","content":""},{"idx":52,"href":"/categories/Angular/","title":"Angular","content":""},{"idx":53,"href":"/tags/Docker/","title":"Docker","content":""},{"idx":54,"href":"/categories/Docker/","title":"Docker","content":""},{"idx":55,"href":"/posts/angular-docker/","title":"DockerでAngularを動かす","content":"以下を参照のこと.\nsolareenlo/angular-cli\n"},{"idx":56,"href":"/tags/app/","title":"app","content":""},{"idx":57,"href":"/tags/engineer/","title":"engineer","content":""},{"idx":58,"href":"/posts/app/","title":"とっても使えるアプリたち","content":" 本を作成  Re:VIEW pandoc  質疑応答  sli.do  作図  draw.io  マークダウン表示  typora  wikiの新しい形  Scrapbox  ノートアプリ  Notion  サーバーレスアプリのホスティングサービス  Now  JSONの書きミスチェッカー  JOSNLint  全文検索  Elasticsearch  モニタリング  KIBANA Grafana Prometheus  "},{"idx":59,"href":"/tags/Docker-Hub/","title":"Docker Hub","content":""},{"idx":60,"href":"/categories/Docker-Hub/","title":"Docker Hub","content":""},{"idx":61,"href":"/tags/pass/","title":"pass","content":""},{"idx":62,"href":"/posts/docker-pass/","title":"ローカル環境のDocker Hubのパスワードをpassで管理する方法","content":" Ubuntu用\n なぜDocker Hubのパスワードをpassを使って管理するか? ローカルからDocker Hubにログインすると, その時のパスワードを平文のまま保存されるから.    ここからdocker-credential-passの最新バージョンをダウンロードする. tar -zxvf docker-credential-pass.tar.gz (解凍する.) mv docker-credential-pass /usr/local/bin (PATHが通ってるところにファイルを移動する.) sudo apt-get install gpg pass (gpgとpassをインストール.) gpg --generate-keyで新しい秘密鍵と公開鍵の組を作る. gpg --list-keysで出てきた, pubの16進数の40文字(大文字のA-F, 0-9の文字列)をコピーする. pass init AAAAAAAAAABBBBBBBBBBCCCCCCCCCCDDDDDDDDDでpassを初期化する. pass insert docker-credential-helpers/docker-pass-initialized-checkでとりあえずのディレクトリを作成する. docker-credential-pass listで{}と返ってくる. ~/.docker/config.jsonに{\u0026quot;credsStore\u0026quot;: \u0026quot;pass\u0026quot;}と書き込む. docker loginでDockerにログインする.   うまくいかないときは権限をchmodを使って変更してみる.\n curl -O https://github.com/docker/docker-credential-helpers/releases/download/v0.6.0/docker-credential-pass-v0.6.0-amd64.tar.gz tar -xvf docker-credential-pass.tar.gz mv docker-credential-pass /usr/local/bin apt-get install gpg pass gpg --generate-key gpg --list-keys \u0026gt; pub rsa2048 2019-04-22 [SC] [有効期限: 2021-04-21] \u0026gt; D7D35B60A7FA571541959AF3C4821C32793D5F5A // ここの公開鍵をコピーする \u0026gt; uid [ 究極 ] solareenlo \u0026lt;test@example.com\u0026gt; \u0026gt; sub rsa2048 2019-04-22 [E] [有効期限: 2021-04-21] pass init D7D35B60A7FA571541959AF3C4821C32793D5F5A // 上記でコピーした公開鍵をペーストする pass insert docker-credential-helpers/docker-pass-initialized-check // ここで入力するパスワードは初期化されるので何でも良い. pass show docker-credential-helpers/docker-pass-initialized-check // 先ほど入力したパスワードが表示される docker-credential-pass list vim ~/.docker/config.json // { // \u0026#34;credsStore\u0026#34;: \u0026#34;pass\u0026#34; // } /* と~/.docker/config.jsonに書き込む. */ docker login  References:  Cannot login to Docker account Document how to initialize docker-credentials-pass #102 Credentials store   "},{"idx":63,"href":"/tags/Bitcoin/","title":"Bitcoin","content":""},{"idx":64,"href":"/categories/Bitcoin/","title":"Bitcoin","content":""},{"idx":65,"href":"/categories/Programming/","title":"Programming","content":""},{"idx":66,"href":"/posts/programming-bitcoin/","title":"Programming BitcoinをHTMLで読んでみる","content":" 前提条件  RubyがPCにインストールされている. RubyのパッケージマネージャーのgemがPCにインストールされている.  HTML作成 git clone git@github.com:jimmysong/programmingbitcoin.git cd programmingbitcoin gem install asciidoctor find . -name \\*.asciidoc -print0 | xargs -0 -n1 asciidoctor これで.asciidocが.htmlに変換されて出力されるので, 任意のブラウザで開いて読む.\nReferences  「Programming Bitcoin」を読んだ jimmysong/programmingbitcoin 脱Word、脱Markdown、asciidocでドキュメント作成する際のアレコレ  "},{"idx":67,"href":"/tags/Python/","title":"Python","content":""},{"idx":68,"href":"/tags/Ruby/","title":"Ruby","content":""},{"idx":69,"href":"/tags/bitbank/","title":"bitbank","content":""},{"idx":70,"href":"/posts/bitbank01/","title":"bitbank Drink Meetup #1 〜エンジニア〜","content":"  bitbank Drink Meetup #1 〜エンジニア〜の自分なりのメモ\n 秘密鍵の安全な生成法 用意するもの\n 電磁波を通さない物質で囲まれたシェルター 電波が通じてない山奥 完全にランダムで賽の目が出るサイコロ 上記のセットを複数個  とってもセキュアに暗号資産を管理してくれるところ  xapo  "},{"idx":71,"href":"/tags/Plasma/","title":"Plasma","content":""},{"idx":72,"href":"/categories/Plasma/","title":"Plasma","content":""},{"idx":73,"href":"/posts/plasma-substrate01/","title":"Plasma × Substrate 勉強会 #1","content":"  Plasma × Substrate 勉強会 #1の自分なりのメモ\n Introducing Plasma Chamber プラズマとは  セキュアにトランザクションをさばく. マークル木を使ってデータを圧縮する. 1分ごとに行う. エンドユーザーが出金したいときはルートチェーンに問い合わせる. 他の人にチャレンジされなければ許可されて出金される仕組み. スケーラブル・セキュリティ・ユーザビリの高いDappasが作れるぞ.  プラズマの悪い点  受取手はトランザクションの履歴を確認しないといけない. ファイナリティは待たないといけない. Exit期間があるのでUIが悪い  Plasma Chamberは上記の3つの悪い点を改善するぞ What I mean by \u0026lsquo;usable\u0026rsquo; High TPS, Less Gas, Work on Mobile, Instant Finality, ERC20使える\n特徴  Exit Game Operatorが資金をかっさらう事がある. それに対する対策を行った. Gas Const/Proof Size Reduction Instantaneous Finality Fast Finality Contract に供託しておく. ユーザー, マーチャント, オペレーター, Ethereum オペレーターまではhttpsで通信する. オペレーターまでなら2秒以下でファイナリティが得られる. Ethereumのブロックチェーンまで待つと2.5分から7分かかる. Plasma MVP → Plasma Cash → Plasma Cashflow → ??? Plapp 出金したい人と入金したい人を合わせるPlapp.  Plasma Substrate Runtime Module Library PlasmaをSubstrateの上で行おう!\n 発表資料: Plasm: Plasma Substrate Runtime Module Library\n発表資料: Staked Substrate\nSubstrateとはブロックチェーン開発のフレームワークのこと.\nReference: Polkadotとブロックチェーン開発フレームワークSubstrateを俯瞰する\n Plasmaには種類が沢山ある. Substrate Chainの上に全てのPlasmaを作れるようにしよう.\n親で且つ子でもあるPlasma Chainを作ろう. そうする事で無限のスケーラビリティがある.\nPlasma Dreams 大きく3つのライブラリがある - plasma-utxo - plasma-parent - plasma-child\nUTXOを使って, 自分の残高がけを保存する. トランザクションは自分で定義できる. マークル木に対応したものと対応していないもの両方に対応したい.\n"},{"idx":74,"href":"/tags/Rust/","title":"Rust","content":""},{"idx":75,"href":"/tags/Substrate/","title":"Substrate","content":""},{"idx":76,"href":"/categories/Substrate/","title":"Substrate","content":""},{"idx":77,"href":"/posts/bitcoind/","title":"bitcoindへのアクセス方法","content":" bitcoindへのアクセス方法3選(bitcoin-cli, curl, POST). 3つともJSON-RPCで通信してる.\n bitcoindとは, 名前の通りunixのデーモンとして動作する事を目的とするBitcoinのクライアントで, JSON-RPCで開発者向けのAPIを提供する. したがって, Webサービスとして動作するBitcoinウォレットのバックエンドとしてや, マイニングプールのサーバーとして使われる.\nReference: Bitcoinウォレットの比較\n 1. bitcoin-cliを使ってアクセスする.  bitcoin-cliとは, bitcoindへJSON-RPCを使ってアクセスするツールのこと.\n bitcoindを使ってBitcoinのフルノードを立ち上げて,\nbitcoin-cli getblockchaininfo  とか.\n2. cURLを使ってアクセスする. 下記curlを行う要件.\n ネットワーク: mainnet 接続環境: ローカル ポート番号: 8332 ユーザーの名前: user-name パスワード: user-password 投げつけているbitcoin-cliのメソッド: getblockchaininfo  curl --data-binary '{\u0026quot;jsonrpc\u0026quot;:\u0026quot;1.0\u0026quot;,\u0026quot;id\u0026quot;:\u0026quot;curltext\u0026quot;,\u0026quot;method\u0026quot;:\u0026quot;getblockchaininfo\u0026quot;,\u0026quot;params\u0026quot;:[]}' -H 'content-type:text/plain;' http://user-name:user-password@127.0.0.1:8332/ | jq  3. 自作プログラムでPOSTしてアクセスする. bitcoindはHTTPリクエストメソッドのPOSTに対応しているので, JSON-RPCをPOSTで投げつける. 以下のプログラムはNode.jsを使った例.\n https://github.com/solareenlo/bc-json-rpc  "},{"idx":78,"href":"/posts/how-to-make-this-site/","title":"このサイトの作り方","content":"  Macユーザー用\n ものすごい初歩からこのサイトの作り方を説明しています. この手順で作成するとGitHubに全ての内容/更新履歴/更新内容が公開されますので, 適宜読み替えてください.\nMacにgitをインストールする https://git-scm.com/download/mac\nGitHubにアカウントを作成する https://github.com\nMacにHomebrewをインストールする /usr/bin/ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34;  References:  https://brew.sh/index_ja.html https://github.com/Homebrew/brew   MacにHugo(静的サイトジェネレーター)をインストールする brew install hugo  Reference: Install Hugo  HugoのExtendedバージョンをインストールする 以下内容をhugo_latest.sh名で保存する.\n# hugo_latest.sh # Find the latest Hugo from GitHub echo \u0026#39;🐹 Starting Hugo Install / Update 🐹\u0026#39; echo \u0026#39; Note: Please be sure to have curl and grep installed\u0026#39; echo \u0026#39;\u0026#39; url=$(curl -s \u0026#34;https://api.github.com/repositories/11180687/releases/latest\u0026#34; | grep -o \u0026#39;https://.*hugo_extended.*_macOS-64bit.tar.gz\u0026#39;) echo \u0026#39;✅ Found latest version\u0026#39; curl -s $url -L -o hugo_latest.tar.gz echo \u0026#39;✅ Download complete: \u0026#39; $url tar -zxf hugo_latest.tar.gz -C /usr/local/bin rm /usr/local/bin/README.md rm /usr/local/bin/LICENSE echo \u0026#39;✅ Extracted to /usr/local/bin\u0026#39; rm hugo_latest.tar.gz echo \u0026#39;✅ Removed downloaded artifacts\u0026#39; echo \u0026#39;\u0026#39; echo \u0026#39;👉 Current Version\u0026#39; $(hugo version) echo \u0026#39;\u0026#39; echo \u0026#39;🎉🎉🎉 Happy Hugo-ing! 🎉🎉🎉\u0026#39; そして, コンソールで以下を実行する.\nbash hugo_latest.sh  Reference: Install Hugo (Extended) Latest With Shell Script For macOS  Hugoのテンプレートテーマであるbookをインストールする cd hugo new site my-site cd my-site git init git submodule add https://github.com/alex-shpak/hugo-book themes/book 試しにサイトをローカルで動かしてみる. hugo server --theme book  References:  https://themes.gohugo.io/hugo-book/ https://github.com/alex-shpak/hugo-book   GitHubにファイルを上げてみる 記事を更新する References 色の参考文献\n aubm/hugo-code-editor-theme altercation/vim-colors-solarized  形状の参考文献\n alex-shpak/hugo-book  "},{"idx":79,"href":"/categories/Development/","title":"Development","content":""},{"idx":80,"href":"/posts/hello-world/","title":"Hello World!","content":"Hello World!\n"},{"idx":81,"href":"/tags/development/","title":"development","content":""},{"idx":82,"href":"/tags/go/","title":"go","content":""},{"idx":83,"href":"/tags/golang/","title":"golang","content":""},{"idx":84,"href":"/categories/golang/","title":"golang","content":""},{"idx":85,"href":"/tags/templates/","title":"templates","content":""},{"idx":86,"href":"/tags/themes/","title":"themes","content":""},{"idx":87,"href":"/docs/alpine-linux/","title":"Alpine Linux","content":" Alpine Linuxとは  muslとBusyBoxをベースとしたLinuxディストリビューションの1つ. セキュリティ・シンプル・リソース効率を重視するパワーユーザー向けに設計されている. とても軽量でセキュアなのでDockerのイメージ作りに使われる. 公式サイト: https://alpinelinux.org  簡単な使い方 # gitをインストール apk add git"},{"idx":88,"href":"/docs/angular/","title":"Angular","content":" Angularとは  Typescript/JavaScriptやその他の言語を使用してモバイルおよびデスクトップWebアプリケーションを構築するための開発プラットフォーム. GitHubリポジトリ: https://github.com/angular/angular References:  https://angular.io/docs https://angular.jp/docs https://angular.keicode.com   用語    用語 意味     module アプリを構成するコンポーネントを束ねたもの.   root module アプリが起動する時に呼びされる大元のモジュール.\nAngularアプリには必ずある.   component View(画面の一部)を制御する.   template componentのUIをどのようにHTMLで表現するかを指定するもの.\n.htmlのこと.   Decorators モジュールやクラスなどの要素に対してメタ情報を付与するもの   constructor TS, JSに付随するものでClassの初期化時に発動する   data binding コンポーネントにおいてテンプレートとクラス内の要素を繋ぐ仕組み.\nテンプレートとコンポーネントのコードを繋ぐ方法   template reference variable #testを使って, そのDOM要素をtest変数で参照できるようにする仕組み.    Decoratorsのパラメーター    パラメーター名 意味     imports 現在のモジュールで利用する他のモジュール／コンポーネント   exports 現在のモジュールで外部に公開するコンポーネントなど   declarations モジュール配下のコンポーネント   bootstrap 最初に起動すべき最上位のコンポーネント(＝ルートコンポーネント)   templateUrl 描画するhtml   template 描画する内容   styleUrls どのcssを使うか   styles 直接cssの内容を記述する   selector コンポーネントの適応先を表す(html, css, classなどとして指定できる)    インストール npm i -g @angular/cli @angular/core バージョンアップ ng update @angular/cli @angular/core DockerでAngular Dockerfileの中身\nFROMnode:10.16.0-alpine RUN apk update \\  \u0026amp;\u0026amp; npm install -g @angular/cli@8.0.6 \\  \u0026amp;\u0026amp; rm -rf /tmp/* /var/cache/apk/* *.tar.gz ~/.npm \\  \u0026amp;\u0026amp; npm cache clear --force \\  \u0026amp;\u0026amp; yarn cache clean \\  \u0026amp;\u0026amp; sed -i -e \u0026#34;s/bin\\/ash/bin\\/sh/\u0026#34; /etc/passwd WORKDIR/app docker-compose.ymlの中身\nversion: \u0026#34;3\u0026#34; services: angular: image: solareenlo/angular-cli build: . command: ash -c \u0026#34;ng serve --host=0.0.0.0\u0026#34; volumes: - .:/app ports: - \u0026#34;4200:4200\u0026#34; として, Dockerfileだけでコンテナを動かすときは,\n# first-appを作成 docker run -it --rm -w /app -v $(pwd):/app solareenlo/angular-cli ng new first-app # first-appディレクトリに移動 cd first-app # コンテナに入って作業する docker run -it --rm -w /app -v $(pwd):/app solareenlo/angular-cli sh # コンポーネントを作成 docker run -it --rm -w /app -v $(pwd):/app solareenlo/angular-cli ng generate component sample-component docker run -it --rm -w /app -v $(pwd):/app solareenlo/angular-cli ng g c sample-component # コンテナを立ち上げる docker run -d -w /app -v $(pwd):/app -p 4200:4200 solareenlo/angular-cli ng serve --host 0.0.0.0 で, localhost:4200を開く.\nDockerfileとdocker-compose.ymlでコンテナを動かすときは,\n# first-appを作成 docker run -it --rm -w /app -v $(pwd):/app solareenlo/angular-cli ng new first-app # first-appディレクトリに移動 cd first-app # コンテナに入って作業する docker run -it --rm -w /app -v $(pwd):/app solareenlo/angular-cli sh # docker-compose を使ってコンテナを立ち上げる docker-compose up -d # コンテナの中に入って作業する docker-compose exec angular sh # コンポーネント作成 docker-compose exec angular ng generate component sample-component docker-compose exec angular ng g c sample-component # テストは作らずにコンポーネント作成 docker-compose exec angular ng g c sample-component --spec false # コンポーネントの中にコンポーネントを作成 docker-compose exec angular ng g c sample-component/test --spec false # マテリアルデザインをインストール docker-compose exec angular ng add @angular/material # 関連するコンテンを全て止める docker-compose stop # 関連するコンテナを全削除 docker-compose rm で, localhost:4200を開く.\nコード例: solareenlo/angular-cli\nnpmの脆弱性を指摘されたら Angularでtarの脆弱性（Arbitrary File Overwrite）を指摘されたので修正する\nTravisCI経由でGitHub Pagesに公開  新規リポジトリを作成 GitHub APIトークンを生成 Travi CIの設定 APIトークンの設定 リポジトリをクローン Angular CLIで新規アプリを作成 (単体テスト)karma.conf.jsの修正 (総合テスト)protractor.conf.jsの修正 .travis.ymlの追加 GitHub Pagesにアクセス  Reference: AngularアプリをTravis CIからGitHub Pagesへデプロイする\nマテリアルデザイン  Googleが提唱した新しいデザインの方向性. 優れた古典と最新の技術と科学を組み合わせたもの. Angular用にもデザインコンポーネントがある. 公式HP: https://material.angular.io  インストール npm i --save @angular/material # or ng add @angular/material バージョンアップ ng update @angular/material 簡単な使い方 app.module.tsに以下を追加し,\nimport { MatInputModule, MatCardModule, MatButtonModule } from \u0026#39;@angular/material\u0026#39;; @NgModule ({ imports: [ MatInputModule, MatCardModule, MatButtonModule ] }) .htmlで, 以下の様に使用し,\n\u0026lt;mat-car\u0026gt; \u0026lt;mat-form-field\u0026gt; \u0026lt;textarea matInput [(ngModel)]=\u0026#34;enteredValue\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;/mat-form-field\u0026gt; \u0026lt;button mat-raised-button color=\u0026#34;primary\u0026#34; (click)=\u0026#34;onAddPost()\u0026#34;\u0026gt; Save Post \u0026lt;/button\u0026gt; \u0026lt;/mat-card\u0026gt; .cssに以下の様に書く.\nmat-card{ width: 80; margin: auto; } mat-form-field, textarea { width: 100%; } ファイル選択ボタンをMaterial化 /* .cssファイル */ .file-select-button, .file-name { display: inline-block; margin: 8px; }\u0026lt;!-- .htmlファイル --\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;file\u0026#34; style=\u0026#34;display: none\u0026#34; #fileInput accept=\u0026#34;image/*\u0026#34; (change)=\u0026#34;onChangeFileInput()\u0026#34; /\u0026gt; \u0026lt;button mat-raised-button color=\u0026#34;primary\u0026#34; class=\u0026#34;file-select-button\u0026#34; (click)=\u0026#34;onClickFileInputButton()\u0026#34;\u0026gt; \u0026lt;mat-icon\u0026gt;attach_file\u0026lt;/mat-icon\u0026gt; ファイルを選択 \u0026lt;/button\u0026gt; \u0026lt;p class=\u0026#34;file-name\u0026#34; *ngIf=\u0026#34;!file; else fileName\u0026#34;\u0026gt;ファイルが選択されていません\u0026lt;/p\u0026gt; \u0026lt;ng-template #fileName\u0026gt; \u0026lt;p class=\u0026#34;file-name\u0026#34;\u0026gt;{{ file?.name }}\u0026lt;/p\u0026gt; \u0026lt;/ng-template\u0026gt; \u0026lt;/div\u0026gt;// .tsファイル import { Component, ViewChild } from \u0026#39;@angular/core\u0026#39;; @Component({ selector: \u0026#39;my-app\u0026#39;, templateUrl: \u0026#39;./app.component.html\u0026#39;, styleUrls: [ \u0026#39;./app.component.css\u0026#39; ] }) export class AppComponent { @ViewChild(\u0026#39;fileInput\u0026#39;) fileInput; file: File | null = null; onClickFileInputButton(): void { this.fileInput.nativeElement.click(); } onChangeFileInput(): void { const files: { [key: string]: File } = this.fileInput.nativeElement.files; this.file = files[0]; } }// app.module.tsファイル import { NgModule } from \u0026#39;@angular/core\u0026#39;; import { BrowserModule } from \u0026#39;@angular/platform-browser\u0026#39;; import { FormsModule } from \u0026#39;@angular/forms\u0026#39;; import { MatButtonModule, MatIconModule } from \u0026#39;@angular/material\u0026#39;; import { AppComponent } from \u0026#39;./app.component\u0026#39;; import { HelloComponent } from \u0026#39;./hello.component\u0026#39;; @NgModule({ imports: [ BrowserModule, FormsModule, MatButtonModule, MatIconModule ], declarations: [ AppComponent, HelloComponent ], bootstrap: [ AppComponent ] }) export class AppModule { } Reference: Angular Materialでファイル選択ボタン\n基本的な使い方  コンポーネント単位で作っていく. 以下の様な感じでxxx.component.tsにコンポーネントの名前をselector: 'app-servers'で指定して, xxx.component.htmlの中で\u0026lt;app-server\u0026gt;\u0026lt;/app-server\u0026gt;と書いてどんどん使っていく.\n@Component({ selector: \u0026#39;app-servers\u0026#39;, templateUrl: \u0026#39;./servers.component.html\u0026#39;, // template: \u0026#39;\u0026lt;app-server\u0026gt;\u0026lt;/app-server\u0026gt;\u0026#39;, styleUrls: [\u0026#39;./servers.component.css\u0026#39;] }) 必要なコンポーネント・モジュールができたらapp.module.tsに追加していく.\n xxx.component.htmlにhtmlを, xxx.component.csにcssを, xxx.component.tsにjsをどんどん書いてく.\n  値を渡す(データバインド)  []は, TypeScriptからHTMLへのバインドを表す. ()は, HTMLからTypeScriptへのバインドを表す. [()]は, 双方向のバインドを表す.  .tsから.htmlへ値を渡す // .tx側 export class TestComponent implements OnInit { newPost = \u0026#39;Yes\u0026#39;; constructor() {} ngOnInit() {} }\u0026lt;!-- .thml側 --\u0026gt; \u0026lt;h1\u0026gt;{{ newPost }}\u0026lt;/h1\u0026gt; .tsから.htmlの\u0026lt;\u0026gt;の中に値を渡す // .ts側 export class TestComponent implements OnInit { newPost = \u0026#39;Yes\u0026#39;; constructor() {} ngOnInit() {} }\u0026lt;!-- .thml側 --\u0026gt; \u0026lt;textarea [value]=\u0026#34;newPost\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; ユーザーからのinputを受け付ける. 1文字ずつ受け付けるのは2種類ある.\nxxx.component.htmlに以下の様に書く.\n\u0026lt;!-- eventのbindを使う方法 --\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; class=\u0026#34;form-control\u0026#34; (input)=\u0026#34;onUpdateServerName($event)\u0026#34;\u0026gt; \u0026lt;p\u0026gt;{{ serverName }}\u0026lt;/p\u0026gt; \u0026lt;!-- serverNameが表示される --\u0026gt; \u0026lt;!-- ngModelモジュールを使う方法 これを使う場合はapp.module.tsに --- import { FormsModule } from \u0026#39;@angular/forms\u0026#39;; @NgModule({ imports: [ FormsModule ] }) --- を追加する必要がある. --\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; class=\u0026#34;form-control\u0026#34; [(ngModel)]=\u0026#34;serverName\u0026#34;\u0026gt; \u0026lt;p\u0026gt;{{ serverName }}\u0026lt;/p\u0026gt; \u0026lt;!-- serverNameが表示される --\u0026gt; ボタンを押して受け付けるのは1つある.\n\u0026lt;!-- .html側 --\u0026gt; \u0026lt;textarea #postInput\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;button (click)=\u0026#34;onAddPost(postInput)\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;p\u0026gt;{{ newPost }}\u0026lt;/p\u0026gt;// .ts側 export class TestComponent implements OnInit { newPost = \u0026#39;\u0026#39;; constructor() {} ngOninit() {} onAddPost(postInput: HTMLTextAreaElement) { this.newPost = postInput; } } 入力された値をコンポーネント内で操作する *.html内において,\n\u0026lt;!-- ↓は親にそのまま入力した値がnewServerNameとして渡る --\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; class=\u0026#34;form-control\u0026#34; [(ngModel)]=\u0026#34;newServerName\u0026#34;\u0026gt; \u0026lt;!-- ↓は子に入力された値が#serverNameInputとして残ってる --\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; class=\u0026#34;form-control\u0026#34; #serverNameInput\u0026gt; 子A \u0026gt; 親 \u0026gt; 子Bと渡す  子A \u0026gt; 親 が@output()で, データを渡す 親 \u0026gt; 子B が@input()で, データを渡す  // 子Aの.tsの中身 import { Component, EventEmitter, Output } from \u0026#39;@angular/core\u0026#39;; @Component({ selector: \u0026#39;app-achild\u0026#39; }) export class AchildComponent { @Output() postCreated = new EventEmitter(); onAddPost() { const post = \u0026#39;test\u0026#39;; this.postCreated.emit(post); } }\u0026lt;!-- 親の.htmlの中身 --\u0026gt; \u0026lt;!-- ここ↓は@Outoutなので, 子の要素postCreatedから親の要素onPostAddedに情報が行く --\u0026gt; \u0026lt;app-achild (postCreated)=\u0026#34;onPostAdded($event)\u0026#34;\u0026gt;\u0026lt;/app-achild\u0026gt; \u0026lt;!-- ここ↓は@Input()なので, 子の要素postsに親の要素storedPostsから情報が行く --\u0026gt; \u0026lt;app-bchild [posts]=\u0026#34;storedPosts\u0026#34;\u0026gt;\u0026lt;/app-bchild\u0026gt;// 親の.tsの中身の一部 export class AppComponent { storedPosts = []; onPostAdded(post) { this.storedPosts.push(post); } }// 子Aの.tsの中身 import { Component, Input } from \u0026#39;@angular/core\u0026#39;; @Component({ selector: \u0026#39;app-bchild\u0026#39; }) export class AchildComponent { @Input() posts = []; } EventEmitter  コンポーネントからその上位コンポーネントへの, 任意の値の通知を提供する.  下位コンポーネントの.tsに以下の様にして使う.\nimport { EventEmitter, Output } from \u0026#39;@angular/core\u0026#39;; export class TestComponent { @output() postCreated = new EventEmitter(); onAddPost() { const post = test; this.postCreated.emit(post); } } コンポーネント間で値を渡す  ここではxxx.service.tsを使う. その際にはInjectableコンポーネントを使用する. xxx.service.tsで, 渡すclassを作って, それを2つのコンポーネントのconstructorでそれぞれ作って, 渡される方の子コンポーネントのngOnInitで値を渡してあげる. RxJSライブラリを使って, streamで非同期でコンポーネント間でデータを渡せる.  // xxx.service.tsの例 import { Injectable } from \u0026#39;@angular/core\u0026#39;; import { Post } from \u0026#39;./post.model\u0026#39;; @Injectable({providedIn: \u0026#39;root\u0026#39;}) export class PostsService { private posts: Post[] = []; getPosts() { return [...this.posts]; } addPosts(title: string, content: string) { const post: Post = {title, content}; this.posts.push(post); } }  componentでデータを変更する. componentは変更したデータをメソッドコールによってserviceに渡す. serviceは変更されたデータを受け取り, そのデータをイベント発火することで展開する. 各componentは発火されたイベントをsubscribeし, 自身のプロパティを更新する.  // csv.service.tsの中身 import { Injectable } from \u0026#39;@angular/core\u0026#39;; // イベント発火のためのSubjectをimport import { Subject } from \u0026#39;rxjs\u0026#39;; @Injectable({providedIn: \u0026#39;root\u0026#39;}) export class CsvService { // データの変更を通知するためのオブジェクト  // 以降の｢Subscribeのためのプロパティを宣言｣と｢データの更新イベント｣で使用するプロパティを宣言し, Subjectのインスタンスを生成する.  // このプロパティを用いて共有データの変更通知を行う.  private inputCsv = new Subject\u0026lt;File\u0026gt;(); // Subscribeするためのプロパティ(componetn間で共有するためのプロパティ)  // 先に生成したオブジェクトinputCsvからasObservable()でオブジェクトを生成する.  // asObservable()で生成されたオブジェクトは, データ共有を行うコンポーネント側でsubscribe(後述)することでデータ共有の仕組みを実現する.  public inputCsv$ = this.inputCsv.asObservable(); // CsvServiceのインスタンスを生成  constructor() {} // データの更新イベント  // これは先に生成したオブジェクトinputCsvからnext()を実行する.  // このメソッドはデータ共有を行うコンポーネントから実行されることを想定したもので, 引数のinputをそのままnext()の引数にセットしている.  // このメソッドでthis.inputCsv.next(input);が実行されることで, subscribe(後述)で待ち受けているコンポーネントに引数のデータが展開される.  public onNotifyInputCsv(input: File) { this.inputCsv.next(input); } }// 送り手の.tsの中身 import { Component, OnInit, ViewChild } from \u0026#39;@angular/core\u0026#39;; import { CsvService } from \u0026#39;../service/csv.service\u0026#39;; @Component({ selector: \u0026#39;app-csv-input\u0026#39;, templateUrl: \u0026#39;./csv-input.component.html\u0026#39;, styleUrls: [\u0026#39;./csv-input.component.css\u0026#39;] }) export class CsvInputComponent implements OnInit { @ViewChild(\u0026#39;fileInput\u0026#39;) fileInput; file: File | null = null; onClickFileInputButton(): void { this.fileInput.nativeElement.click(); } onChangeFileInput(): void { const files: { [key: string]: File } = this.fileInput.nativeElement.files; this.file = files[0]; // ここでデータをservice.tsへ送ってる.  // ここで引数にセットしたデータがコンポーネント間で共有するデータとして扱われる.  this.csvService.onNotifyInputCsv(this.file); } constructor(private csvService: CsvService) { } ngOnInit() { } }// 受け手の.tsの中身 import { Component, OnInit, OnDestroy } from \u0026#39;@angular/core\u0026#39;; import { Subscription } from \u0026#39;rxjs\u0026#39;; import { CsvService } from \u0026#39;../service/csv.service\u0026#39;; @Component({ selector: \u0026#39;app-calculate\u0026#39;, templateUrl: \u0026#39;./calculate.component.html\u0026#39;, styleUrls: [\u0026#39;./calculate.component.css\u0026#39;] }) export class CalculateComponent implements OnInit, OnDestroy { public file: File | null = null; // subscribeを保持するためのSubscription  private csvSubscription: Subscription; constructor(private csvService: CsvService) {} ngOnInit() { // serviceで共有しているデータが更新されたら発火されるイベントをキャッチする.  // inputCsv におけるデータの更新イベントでnext()によって発火されたイベントをsubscribeするイベントハンドラを登録している.  // またcsvSubscriptionにsubscribeのオブジェクトをセットしているのは, 後述のngOnDestroyでsubscribeの内容を破棄するため.  this.csvSubscription = this.csvService.inputCsv$.subscribe(csv =\u0026gt; { this.file = csv; }); } // component破棄時の後処理  // subscribeした内容をcomponentが破棄されるタイミングでunsubscribeすることで破棄する.  // これを行わないと, 登録したイベントハンドラが延々と生き続けることになる.  ngOnDestroy() { this.csvSubscription.unsubscribe(); } } Reference: Angular サービスを使用してデータをコンポーネント間で共有する\n値を渡す(テンプレート参照変数) \u0026lt;input #test type=\u0026#34;text\u0026#34; (key)=\u0026#34;onKey(test.value)\u0026#34;\u0026gt; これで, inputにテキストで入力された文字が1つずつonKey関数に渡っていく.\nngIf else 特定の状況下でのみアプリケーションがビューまたはビューの一部を表示する様にする.\n\u0026lt;!-- *.htmlの中身 --\u0026gt; \u0026lt;p *ngIf=\u0026#34;serverCreated\u0026#34;\u0026gt;Server was created, server name is {{ serverName }}\u0026lt;/p\u0026gt;// *.tsの中身 import { Component, OnInit } from \u0026#39;@angular/core\u0026#39;; @Component({ selector: \u0026#39;app-servers\u0026#39;, templateUrl: \u0026#39;./servers.component.html\u0026#39;, styleUrls: [\u0026#39;./servers.component.css\u0026#39;] }) export class ServersComponent implements OnInit { serverCreated = false; constructor() {} ngOnInit() { } onCreateServer() { this.serverCreated = true; this.serverCreationStatus = \u0026#39;Server was created!\u0026#39;; } } ngStyle コンポーネントのスタイルを操作する.\n\u0026lt;!-- *.htmlの中身 Hello World!が緑になったり赤になったりする.--\u0026gt; \u0026lt;p [ngStyle]=\u0026#34;{backgroundColor: getColor()}\u0026#34;\u0026gt;Hello World!\u0026lt;/p\u0026gt;// *.tsの中身 import { Component } from \u0026#39;@angular/core\u0026#39;; @Component({ selector: \u0026#39;app-server\u0026#39;, templateUrl: \u0026#39;./server.component.html\u0026#39; }) export class ServerComponent { serverStatus = \u0026#39;offline\u0026#39;; constructor() { this.serverStatus = Math.random() \u0026gt; 0.5 ? \u0026#39;online\u0026#39; : \u0026#39;offline\u0026#39;; } getServerStatus() { return this.serverStatus; } getColor() { return this.serverStatus === \u0026#39;online\u0026#39; ? \u0026#39;green\u0026#39; : \u0026#39;red\u0026#39;; } } ngClass コンポーネントのクラスを扱う.\n\u0026lt;!-- *.htmlの中身 Hello World!の背景が緑になったり赤になったりする. 背景が緑の時に文字が白色になる. --\u0026gt; \u0026lt;p [ngStyle]=\u0026#34;{backgroundColor: getColor()}\u0026#34; [ngClass]=\u0026#34;{online: serverStatus === \u0026#39;online\u0026#39;}\u0026#34;\u0026gt; Hello World! \u0026lt;/p\u0026gt;// *.tsの中身 import { Component } from \u0026#39;@angular/core\u0026#39;; @Component({ selector: \u0026#39;app-server\u0026#39;, templateUrl: \u0026#39;./server.component.html\u0026#39;, styles: [`.online { color: white; }`] }) export class ServerComponent { serverStatus = \u0026#39;offline\u0026#39;; constructor() { this.serverStatus = Math.random() \u0026gt; 0.5 ? \u0026#39;online\u0026#39; : \u0026#39;offline\u0026#39;; } getServerStatus() { return this.serverStatus; } getColor() { return this.serverStatus === \u0026#39;online\u0026#39; ? \u0026#39;green\u0026#39; : \u0026#39;red\u0026#39;; } } 要素を渡す Aコンポーネントが利用させるときに, Aコンポーネントのタグに挟まっている要素をAコンポーネントが取得してきて, Aコンポーネント内の\u0026lt;ng-content\u0026gt;\u0026lt;/ng-content\u0026gt;の部分に展開する.\nコンポーネントのライフサイクル    フック 目的とタイミング     ngOnChanges() Angularがデータバインドされた入力プロパティを(再)設定するときに応答する.このメソッドは, 現在および以前のプロパティ値のSimpleChangesオブジェクトを受け取る.ngOnInit()の前に呼び出され, データバインドされた入力プロパティが変更されるたびに呼び出される.   ngOnInit() Angularがデータバインドされたプロパティを最初に表示し, ディレクティブ/コンポーネントの入力プロパティを設定した後で, ディレクティブ/コンポーネントを初期化する.最初のngOnChanges()の後に一度呼び出される.   ngDoCheck() Angularが検出できない, または検出できない変更を検出して, それに基づいて実行する.変更検知の実行中に毎回, そしてngOnChanges()とngOnInit()の直後に呼び出される.   ngAfterContentInit() Angularがコンポーネントのビューあるいはディレクティブが存在するビューに, 外部コンテンツを投影した後に応答する.最初のngDoCheck()の後に1度呼び出される.   ngAfterContentChecked() Angularがディレクティブ/コンポーネントに投影された外部コンテンツをチェックした後に応答する. ngAfterContentInit()とその後全てのngDoCheck()の後に呼び出される.   ngAfterViewInit() Angularがコンポーネントのビューと子のビュー, あるいはディレクティブが存在するビューを初期化した後に応答する.最初のngAfterContentChecked()の後に1度呼び出される.   ngAfterViewChecked() Angularがコンポーネントのビューと子のビュー, あるいはディレクティブが存在するビューをチェックした後に応答する.ngAfterViewInit()とその後のすべてのngAfterContentChecked()の後に呼び出される.   ngOnDestroy() Angularがディレクティブ/コンポーネントを破棄する直前に, クリーンアップする.メモリリークを回避するためにObservableの購読を解除し, イベントハンドラをデタッチしましょう.Angularがディレクティブ/コンポーネントを破棄する直前に呼び出される.    Reference: ライフサイクル・フック\nformを使う NgFormモジュールを使えば良い.\n// .tsの例 import { NgForm } from `@angular/forms`; export class TestComponent { onAddPost(form: NgForm) { if (form.invalid) { return ; } const post = { title: form.value.title; } } }\u0026lt;!-- .htmlの例 --\u0026gt; \u0026lt;form (submit)=\u0026#34;onAddPost(postForm)\u0026#34; #postForm=\u0026#34;ngForm\u0026#34;\u0026gt; \u0026lt;mat-form-field\u0026gt; \u0026lt;input matInput type=\u0026#34;text\u0026#34; name=\u0026#34;title\u0026#34; ngModel required #title=\u0026#34;ngModel\u0026#34;\u0026gt; \u0026lt;mat-error *ngIf=\u0026#34;title.invalid\u0026#34;\u0026gt;タイトルを入力してください.\u0026lt;/mat-error\u0026gt; \u0026lt;/mat-form-field\u0026gt; \u0026lt;/form\u0026gt; デプロイ  超簡単にサイト公開できるAWS Amplify Consoleを使ってAngularのCI/CD環境を作ってみる AngularアプリをTravis CIからGitHub Pagesへデプロイする Angularで作ったWebアプリをGitHubで管理してS3に自動デプロイする Create an Angular Application That Builds and Deploys with Now  "},{"idx":89,"href":"/docs/aws/","title":"Aws","content":" アマゾンウェブサービス（AWS）とは  Amazonが提供するパブリッククラウドコンピューティングのこと. 従量課金制. コンピューティング, ストレージ, データベース, 分析, ネットワーキング, モバイル, 開発者用ツール, 管理ツール, IoT, セキュリティ, エンタープライズアプリケーションなど, グローバルなクラウドベース製品を幅広く利用できる.  S3  インターネット用のオブジェクトストレージサービスのこと. Amazon Simple Storage Serviceの略.  Elastic Beanstalk  Java, .NET, PHP, Node.js, Python, Ruby, GoおよびDockerを使用して開発されたウェブアプリケーションやサービスを, Apache, Nginx, Passenger, IISなどのサーバーでデプロイおよびスケーリングするためのサービスのこと. 平たく言うとアマゾン版VPS.  SSH接続  インスタンスを立ち上げる. インスタンスにキーペア(秘密鍵/公開鍵のペア)を設定する. 秘密鍵をダウンロードして(ファイル名sshkey.pem), インスタンスのIPアドレスを確認して, 以下を実行.\nchmod 600 sshkey.pem ssh -i sshkey.pem ec2-user@000.000.000.000 後は普通のVPSと同じ.\n  Amazon Linuxのバージョン確認 cat /etc/system-release お名前.comで取得したドメインを割り当てる  Route 53でCreate Hosted Zoneボタンを押す. Domain Nameに, example.jpなど独自ドメインを入れて, Createを押す. NS（ネームサーバー）のアドレス4つをコピペしておく. Create Record Setボタンを押す.  Type: A - IPv4 address もしくは iPV6 address Alias: Yes Alias Hostedを選択するとプルダウン表示されるので, そこからElastic Beanstalkのデフォルトのホスト名を選択  お名前.comのドメイン設定のネームサーバー変更を選択する. Elastic Beanstalkに割り当てたいドメインにチェックを入れる. 他のネームサーバーの利用を選択して, Route 53で控えたネームサーバーのアドレス4つを入れて確認画面へ進むを押して保存する. 数時間後には独自ドメインでアクセスできる.  Reference: Elastic Beanstalkのサーバーにお名前.comで取得した独自ドメインを割り当てる\nhttps化する  ドメインを取得する. 上記の方法でElastic Beanstalkにカスタムドメインを割り当てる. Elastic Beanstalkにロードバランサーを割り当てる.  Elastic Beanstalk \u0026gt; インスタンス \u0026gt; 設定 \u0026gt; 容量 \u0026gt; 環境タイプをロードバランサーへ \u0026gt; 1つ戻ってロードバランサー  ロードバランサーに証明書を割り当てる.  IAM  ユーザーに対してAWSへのアクセスを安全に制御するための仕組みのこと. AWS Identity and Access Managementの略.  ECS  Dockerアプリケーションをスケーラブルなクラスターで実行するために使用するサービスのこと. Amazon Elastic Container Serviceの略.  RDS  クラウド上でリレーショナルデータベースをセットアップ, 運用, スケーリングできるサービスのこと. RDBで作ったコンテナの代わりに使える. Amazon Relational Database Serviceの略.  Memcached  高パフォーマンスキャッシュやセッションストアとして使用できる, 分散型インメモリkey-valueストアのこと. Redisで作ったコンテナの代わりに使える.  VPC  AWSアカウント専用の仮想ネットワークのこと. 定義した仮想ネットワーク内でAWSリソースを起動することができる. Amazon Virtual Private Cloudの略.  VPCセキュリティグループ  同一グループ外のインスタンスと通信を行う際のトラフィックを制御する仮想ファイアウォールのこと.  Amplify Console  フルスタックのサーバーレスウェブアプリケーションのデプロイおよびホストするための, Gitベースのワークフローを提供する. フルスタックのサーバーレスアプリケーションは, GraphQLやREST APIなどのクラウドリソース, ファイルおよびデータストレージで構成されたバックエンドと, React, Angular, Vue, Gatsbyなどの単一ページのアプリケーションフレームワークで構築されたフロントエンドから構成される.  Certificate Manager  AWSでのウェブアプリのhttps化の設定の時に使用する.  ざっくり料金計算  ざっくりAWS  GitHubリポジトリ: noplan1989/aws-rough   "},{"idx":90,"href":"/docs/blockchain/","title":"Blockchain","content":" Blockchainとは  正しい記録しか記録できず、記録を変更・改ざんできない。（耐改ざん性） 管理者不在で、参加者全員で共有・運用する。（非中央集権・トラストレス・自律的） ネットワーク共有型データベース。（分散型DB） 後方参照するハッシュポインタをもつ連結リスト Reference: ブロックチェーンのデータ構造をJavascriptで作ろう  Blockchainの仕組み  プロトコルに従った書式のDBだけが記録される。 参加者全員によって合意されたデータだけが有効となる。 一度書き込まれたデータは変更も削除もできない。 システム全体を止めることはほぼできない。 記録されるのは取引の履歴だけ。  BlockChainの歴史  1980年代のリバタリアニズム. 中央集権が可能な限り最小限でなければならいという考え. 政治的イデオロギー. 1990年代のサイファーパンクの結成  個人の通信における本当のプライバシーを我々に与える保障を、法的にではなく物理的・数学的に保証する。  サイファーパンクの理念  プライバシーというのは選択的に自己開示する力のことをいう。 開かれた社会においてはプライバシーには匿名の取引システムが必須だ。 我々サイファーパンクは匿名システムの建設に献身する。 Reference: ビットコインに実は４０年の歴史【サイファーパンク宣言を読む】全文和訳掲載   BlockChainにはブロックが必要？  台帳記録にはブロックは必須要素ではない. ブロックの承認のためのルールが記載されている. コンセンサスを駆動する本体はブロック ノードは単なるスクリプト処理系  BlockChainのコンセンサスによるガバナンス  ブロックチェーンノードが コンセンサスの主体 ブロックを承認する ブロック作成者（マイナー）は 信頼点ではない コンセンサスの結果（承認）に支配される Reference: 地域におけるブロックチェーン活用の可能性  BlockChainが発達すると消える産業  公証人 各種仲介業者（アート的発想で価値を判断する人は必要） 第一次産業・トレーサビリティー 貧困解消 裁判の証拠 References:  第21 『#ブロックチェーンビジネスに今すぐ参入すべき？』Part2 3 第21 『#ブロックチェーンビジネスに今すぐ参入すべき？』Part2 2   Blockchainの進化 パターン1  Blockchain 1.0: デジタル通貨の実現(例: Bitcoin) Blockchain 2.0: デジタルアセットのオンライン流通を実現, 金融分野 Blockchain 3.0: スマートコントラクトやDappsの実現, 非金融分野(医療情報, 商流管理, 資産管理, 土地登記など) Reference: 「ブロックチェーン3.0」への電通の挑戦  パターン2  Blockchain 1.0: 暗号通貨 Blockchain 2.0: スマートコントラクト Blockchain 3.0: アプリケーションの拡張 Blockchainの適用は, ヘルスケア, 知的財産権, 教育, そしてマテリアルに徐々に広がっている. ネットワーキング, 経済の共有, コミュニケーション, 社会管理, 慈善事業, 文化, 娯楽などの幅広いアプリケーションに広がっている. Reference: Knowing the Blockchain 1.0, Blockchain 2.0, Blockchain 3.0, and Blockchain 4.0  Blockchain関連の市場規模  価値の流通・ポイント: 1兆円 権利証明行為の非中央集権化の実現: 1兆円 遊休資産ゼロ, 高効率シェアリングの実現: 13兆円 オープン, 高効率, 高信頼なサプライチェーンの実現: 32兆円 プロセス, 取引の全自動化, 効率化の実現: 20兆円 Reference: 経済産業省「ブロックチェーン技術を利用したサービスに関する国内外動向調査」  "},{"idx":91,"href":"/docs/c/","title":"C","content":" C言語とは  1972年のAT\u0026amp;Tベル研究所で, ブライアン・カーニハンとデニス・リッチーによって開発された, コンパイル型の汎用プログラミング言語のこと.  Hello World #include \u0026lt;stdio.h\u0026gt; int main(void) { puts(\u0026#34;Hello, world!\u0026#34;); return 0; } コンパイラ  低レイヤを知りたい人のためのCコンパイラ作成入門  "},{"idx":92,"href":"/docs/circleci/","title":"Circleci","content":" CircleCIとは  クラウド上でCI/CDを行なってくれるサービスの1つ. 公式サイト: https://circleci.com  docs  CircleCI Documentation  Angular \u0026gt; CircleCI \u0026gt; GitHub Pages の例  iotajapan/ng-iotajapan  submoduleをpush出来るようにするには  Settings \u0026gt; PERMISSIONS \u0026gt; Checkout SSH keys でuser keyを有効にする.  AWSのS3へデプロイ  Nuxt.js+CircleCIで静的ページをAWSのS3へデプロイする  AWSのElastic Beanstalkへデプロイ  以下でCircleCIでElastic Beanstalk CLIを起動して, デプロイする.\n# .circleci/config.yml version: 2 jobs: deploy: working_directory: ~/app docker: - image: circleci/ruby:2.6.3 steps: - checkout - run: name: Installing deployment dependencies working_directory: / command: | sudo apt-get -y -qq update sudo apt-get install python-pip python-dev build-essential sudo pip install --upgrade setuptools sudo pip install awsebcli --upgrade - run: name: Deploying command: eb deploy master-TaxPlusAws01-env workflows: version: 2 build: jobs: - deploy: filters: branches: only: - master 以下はElastci Beanstalk CLIの設定.\n# .elasticbeanstalk/config.yml branch-defaults: master: environment: master-TaxPlusAws01-env global: application_name: tax-plus-aws-01 default_ec2_keyname: tax-plus default_platform: 64bit Amazon Linux 2018.03 v4.8.2 running Node.js default_region: ap-northeast-1 sc: git そして, CircleCIのProject Settings \u0026gt; Environment VariablesでAWS_ACCESS_KEY_IDとAWS_SECRET_ACCESS_KEYを設定する.\n Reference:\n Deploying to Elastic Beanstalk via CircleCi 2.0 https://github.com/solareenlo/tax-plus-aws   参考サイト  CircleCI 2.1の機能を使ってインフラの\u0026rdquo;ほぼ\u0026rdquo;全自動構成管理をやってみた話 CircleCI 2.1 の新機能を使って冗長な config.yml をすっきりさせよう！  "},{"idx":93,"href":"/docs/cloud/","title":"Cloud","content":" クラウドコンピューティングとは  クラウドサービスプラットフォームからインターネット経由で処理能力, データベースストレージ, アプリケーション, および他のITリソースをオンデマンドかつ従量制料金で利用するシステムのこと.  比較  ilyas-it83/CloudComparer  "},{"idx":94,"href":"/docs/command/","title":"Command","content":" コマンドとは  コンピュータに特定の機能の実行を指示する命令のこと. たくさんのコマンドがあり, 黒い画面に直接入力する.  Linuxでhtmlを開く xdg-open index.html UbuntuでChromeを開く google-chrome プロセスの動作状況 (ps) psコマンドはプロセスの動作状況を確認するためのコマンド.\nauxオプション\nauxオプションは、aとuとxというオプションを組み合わせたものです。\n a: 端末操作のプロセスを表示する u: CPUやメモリの使用率などを表示する x: 端末操作以外のプロセスを表示する  ps aux \u0026gt; USER PID %CPU %MEM VSZ RSS TT STAT STARTED TIME COMMAND \u0026gt; solareenlo 96263 4.3 2.0 5500012 168620 ?? S 水07PM 21:03.04 /Applications/Utilities/Terminal.app/Contents/MacOS/Terminal \u0026gt; その他たくさん こんな感じで標準出力される.\nReference: ps auxの見方がよく判らない・・・\nsha256を出力 # Mac shasum -a 256 \u0026lt;ファイル名\u0026gt; # Linux sha256sum \u0026lt;ファイル名\u0026gt; 所有権を変更 (chown) ファイルのユーザー所有権とグループ所有権をrootからsolareenloへ変更する\nsudo chown solareenlo:solareenlo ファイル名 # 再帰的に変更 sudo chown -R solareenlo:solareenlo ファイル名 基本的なUnixコマンドの使い方 mkdirを使って一気にファイルを複数作成する # app1, app2, ... app39, app40というフォルダを一斉に作成する方法 mkdir app{1..40} 一般ユーザーと管理ユーザー # 一般ユーザーだと [solareenlo@localhost ~]$ # 管理ユーザーだと [solareenlo@localhost ~]# UNIXシステムのディレクトリの大体の構成  binには, バイナリデータが入ってる. binには, catやcpといった, システムを動かすための基本コマンドの実行ファイルがある. etcには, アプリケーションの設定ファイルが入っている. homeには, 各ユーザーのホームディレクトリが入ってる. sbinには, システム管理用のコマンドが入っている. usrには, 一般的なアプリケーションが格納されてる. varには, システムのログファイルなどの頻繁に書き換わるようなファイルが入ってる.  ディレクリを移動 # 現在いるディレクトリを表示 pwd # 画面をきれいにするには clear # Control + l # ディレクトリへ移動 cd path/to/directory/ # 1つ上の階層へ戻る cd .. # 直前のディレクトリへ戻る cd - # ホームディレクトリへ戻る cd ディレクトリを操作 # ディレクトリを新規作成 mkdir test # ディレクトリ一覧表示 ls # ディレクトリをコピー cp -r test test2 # test3ディレクトリの中にconfigディレクトリを一気に作成する mkdir -p test3/config # test3ディレクトリをtest2ディレクトリに移動する mv test3 test2 # 空のディレクトリを削除する rmdir test2/test3/config # 空でないディレクトリを削除する rm -r test2 ファイル操作 # file.txtの中身を全部一斉に見る cat path/to/file.txt # file.txtの中身を少しずつ見るには less path/to/file.txt # 矢印キーでスクロール # space で下へ移動 # Control + F で一画面先へ移動 # Control + B で一画面前へ移動 # g でファイル先頭へ移動 # G でファイル末尾へ移動 # q で終了 # 現在のディレクトリにファイルコピー cp path/to/file.txt . # 現在のディレクトリにあるファイルを名前変更 mv file.txt file2.txt # ファイルを削除 rm file2.txt bashの便利機能 # 操作をとりあえずキャンセル # CTRL + C # コマンドの履歴検索 # CTRL + R # そこで何かしら前に使ったコマンドを途中まで入力してtabキーを押して補完して, エンターキーを押すと実行される コマンドの履歴 # 今までに使用したコマンドの履歴を表示する history # 出てきた履歴を使う !333 # 直前のコマンドを使う !! # 2個前のコマンドを使う !-2 # コマンドに渡した最後の文字列を再利用するには!$を使う ls test/ cd !$ # 履歴の予測を使う !pw # 上記のコマンドで, 今までに使ったことがあるpwdを実行してくれる # 記憶があやふやな場合は !pw:p # で, 直近に使ったコマンド予測が実行されずに帰ってくる # !を使ってコマンドの履歴にアクセスできる. コマンドについて詳しく調べる # mkdirについて調べる mkdir --help # より詳しく調べる man mkdir # マニュアル内での検索は /all # のように/を使って行う. # 後の操作はvimと一緒. シンボリックリンクの使い方 # シンボリックリンクの付け方 mkdir -p config/production/database ln -s config/production/database/ dbconfig ls -l # シンボリックリンクを解消する unlink dbconfig ユーザーとグループを確認 # ユーザーを確認する cat /etc/passwd \u0026gt; solareenlo:x:1000:1000:solareenlo,,,:/home/solareenlo:/bin/bash # ユーザー名:パスワード有り:ユーザーID:グループID:グループ名,,,:ホームディレクトリ:シェルの場所 # グループを確認する cat /etc/group \u0026gt; solareenlo:x:1000: # グループ名:パスワード有り:グループID:所属するユーザー名 # 自分が所属しているグループ名を表示 groups パーミッションの変更 # 一番はじめの状態が ls -l \u0026gt; -rwxrw-r--. 1 solareenlo solareenlo 日付 sample # としよう. # rwxrwxrwx の並びは, user group other の並びになっている. # groupに実行権限を付与する chmod g+x sample \u0026gt; rwx rwx r-- # groupとotherに実行権限を与える chmod go+x sample \u0026gt; rwx rwx r-x # user, group, other全員から実行権限を剥奪する chmod a-x sample \u0026gt; rw- rw- r-- 数値によるパーミッションの変更 # rwx = 4+2+1 = 7 # と, 2進数の和で表現される. # ので, rwx rw- r-- = 4+2+1, 4+2+0, 4+0+0 = 764 # ので, chmod 774 sample = rwx rwx r-- chmod 664 sample = rw- rw- r-- # となる 独自のコマンドを作成 # 先ずはコマンドが先に存在しないことを確認する type hi \u0026gt; -bash: type: hi: not found # で, OK # hi!と出力されるコマンドをvimで作成する vim hi #!/bin/bash echo \u0026#39;hi!\u0026#39; :wq # hiコマンドの実行権限を見てみる ls -l \u0026gt; -rw-rw-r-- solareenlo solareenlo 日付 hi # 実行権限が無いので付与する chmod u+x hi ls -l \u0026gt; -rwx-rw-r-- solareenlo solareenlo 日付 hi ./hi \u0026gt; hi! 一時的にpathを通す pwd \u0026gt; /home/現在の/path/test export PATH=/home/現在の/path/test:$PATH # どこにpathが通っているのかを見るには echo $PATH \u0026gt; /anaconda3/bin:/usr/local/git/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/home/現在の/path/test # いろいろなpathが通っているディレクトリが見れる hi \u0026gt; hi! # この方法は一時的なpathの通し方 # 実行しようとしているコマンド(hi)がどこから呼び出されているのかを探るには which hi # 全体の環境変数を見るには printenv \u0026gt; TERM_PROGRAM=Apple_Terminal \u0026gt; ANDROID_HOME=/Users/solareenlo/Library/Android/sdk \u0026gt; TERM=xterm-256color \u0026gt; SHELL=/bin/bash \u0026gt; CLICOLOR=1 # こんな感じで出てくる echo $PATH \u0026gt; /anaconda3/bin:/usr/local/git/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/home/現在の/path/test # 環境変数に$を付けると, その値を意味する 管理者ユーザーになる ls -l /var/log/boot.log \u0026gt; -rw------- 1 root root 27000 日付 /var/log/boot.log cat !$ \u0026gt; cat /var/log/boot.log \u0026gt; cat: /var/log/boot.log: 許可がありません # となるので, # rootユーザーに切り替える # 現在のディレクトリにログイン sudo su \u0026gt; Password: # か, # ホームディレクトリにログイン sudo su -l \u0026gt; Password: # か, sudo su - \u0026gt; Password: pwd \u0026gt; /root cat /var/log/boot.log \u0026gt; きちんと中身が見れる # rootユーザーを抜ける exit # rootユーザーは何でもできるので, うっかりで大変なことになるので, # 実際はsudoで1つ1つrootユーザー権限でコマンドを実行する. sudo cat /var/log/boot.log \u0026gt; きちんと中身が見れる 管理者を変更するchown cp /var/log/boot.log . \u0026gt; cp: \u0026#39;/var/log/boot.log\u0026#39; を読み込み用に開くことができません: 許可がありません sudo !! \u0026gt; sudo cp /var/log/boot.log . ls -l \u0026gt; -rw------- 1 root root 27000 日付 boot.log cat boot.log \u0026gt; cat: boot.log: 許可がありません # boot.logのオーナーを変更する sudo chown solareenlo:solareenlo boot.log \u0026gt; -rw------- 1 solareenlo solareenlo 27000 日付 boot.log cat boot.log \u0026gt; boot.logの中身が見れる wc, head, tail, grepを使う # ファイルの行数, 単語数, 文字数をカウントしてくれるwc wc boot.log \u0026gt; 490 3397 27077 boot.log # ファイルの行数だけ表示 wc -l boot.log \u0026gt; 490 boot.log # ファイルの先頭10行をcatしたい時 head boot.log \u0026gt; 先頭の10行だけが表示される # ファイルの先頭3行だけを表示したい時 head -n 3 boot.log head -3 boot.lgo \u0026gt; 先頭の3行だけが表示される # ファイルの末尾から10行を表示する tail boot.log # ファイルの末尾から3行を表示する tail -n 3 boot.log tail -3 boot.log # 特定の単語を検索する # 正規表現ももちろんできる grep \u0026#39;etc\u0026#39; boot.log \u0026gt; 検索結果が返ってくる リダイレクション, パイプを使う # コマンドの実行結果をテキストファイルに出力する echo \u0026#39;date\u0026#39; \u0026gt; cmd.txt cat cmd.txt \u0026gt; date # cmd.txtの中にdateが書き込まれた # コマンドの実行結果をテキストファイルの末尾に付け加える echo \u0026#39;free\u0026#39; \u0026gt;\u0026gt; cmd.txt cat cmd.txt \u0026gt; date \u0026gt; free # 逆にテキストファイルの中身をコマンドに渡して実行する bash \u0026lt; cmd.txt \u0026gt; 日付 \u0026gt; メモリの使用状況 # テキストファイルの中身をコマンドに渡した実行結果をテキストファイルに書き込む bash \u0026lt; cmd.txt \u0026gt; result.txt cat result.txt \u0026gt; 日付 \u0026gt; メモリの使用状況 # コマンドの実行結果をパイプを使ってコマンドに渡す ls -l /etc | grep \u0026#39;bash\u0026#39; \u0026gt; bashを含むls -l /etcの結果が返ってくる # さらに, 上記の結果の行数を調べる ls -l /etc | grep \u0026#39;bash\u0026#39; | wc -l \u0026gt; 3 ワイルカード # 任意の文字列を扱う*を使って, 拡張子が.confを表示する ls /etc/*.conf \u0026gt; 拡張子が.confのものだけが表示される # cから始まり, 2文字だけ何でも良くて, 拡張子も何でもいい場合は?と*を使う ls /etc/c??.* \u0026gt; 当該条件に合致するものが表示される find, xargs # ファイルを検索してくれるfind # find 場所 名前で検索 条件(initのあとは何でも良い) find /etc -name \u0026#39;init*\u0026#39; \u0026gt; 当該ファイルが出力される # ディレクトリを覗いてファイルだけ検索したい場合 find /etc -name \u0026#39;init*\u0026#39; -type f # さらに, 検索したファイルに対して別のコマンドを実行したい場合は, -exec wc -l {} + を使う. # {}の中に検索結果を入れて実行してくれる. find /etc -name \u0026#39;init*\u0026#39; -type f -exec wc -l {} + \u0026gt; 当該ファイルの行数がカウントされて表示される # 複数の結果をコマンドに流し込めるxargsもある find /etc -name \u0026#39;init*\u0026#39; -type f | xargs wc -l \u0026gt; 当該ファイルの行数がカウントされて表示される ブレース展開 # まとめて展開 echo {a, b, c} \u0026gt; a b c echo {1..10} \u0026gt; 1 2 3 4 5 6 7 8 9 10 echo {1..3}{a..c} \u0026gt; 1a 1b 1c 2a 2b 2c 3a 3b 3c # 連続してコマンドを実行するには\u0026amp;\u0026amp;を使う mkdir test \u0026amp;\u0026amp; cd test # ブレース展開を使って一気にディレクトリを作成する mkdir app{1..3} ls \u0026gt; app1 app2 app3 # ブレース展開を使って一気にディレクトリの中にファイルを作成する touch app{1..3}/test{1..3}{.txt,.jpeg,.git} ls app2 \u0026gt; test1.txt test1.jpeg test1.git test2.txt test2.jpeg test2.git test3.txt test3.jpeg test3.git # 上記の中から特定の拡張子のファイルだけ削除する rm app{1..3}/test{1..3}{.jpeg,.git} ls app2 \u0026gt; test1.txt test2.txt test3.txtt"},{"idx":95,"href":"/docs/container/","title":"Container","content":" コンテナ技術とは  OS上に他のプロセスからは隔離されたアプリケーション実行環境を構築することで, 仮想的な動作環境をより少ないコンピュータリソースで実現する技術のこと. Reference: コンテナ技術とは何？  コンテナとは  コンテンは仮想マシンの一種. コンテナ型仮想化という技術を使っている. 特徴  コンテナの容量が小さい 現実的な速度で, インターネット経由で受け渡しできる. 動作が軽い １つのホストOS上でたくさんのコンテナを動かすことができる.  そしてコンテナが増えすぎたので, 複数のコンテナを管理するコンテナ・オーケストレーションが生み出された.  Reference: Kubernetesってなにそれおいしいの？という人向けの超入門\n"},{"idx":96,"href":"/docs/crypto-docs/","title":"Crypto Docs","content":" 暗号資産の日本語訳ドキュメント  Ethereum: https://github.com/a-mitani/mastering-ethereum Solidity: https://solidity-jp.readthedocs.io/ja/latest/ IPFS: https://github.com/a-mitani/ipfs-primer IOTA: https://docs.iotajapan.com NEM: https://nemtech.github.io/ja/ truffle: https://github.com/ZahanWu/truffle-docs-ja/wiki MakerDao: https://github.com/makerdao/community/tree/master/faqs/ja  "},{"idx":97,"href":"/docs/crypto/","title":"Crypto","content":" 暗号通貨/暗号資産とは  暗号技術を用いた通貨/資産のこと.  "},{"idx":98,"href":"/docs/css/","title":"Css","content":" CSSとは  ウェブページのスタイルを指定するための言語. Cascading Style Sheetsの略.  Bootstrap  Webアプリケーションフレームワークの1つ.  グリッドシステム Reference: Bootstrapのグリッドシステムの使い方を初心者に向けておさらいする\n\u0026lt;div class=\u0026#34;contaiiner\u0026#34;\u0026gt; /* 固定枠 */ \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; /* row枠 */ \u0026lt;div class=\u0026#34;col-xs-12\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; /* スマホ枠 */ \u0026lt;div class=\u0026#34;col-sm-12\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; /* タブレット枠 */ \u0026lt;div class=\u0026#34;col-md-12\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; /* PC枠 */ \u0026lt;div class=\u0026#34;col-lg-12\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; /* PC大枠 */ \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Reference: Bootstrapのグリッドシステムについてまとめてみた\n"},{"idx":99,"href":"/docs/docker-compose/","title":"Docker Compose","content":" Docker Composeとは  複数のコンテナで構成されるアプリケーションを定義と実行するためのツールのこと. Dockerとは切り離されてる. Composeはアプリケーションのサービスをファイルで定義する. Dockerコマンドと高い親和性があるため, 学習コストが比較的低い. Swarmモードにサービスをデプロイできるオーケストレーション機能もある.  Reference: Docker Compose 徹底解説  GitHubリポジトリ: https://github.com/docker/compose  活用場面  利用者視点  docker-compose.ymlがあれば, すぐに何でも実行できる.  開発者視点  環境の再構築が簡単 バージョン違いの環境を作りやすい 1つのマシン上に, 複数の環境を立ち上げられやすい   適切に書かれたYAMLファイルさえあれば, 誰でも簡単に環境構築もアプリケーション実行もできるのが強み.\nインストール  https://docs.docker.com/compose/install/  docker-compose.ymlの書き方  services:(使うイメージ), networks:(使うネットワーク), volumes:(使うボリューム)を定義する. docker-compose.ymlの書き方 -\u0026gt; Docker Compose - docker-compose.yml リファレンス  公式Reference  Compose file version 3 reference  working directory指定 working_dirを使う.\nversion: \u0026#39;3\u0026#39; services: angular: image: angular-first-app ports: - \u0026#34;4200:4200\u0026#34; volumes: - .:/usr/src/app working_dir: /usr/src/app/first-app command: ng serve --host=0.0.0.0 起動と停止 # 起動 docker-compose up # ビルドして起動 docker-compose up --build # バックグラウンドで起動 docker-compose up -d # 停止 docker-compose down # ボリュームも削除しつつ停止 docker-compose down -v nginxとhttpd docker-composeを以下の様に書く.\n# docker-compose.yml version: \u0026#39;3\u0026#39; services: proxy: image: nginx:latest # this will use the latest version of 1.13.x ports: - \u0026#39;80:80\u0026#39; # expose 80 on host and sent to 80 in container volumes: - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro web: image: httpd:latest # this will use httpd:latest nginx.confを以下の様に書く.\n# nginx.conf server { listen 80; location / { proxy_pass http://web; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Host $server_name; } } そして, 以下を実行する.\ndocker-compose up -d # デーモンでコンテナ群を起動 docker-compose ps # 動いてるコンテナ一覧が見られる \u0026gt; Name Command State Ports \u0026gt; ---------------------------------------------------------------------------- \u0026gt; compose-sample-2_proxy_1 nginx -g daemon off; Up 0.0.0.0:80-\u0026gt;80/tcp \u0026gt; compose-sample-2_web_1 httpd-foreground Up 80/tcp docker-compose down # コンテナ群を停止する コード例: solareenlo/udemy-docker-mastery/compose-sample-2\nDrupalとPostgreSQL docker-compose.ymlに以下を記述する.\n# Drupal with PostgreSQL # # Access via \u0026#34;http://localhost:8081\u0026#34; # (or \u0026#34;http://$(docker-machine ip):8081\u0026#34; if using docker-machine) # # During initial Drupal setup, # Database type: PostgreSQL # Database name: postgres # Database username: postgres # Database password: passwd # ADVANCED OPTIONS; Database host: postgres # ADVANCED OPTIONS; Database port: 5432 version: \u0026#39;3.7\u0026#39; services: drupal: image: drupal:8-apache ports: - 8081:80 volumes: - drupal-modules:/var/www/html/modules - drupal-profiles:/var/www/html/profiles - drupal-themes:/var/www/html/themes - drupal-sites:/var/www/html/sites restart: always postgres: image: postgres:10 environment: POSTGRES_PASSWORD: passwd restart: always volumes: drupal-modules: drupal-profiles: drupal-themes: drupal-sites: そして, 起動する.\ndocker-compose up -d # DrupalとPostgreSQLを起動 docker-compose ps # 起動してるか確認 \u0026gt; Name Command State Ports \u0026gt; ----------------------------------------------------------------------------------------------- \u0026gt; compose-assignment-1_drupal_1 docker-php-entrypoint apac ... Up 0.0.0.0:8081-\u0026gt;80/tcp \u0026gt; compose-assignment-1_postgres_1 docker-entrypoint.sh postgres Up 5432/tcp 任意のブラウザでlocalhost:8081を開くとDrupalが立ち上がってる.\n設定値は以下.\nDatabase type: PostgreSQL Database name: postgres Database username: postgres Database password: passwd ADVANCED OPTIONS; Database host: postgres ADVANCED OPTIONS; Database port: 5432 そして, 停止する.\ndocker-compose down -v # volumeも一緒に削除. コード例: solareenlo/udemy-docker-mastery/compose-assignment-1\nNode.jsとRedix docker-compose.ymlに以下の様に書く.\n# docker-compose.yml version: \u0026#39;3\u0026#39; services: redis-server: image: \u0026#39;redis\u0026#39; node-app: build: . ports: - \u0026#34;8082:8082\u0026#34; Dockerfileに以下の様に書く.\n# Dockerfile FROMnode:alpine WORKDIR\u0026#39;/app\u0026#39; COPY package.json . RUN npm install COPY . . CMD[\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] そして, 以下の様に実行する.\ndocker-compose up -d # 任意のブラウザでlobalhost:8082を訪れると訪問回数を表示するサイトが表示される docker-compose down コード例: solareenlo/visits-docker-nodejs\n複数のイメージを作る Dockerfileからカスタムnginxイメージを作成しつつ, カスタムnginxコンテナとhttpdコンテナを動かしている.\ngit clone git@github.com:solareenlo/udemy-docker-mastery.git cd udemy-docker-mastery/compose-sample-3 docker-compose.ymlの中身は以下.\nversion: \u0026#39;2\u0026#39; services: proxy: build: context: . dockerfile: nginx.Dockerfile image: custom-nginx ports: - \u0026#39;80:80\u0026#39; web: image: httpd volumes: - ./html:/usr/local/apache2/htdocs/ カスタムnginxのnginx.Dockerfileの中身は以下.\nFROMnginx:1.13 COPY nginx.conf /etc/nginx/conf.d/default.conf nginx.confの中身は以下.\nserver { listen 80; location / { proxy_pass http://web; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Host $server_name; } } webコンテナで使っているhtmlディレクトリの中身はhttps://startbootstrap.com/template-overviews/agency/です.\nそして, 起動する.\ndocker-compose up -d localhost:80を開くとサイトが見られる.\nそして, 停止する.\ndocker-compose down --rmi local コード例: solareenlo/udemy-docker-mastery/compose-sample-3\ndockerfileでカスタムイメージを作成しつつdocker-composeで動かす Dockerfileに下記を記入する.\nFROMdrupal:8-apache RUN apt-get update \u0026amp;\u0026amp; apt-get install -y git \\  \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* WORKDIR/var/www/html/themes RUN git clone --branch 8.x-3.x --single-branch --depth 1 https://git.drupal.org/project/bootstrap.git \\  \u0026amp;\u0026amp; chown -R www-data:www-data bootstrap WORKDIR/var/www/html docker-compose.ymlに下記を記入する.\n# Drupal with PostgreSQL # # Access via \u0026#34;http://localhost:8081\u0026#34; # (or \u0026#34;http://$(docker-machine ip):8081\u0026#34; if using docker-machine) # # During initial Drupal setup, # Database type: PostgreSQL # Database name: postgres # Database username: postgres # Database password: passwd # ADVANCED OPTIONS; Database host: postgres # ADVANCED OPTIONS; Database port: 5432 version: \u0026#39;3.7\u0026#39; services: drupal: image: custom-drupal build: . ports: - 8081:80 volumes: - drupal-modules:/var/www/html/modules - drupal-profiles:/var/www/html/profiles - drupal-themes:/var/www/html/themes - drupal-sites:/var/www/html/sites restart: always postgres: image: postgres:10 environment: POSTGRES_PASSWORD: passwd volumes: - drupal-data:/var/lib/postgresql/data restart: always volumes: drupal-modules: drupal-profiles: drupal-themes: drupal-sites: drupal-data: そして, 下記を実行する.\ndokcer-compose up -d すると, 任意のブラウザでlocalhost:8081を開くとDrupalが走っていて,\n設定値は以下を入力して,\nDatabase type: PostgreSQL Database name: postgres Database username: postgres Database password: passwd ADVANCED OPTIONS; Database host: postgres ADVANCED OPTIONS; Database port: 5432 ページのテーマをDockerfileで設定してダウンロードしてきたBootstrapに変えてみる.\n停止するには,\ndocker-compose down コード例: solareenlo/udemy-docker-mastery/compose-assignment-2\nテストを行う 以下のようにdocker-compose.ymlにtests項目を追加する.\n# docker-compose.ymlの中身 version: \u0026#39;3\u0026#39; services: web: build: context: . dockerfile: Dockerfile.dev ports: - \u0026#34;3001:3000\u0026#34; volumes: - /app/node_modules - .:/app tests: build: context: . dockerfile: Dockerfile.dev volumes: - /app/node_modules - .:/app command: [\u0026#34;npm\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;test\u0026#34;]# Dockerfile.devの中身 FROMnode:alpine WORKDIR\u0026#39;/app\u0026#39; COPY package.json . RUN npm install COPY . . CMD[\u0026#34;npm\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;start\u0026#34;] そして, 以下でビルドし, 実行する.\ndocker-compose up --build テスト用のコードを変更すると, 標準出力で結果が出てくる.\nコード例: frontend-docker-react\n環境変数 以下のようにvariabeleName=valueと書けばコンテナの中で有効な環境変数になる.\nenvironment: - REDIS_HOST=redis - REDIS_PORT=6378 以下のようにvariableNameとだけ書けばホストから環境変数を取ってきてコンテナの中で有効な環境変数になる.\nenvironment: - REDIS_HOST  Referece:  Docker-Compose の変数定義について   volumes 以下のようにパスをvolumesに指定するとボリュームとしてマウントしてくれる.\nvolumes - /path/to/filename 以下のようにホストのパス:コンテナのパスと書くとホストをマウントしてくれる.\nvolumes - host/path:./path/to/test  References:  Docker、ボリューム(Volume)について真面目に調べた Docker Compose - docker-compose.yml リファレンス   AWSで動かした例  solareenlo/complex-docker  Node.jsを動かした例  BretFisher/node-docker-good-defaults  "},{"idx":100,"href":"/docs/docker-hub/","title":"Docker Hub","content":" Docker Hubとは  コンテナイメージをビルドしたり配布したりする場所. 公式サイト: https://hub.docker.com  配布方法 イメージをそのままpush # 先ずはDocker Hubにログインする docker login # 自分の名前でtag付けしてイメージを作成する docker image build -t solareenlo/test . # そして, Docker Hubにpushする docker push solareenlo/test GitHubからDockerfileをpush "},{"idx":101,"href":"/docs/docker1/","title":"Docker1","content":" Dockerとは  コンテナ型の仮想環境を作成, 配布, 実行するためのプラットフォームのこと. プロセスを簡単にコンテナ化(isolate)し, 簡単かつ素早く開発・移動・実行できるプラットフォームのこと.\n Dockerコンテナは実行に必要な全てをパッケージして簡単に動かせる\n Dockerイメージは複数のイメージ・レイヤとメタ情報の積み重なりからできている.\n コンテナのプロセスはデフォルトでisolate(隔離・分離)された状態\n Dockerについての良い読み物1→2018年なぜ私達はコンテナ/Dockerを使うのか. Dockerについての良い読み物2→標準化が進むコンテナとサーバーレス！ 「提供したい価値」から見極める活用の勘所とは【デブサミ2018 福岡】 Dockerについての良い説明→いまさらDockerに入門したので分かりやすくまとめます Dockerについての良いスライド→Docker Compose 徹底解説  公式サイト: https://www.docker.com\n  Dockerのメリット/デメリット メリット  ゲストOSはホストのKernelを直接使うためオーバーヘッドが小さくて高速 ゲストOSがそれぞれにKernelを持たないため, Memory消費量やDisk消費量を節約できる 必要とする資源が少ないため, 多くのゲストOSを立ち上げることが可能 Kernelを新しく起動する必要がないため, ゲストOSの起動が速い コンテナのイメージ(雛形)からコンテナ(実体)を作るため, 同一構成のOSを簡単に複数作れる テストが通ったイメージは本番環境でもすぐに使える(開発とデプロイのサイクルが速い)  Reference: Dockerの利点   デメリット  提供できるホストの種類が少ない(ホストOSのKernelにLinux使ってたらゲストOSのKernelにWindows Serverは使えない) 完全仮想化に比べて, 管理者が学ぶべきことが多い  Reference: Dockerの欠点   なぜrootユーザーか Dockerはroot権限で動いているデーモン(dockerd)とunixソケットまたはtcp/ipで通信しているが, dockerdにアクセスするにはdockerグループに所属しているかroot権限が必要. そしてdockerはroot無しでアクセスできる様にすると簡単に権限昇格ができてしまい, いろんなことができる様になってしまうから.\nReference: Dockerでユーザーをdockerグループに追加することの危険性を理解しよう\nインストール方法 Linux編 curl -fsSL get.docker.com -o get-docker.sh sh get-docker.sh 基本的な使い方(v18.09.5) Reference: Dockerコマンドメモ\ncontainer DockerでHello World! docker container run --rm alpine /bin/echo \u0026#39;Hello World!\u0026#39; \u0026gt; Hello World! コンテナを起動/停止/再起動 `docker run` = `docker create` + `docker start`sudo docker container run nginx // 起動 sudo docker container run -d nginx // デーモンとして起動 sudo docker container stop \u0026lt;CONTAINERID か NAMES\u0026gt; // 停止 sudo docker container start \u0026lt;CONTAINERID か NAMES\u0026gt; // 再起動 一覧/log表示 sudo docker container run --publish 80:80 --name webhost nginx // nginxを起動 sudo docker container run --publish 80:80 --detach --name webhost nginx // デーモンとして起動 sudo docker container ls // 起動しているコンテナ一覧表示 \u0026gt; CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES \u0026gt; b6e083217819 nginx \u0026#34;nginx -g \u0026#39;daemon of…\u0026#34; 7 minutes ago Up 23 seconds 0.0.0.0:80-\u0026gt;80/tcp webhost \u0026gt; 9ea87fb8e2e1 mongo \u0026#34;docker-entrypoint.s…\u0026#34; 10 hours ago Up 10 hours 27017/tcp mongo sudo docker container logs \u0026lt;CONTAINERID か NAMES\u0026gt; // 指定したコンテナのlogを表示 sudo docker container ls -a // コンテナの一覧を表示 sudo docker container ls -aq // コンテナIDだけ表示 コンテナの状態を見る sudo docker container top \u0026lt;CONTAINERID or NAMES\u0026gt; // コンテナが実行しているプロセスを表示 sudo docker container inspect \u0026lt;CONTAINERID or NAMES\u0026gt; // コンテナの詳細を表示 sudo docker cotnainer stats \u0026lt;CONTAINERID or NAMES\u0026gt; // コンテナのパフォーマンスを表示 コンテナを動かす runコマンドを使う.\n// mysqlを使う sudo docker container run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=ture mysql // mysqlを動かす 対話型モードでコンテナを動かす -itオプションを使う.\n -t: ホスト側の入力をコンテナの標準出力をつなげる -i: キーボードから入力した文字はコンテナ内のプロセスに送られる  sudo docker container run -it ubuntu /bin/bash // ubuntuを動かす apt install curl -y curl https://google.lcom \u0026gt; \u0026lt;HTML\u0026gt;\u0026lt;HEAD\u0026gt;\u0026lt;meta http-equiv=\u0026#34;content-type\u0026#34; content=\u0026#34;text/html;charset=utf-8\u0026#34;\u0026gt; \u0026gt; \u0026lt;TITLE\u0026gt;301 Moved\u0026lt;/TITLE\u0026gt;\u0026lt;/HEAD\u0026gt;\u0026lt;BODY\u0026gt; \u0026gt; \u0026lt;H1\u0026gt;301 Moved\u0026lt;/H1\u0026gt; \u0026gt; The document has moved \u0026gt; \u0026lt;A HREF=\u0026#34;https://www.google.com/\u0026#34;\u0026gt;here\u0026lt;/A\u0026gt;. \u0026gt; \u0026lt;/BODY\u0026gt;\u0026lt;/HTML\u0026gt; Alpineを動かす Alpineは軽量なLinux distributionの1つ.\nsudo docker container run -it alpine /bin/ash apk add curl curl https://google.com コンテナの停止とともにコンテナ削除 --rmオプションを使う.\nsudo docker container run --rm -it alpine /bin/ash コンテナを一度に停止する -qオプションで起動しているコンテナIDを取得し, バッククォートで引数として渡す.\nsudo docker container stop `sudo docker container ls -q` コンテナを一度に削除する -aqオプションで存在するコンテナIDを取得し, バッククォートで引数として渡す.\nsudo docker container rm `sudo docker container ls -aq` 起動しているコンテナに入る execコマンドを使う.\nsudo docker container exec -it コンテナ名 portを指定してnginxを起動する sudo docker container run -p 80:80 --name webhost nginx // 80:80の順番はHOST:CONTAINERの順番になっている. sudo docker container port webhost // portの繋がりがどうなっているか確認 \u0026gt; 80/tcp -\u0026gt; 0.0.0.0:80 sudo docker container inspect --format \u0026#39;{{ .NetworkSettings.IPAddress }}\u0026#39; webhost // webhostのIPアドレスを表示 \u0026gt; 172.17.0.2 network ネットワークを新規に作って接続して削除する sudo docker network ls \u0026gt; NETWORK ID NAME DRIVER SCOPE \u0026gt; bc9b26e5c4d9 bridge bridge local \u0026gt; ba4557f6a2be host host local \u0026gt; 5ac181d8a48b none null local  bridge: Linux bridgeで仮想インタフェースを作成し, そのインタフェースに対してvethでDockerコンテナと接続する方式で, Dockerホストが属するネットワークとは異なる, 仮想bridge上のネットワークにコンテナを作成し, NAT形式で外部のノードと通信する形式. host: Dockerホストと同じネットワークにスタックするドライバで, Dockerホストマシンと同じネットワークインタフェース, IPアドレスを持つようになる. null: ネットワーク接続を必要としないコンテナを作成する場合に使用する.  Reference: Docker network 概論  bridge・hostいずれもインターネット経由でコンテナへのアクセスが可能. bridgeはホストの任意のポートをコンテナのポートにマップすることが出来る. hostはコンテナでexposeされたポートをホストでも利用する. その為一つのホストで同じポートを使うコンテナは利用できない.  Reference: Docker の bridge と host ネットワークについて勉強する   sudo docker network create my_app_net // 新規ネットワークを作成 sudo docker container run -d --name new_nginx --network my_app_net nginx // この新規に作成したネットワークでコンテナを走らせる sudo docker network inspect my_app_net // 新規ネットワークにどのコンテナが接続されているかを確認する sudo docker network connect bridge new_nginx // bridgeネットワークにnew_nginxコンテナを接続する sudo docker network disconnect bridge new_nginx // 先ほど繋いだコンテナの接続を切る  コンテナを起動するデフォルトの設定では外部へのポートは閉じられてる. なので, -pオプションを使って手動で外部とのポートと繋ぐ必要がある.  コンテナからコンテナに問い合わせる 同じネットワーク内にあるコンテナからコンテナへ問い合わせる.\ndocker container run -d --name my_nginx --network my_app_net nginx:alpine sudo docker container exec -it my_nginx ping new_nginx \u0026gt; 64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.060 ms \u0026gt; 64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.069 ms \u0026gt; 64 bytes from 172.18.0.2: seq=2 ttl=64 time=0.093 ms 2個コンテナを立ててDNSラウンドロビンを使ってみる elasticsearchを2つコンテナとして立ててる.\nReference: はじめての Elasticsearch\nsudo docker network create dude // 新規にdudeネットワークを作成 sudo docker container run -d --net dude --net-alias search elasticsearch:2 sudo docker container run -d --net dude --net-alias search elasticsearch:2 sudo docker container ls \u0026gt; CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES \u0026gt; 46d60f6737ca elasticsearch:2 \u0026#34;/docker-entrypoint.…\u0026#34; About a minute ago Up About a minute 9200/tcp, 9300/tcp vigilant_stonebraker \u0026gt; 4bea0ab17400 elasticsearch:2 \u0026#34;/docker-entrypoint.…\u0026#34; About a minute ago Up About a minute 9200/tcp, 9300/tcp determined_archimedes sudo docker container run --rm --net dude alpine nslookup search // dudeネットワークでalpineコンテナを立ち上げて, nslookupでsearchのipアドレスを問い合わせてる \u0026gt; nslookup: can\u0026#39;t resolve \u0026#39;(null)\u0026#39;: Name does not resolve \u0026gt; Name: search \u0026gt; Address 1: 172.19.0.3 search.dude \u0026gt; Address 2: 172.19.0.2 search.dude sudo docker container run --rm --net dude centos curl -s search:9200 | jq // dudeネットワークにcentosコンテナ立ち上げて, curlでsearchのエイリアスの効いたIPアドレスの9200番ポートに問い合わせてる \u0026gt; { \u0026gt; \u0026#34;name\u0026#34;: \u0026#34;Miek\u0026#34;, \u0026gt; \u0026#34;cluster_name\u0026#34;: \u0026#34;elasticsearch\u0026#34;, \u0026gt; \u0026#34;cluster_uuid\u0026#34;: \u0026#34;tf7h0SLXS8Gx6UMxgC7hRg\u0026#34;, \u0026gt; \u0026#34;version\u0026#34;: { \u0026gt; \u0026#34;number\u0026#34;: \u0026#34;2.4.6\u0026#34;, \u0026gt; \u0026#34;build_hash\u0026#34;: \u0026#34;5376dca9f70f3abef96a77f4bb22720ace8240fd\u0026#34;, \u0026gt; \u0026#34;build_timestamp\u0026#34;: \u0026#34;2017-07-18T12:17:44Z\u0026#34;, \u0026gt; \u0026#34;build_snapshot\u0026#34;: false, \u0026gt; \u0026#34;lucene_version\u0026#34;: \u0026#34;5.5.4\u0026#34; \u0026gt; }, \u0026gt; \u0026#34;tagline\u0026#34;: \u0026#34;You Know, for Search\u0026#34; \u0026gt; } sudo docker container run --rm --net dude centos curl -s search:9200 | jq // dudeネットワークにcentosコンテナ立ち上げて, curlでsearchのエイリアスの効いたIPアドレスの9200番ポートに問い合わせてる \u0026gt; { // 2回目は1回目とは違うコンテナに問い合わせてる \u0026gt; \u0026#34;name\u0026#34;: \u0026#34;Mondo\u0026#34;, \u0026gt; \u0026#34;cluster_name\u0026#34;: \u0026#34;elasticsearch\u0026#34;, \u0026gt; \u0026#34;cluster_uuid\u0026#34;: \u0026#34;OoTXK8QASzWdxxEF64iEHA\u0026#34;, \u0026gt; \u0026#34;version\u0026#34;: { \u0026gt; \u0026#34;number\u0026#34;: \u0026#34;2.4.6\u0026#34;, \u0026gt; \u0026#34;build_hash\u0026#34;: \u0026#34;5376dca9f70f3abef96a77f4bb22720ace8240fd\u0026#34;, \u0026gt; \u0026#34;build_timestamp\u0026#34;: \u0026#34;2017-07-18T12:17:44Z\u0026#34;, \u0026gt; \u0026#34;build_snapshot\u0026#34;: false, \u0026gt; \u0026#34;lucene_version\u0026#34;: \u0026#34;5.5.4\u0026#34; \u0026gt; }, \u0026gt; \u0026#34;tagline\u0026#34;: \u0026#34;You Know, for Search\u0026#34; \u0026gt; } image Dockerのイメージは2種類のレイヤ構造になっている.\n 読み込み専用レイヤのイメージレイヤ 読み書き可能なコンテナレイヤ  Dockerはユニオンファイルシステム(複数のファイルシステム上のディレクトリやファイルをレイヤとしてスタックし, それらを仮想的に一つのファイルシステムとして扱う技術)を使い, コンテナを軽量化している. Reference: 知らないと損する Docker イメージのレイヤ構造とは\n一括してimageを削除 docker rmi `docker images -a -q` 一括してimageを最新へ更新 Reference: 一括してDockerイメージを最新にアップデートしたい\nsudo docker images | cut -d \u0026#39; \u0026#39; -f1 | tail -n +2 | sort | uniq | egrep -v \u0026#39;^(\u0026lt;none\u0026gt;|ubuntu)$\u0026#39; | xargs -P0 -L1 sudo docker pull imageをDocker Hubからpull sudo docker pull mysql タグ付けしてpull タグけせずにpullを行うとデフォルトでタグ名がlatestになる.\nタグ付けするときはイメージ名の後ろに「:」を付けて, その後ろにタグ名を指定する.\nsudo docker image pull nginx:mainline 既にあるimageに新たにタグ付けする タグ付けするとDocker Hubにタグ別にどんどんイメージをpushできる.\nタグを変えるだけだと同じイメージが使われる.\nsudo docker image tag nginx solareenlo/nginx Docker Hubにログイン そのままローカル環境からDocker Hubにログインするとパスワードが平文のまま保存されるのでpassなどを使って暗号化して保存する. 保存方法はこらら.\nsudo docker login Docker Hubに自分でタグ付けしたimageをpush sudo docker push solareenlo/nginx Dockerfile Dockerfileを書いてみる  FROM: 元となるイメージを指定する. Docker Hubから引っ張ってくる. ENV: 環境変数を設定できる. RUN: 既存イメージ上の新しいレイヤで, あらゆるコマンドを実行し, その結果をコミットする命令. 一度RUNを抜けるとホームディレクトリからの実行となる. ひたすらコマンドで書く. EXPOSE: コンテナがリッスンするポートを設定できる. これを設定した後コンテナ起動時に-pを使ってポートの公開範囲を指定する必要がある. CMD: 構築時には何もしないが、イメージで実行するコマンドを指定する. 一度だけ実行する. 複数CMDがある場合は一番後ろのものが実行される. \u0026lt;コマンド\u0026gt;をシェルを使わずに実行したい場合, コマンドをJSON配列で記述し, 実行可能なフルパスで指定する必要がある. 配列の形式がCMDでは望ましい形式. あらゆる追加パラメータは個々の配列の文字列として指定する必要がある.  # こんな感じにDockerfileに書いてみる FROMdebian:stretch-slim ENVNGINX_VERSION 1.13.6-1~stretch ENVNJS_VERSION 1.13.6.0.1.14-1~stretch RUN apt-get update \\  \u0026amp;\u0026amp; apt-get install --no-install-recommends --no-install-suggests -y gnupg1 \\  \u0026amp;\u0026amp; \\  NGINX_GPGKEY=573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62; \\  found=\u0026#39;\u0026#39;; \\  for server in \\  ha.pool.sks-keyservers.net \\  hkp://keyserver.ubuntu.com:80 \\  hkp://p80.pool.sks-keyservers.net:80 \\  pgp.mit.edu \\  ; do \\  echo \u0026#34;Fetching GPG key $NGINX_GPGKEYfrom $server\u0026#34;; \\  apt-key adv --keyserver \u0026#34;$server\u0026#34; --keyserver-options timeout=10 --recv-keys \u0026#34;$NGINX_GPGKEY\u0026#34; \u0026amp;\u0026amp; found=yes \u0026amp;\u0026amp; break; \\  done; \\  test -z \u0026#34;$found\u0026#34; \u0026amp;\u0026amp; echo \u0026gt;\u0026amp;2 \u0026#34;error: failed to fetch GPG key $NGINX_GPGKEY\u0026#34; \u0026amp;\u0026amp; exit 1; \\  apt-get remove --purge -y gnupg1 \u0026amp;\u0026amp; apt-get -y --purge autoremove \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* \\  \u0026amp;\u0026amp; echo \u0026#34;deb http://nginx.org/packages/mainline/debian/ stretch nginx\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list \\  \u0026amp;\u0026amp; apt-get update \\  \u0026amp;\u0026amp; apt-get install --no-install-recommends --no-install-suggests -y \\  nginx=${NGINX_VERSION} \\  nginx-module-xslt=${NGINX_VERSION} \\  nginx-module-geoip=${NGINX_VERSION} \\  nginx-module-image-filter=${NGINX_VERSION} \\  nginx-module-njs=${NJS_VERSION} \\  gettext-base \\  \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* RUN ln -sf /dev/stdout /var/log/nginx/access.log \\  \u0026amp;\u0026amp; ln -sf /dev/stderr /var/log/nginx/error.log EXPOSE80 443 CMD[\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] DockerFileからイメージを作成する // Dockerfileのあるディレクトリで以下を実行して新たにイメージを作成する. sudo docker image build -t customnginx . // そして, コンテナを作成し, `localhost:80`にアクセスする. sudo docker container run --rm -p 80:80 --name nginx2 customnginx ローカルにあるファイルをコピーしてイメージを作成する 以下のようにindex.htmlを作って,\n\u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;2番目のDockerfile動いてる!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;ビルド時にカスタムファイルをイメージにコピーして, コンテナを正常に実行できています.\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 以下のようにDokcerfileを作ってみる.\n# Dockerfileはこんな感じ FROMnginx:latest WORKDIR/usr/share/nginx/html COPY index.html index.html そして, イメージを作ってコンテナを走らせて, localhost:80にアクセスすると, 先ほど作ったindex.htmlが表示される.\nsudo docker image build -t nginx-with-html . sudo docker container run -p 80:80 --rm nginx-with-html COPYとADDの違い  COPYはローカルのファイルをイメージのレイヤーにコピーできる. ADDはリモートのファイルもイメージのレイヤーにコピーできる.  WORKDIRで作業ディレクトリを指定する  DockerfileでRUN, CMD, ENTRYPOINT, COPY, ADD命令実行時の作業ディレクトリを指定できる. 複数回の利用が可能で, 複数回利用すると相対パスになる.  WORKDIR/a WORKDIRb WORKDIRc RUN pwd とすると, /a/b/c pwdとなる.\n WORKDIRはENVを使った環境変数も利用できる.  ENVDIRPATH /path WORKDIR$DIRPATH/to RUN pwd とすると, /path/to pwdとなる.\nNode.js用のDockerfileをスクラッチから書いてみる # alpine用のnodeイメージインストールする FROMnode:8.16.0-alpine # コンテナの3000番ポートを開く EXPOSE3000 # tiniをインストールして, 作業ディレクトリを作成する RUN apk add --update tini \\  \u0026amp;\u0026amp; mkdir -p /usr/src/app # 作業ディレクトリに移動する WORKDIR/usr/src/app # package.jsonを作業ディレクトリにコピーする COPY package.json package.json # 作業ディレクトリにnpmパッケージをインストールする RUN npm install RUN npm cache clean --force # コンテナのイメージレイヤーに必要なファイル全てをコピーする COPY . . # tiniでnodeを起動する CMD[\u0026#34;/sbin/tini\u0026#34;, \u0026#34;--\u0026#34;, \u0026#34;node\u0026#34;, \u0026#34;./bin/www\u0026#34;] こんな感んじでDokcerfileを作成する.\nコード例: dockerfile-assignment-1\nそして, イメージをビルドして, コンテナを起動して, localhost:3000にアクセスする.\ndocker image build -t nodetest . docker container run --rm -p 80:3000 nodetest 任意のDockerfileを指定する -fを使う.\ndocker build -f Dockerfile.dev . volume  volumeはDockerが管理するデータ領域(コンテナが消えても残るデータ領域)をコンテナ上にマウントする機能のこと. volumeのデータは/var/lib/docker/volumes配下にある. 設定する方法は-vと--mountの2種類ある. コンテナ内のvolumeにマウントしたらよいpathはhub.docker.comにあるイメージのページのタグのページから探すと良い. 新規ユーザーは--mountを使おう. --mountがkey=value形式で分かりやすいから.  -vを使ってvolumeをmysqlコンテナにマウントする 下記ではDocker内のvolumeという永続的にデータが保管されるところにmysql-dbというディレクトリが作成されて, それがコンテナ内の/var/lib/mysqlに紐付くということ.\ndocker container run -d --name mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=True -v mysql-db:/var/lib/mysql mysql \u0026ndash;mountを使ってvolumeをmysqlコンテナにマウントする --mountは, key=value形式でvolumeの指定をするフラグ.\ndocker container run -d --name mysql2 -e MYSQL_ALLOW_EMPTY_PASSWORD=True --mount type=volume,src=mysql-db2,dst=/var/lib/mysql mysql 2つのコンテナに同じvolumeをマウントする docker container run -d --name psql --mount type=volume,src=psql,dst=/var/lib/postgresql/data postgres:alpine docker container logs -f psql \u0026gt; psqlのlogが標準出力される docker container stop psql docker container run -d --name psql2 --mount type=volume,src=psql,dst=/var/lib/postgresql/data postgres:alpine docker container logs -f psql2 \u0026gt; psql2のlogが出力される docker volume ls \u0026gt; DRIVER VOLUME NAME \u0026gt; local psql bind mount bind mountはDocker外の任意のファイル・ディレクトリをコンテナ内にマウントする機能のこと.\n-vを使ってDocker外のデータをnginxコンテナにマウントする git clone git@github.com:solareenlo/udemy-docker-mastery.git ch udemy-docker-mastery/dockerfile-sample-2 docker container run -d --name nginx -p 80:80 -v $(pwd):/usr/share/nginx/html nginx \u0026ndash;mountを使ってDocker外のデータをnginxコンテナにマウントする git clone git@github.com:solareenlo/udemy-docker-mastery.git ch udemy-docker-mastery/dockerfile-sample-2 docker container run -d --name nginx2 -p 8080:80 --mount type=bind,src=$(pwd),dst=/usr/share/nginx/html nginx そして, nginxの中に入って, Docker外のデータとコンテナがきちんとマウントされてるかどうかを確かめてみる.\ndocker container exec -it nginx /bin/bash cd /usr/share/nginx/html ls -la \u0026gt; drwxr-xr-x 2 1000 1000 4096 Apr 24 16:17 . \u0026gt; drwxr-xr-x 3 root root 4096 Apr 16 21:20 .. \u0026gt; -rw-r--r-- 1 1000 1000 415 Apr 19 17:34 Dockerfile \u0026gt; -rw-r--r-- 1 1000 1000 285 Apr 23 22:54 index.html # 別のターミナルを開いて, コンテナをマウントしたディレクトリでtest.mdを作成すると, ls -la \u0026gt; drwxr-xr-x 2 1000 1000 4096 Apr 25 01:20 . \u0026gt; drwxr-xr-x 3 root root 4096 Apr 16 21:20 .. \u0026gt; -rw-r--r-- 1 1000 1000 415 Apr 19 17:34 Dockerfile \u0026gt; -rw-r--r-- 1 1000 1000 285 Apr 23 22:54 index.html \u0026gt; -rw-rw-r-- 1 1000 1000 0 Apr 25 01:20 test.md # test.mdがきちんと増えてる. ローカルのJekyllをコンテナのJekllサーバで動かす git clone git@github.com:solareenlo/udemy-docker-mastery.git cd udemy-docker-mastery/bindmount-sample-1 docker run -p 80:4000 --mount type=bind,src=$(pwd),dst=/site bretfisher/jekyll-serve \u0026gt; コンテナでJekyllサーバが起動する \u0026gt; Configuration file: /site/_config.yml \u0026gt; Deprecation: The \u0026#39;gems\u0026#39; configuration option has been renamed to \u0026#39;plugins\u0026#39;. Please update your config file accordingly. \u0026gt; Source: /site \u0026gt; Destination: /site/_site \u0026gt; Incremental build: disabled. Enable with --incremental \u0026gt; Generating... \u0026gt; Jekyll Feed: Generating feed for posts \u0026gt; done in 0.261 seconds. \u0026gt; Auto-regeneration: enabled for \u0026#39;/site\u0026#39; \u0026gt; Server address: http://0.0.0.0:4000/ \u0026gt; Server running... press ctrl-c to stop. ブラウザでlocalhost:80にアクセスするとJekyllで作ったサイトが立ち上がってる.\n"},{"idx":102,"href":"/docs/docker2/","title":"Docker2","content":" Docker その2 コンテナの基本的な動かし方 # run = create + start docker run busybox echo hi there \u0026gt; hi there # コンテナ作ってスタートさせる docker create --name my-busybox busybox echo hi there docker start -a my-busybox \u0026gt; hi there # 一定期間後に終了 docker stop CONTAINER_NAME # 直ぐに終了 docker kill CONTAINER_NAME # Image,Container,Volumeの数や容量を表示 docker system df # 止まってるContainer, 使われてないVolume, 使われてないNetwork, 使われてないImageを削除 docker system prune # 現在動いているredisコンテナにアクセスする docker run --name myredis -d redis docker exec -it myredis redis-cli 127.0.0.1:6379\u0026gt; set my-number 5 \u0026gt; OK 127.0.0.1:6379\u0026gt; get my-number \u0026gt; \u0026#34;5\u0026#34; # CTL-Cで終了 # Shell Scriptモードで起動 docker run -it busybox sh / # ping google.com \u0026gt; 64 bytes from 172.217.31.174: seq=0 ttl=51 time=3.399 ms \u0026gt; 64 bytes from 172.217.31.174: seq=1 ttl=51 time=3.672 ms ^C / # echo hello hello / # # こんな感じでbusyboxはシェルスクリプトが使える Dockerfile 公式Reference  Dockerfile reference  書き方  Dockerfile -\u0026gt; Docker Client -\u0026gt; Docker Server -\u0026gt; Imageの流れでイメージが作られる. Dockerfileに書かれてあること1行ずつに対して履歴を取っている.  以下をDockerfileとして保存して,\nFROMalpine RUN apk add --update redis CMD[\u0026#34;redis-server\u0026#34;] 以下でイメージをし,\n# 最後の「.」はDockerfileがある場所を指定している. docker build . \u0026gt; 色々出てくる \u0026gt; Successfully built 8fcebe7331d6 以下でコンテナを走らせる.\ndocker run 8fcebe7331d6 \u0026gt; 色々出てくる Best Practices  ビルド時間 イメージサイズ メンテナンス性/可読性 セキュリティ 持続性/再現性 Reference: DCSF19 Dockerfile Best Practices  タグ付け 以下のようにしてタグ付けを行う.\ndocker build -t solareenlo/redis:latest . 1つずつイメージを作っていく docker run -it alpine sh / # apk add --update redis \u0026gt; インストールされる 別のターミナルを開いて, 以下のようにcommitで新たにイメージを作成する.\ndocker ps \u0026gt; コンテナの情報 docker commit -c \u0026#39;CMD [\u0026#34;redis-server\u0026#34;]\u0026#39; \u0026lt;コンテナのhash値か名前\u0026gt; \u0026gt; sha256: イメージのハッシュ値 docker run イメージのハッシュ値 \u0026gt; 新たに作ったイメージからコンテナが走る Dockerfileの効率的な作り方  ベースにするDockerイメージを決める. docker run -it --name custom-container \u0026lt;元となるdocker image\u0026gt; shでコンテナに入る. コンテナ内で色々インストールしたり, 設定したりする. うまくいったらその内容を1行ずつメモする. いい頃合いで, exitでコンテナからログアウトし, docker commit custom-container solareenlo/custom-image:latestで新しいDockerイメージを作成する. そして, docker attach custom-imageで再度コンテナに入る. 失敗したらexitして, 再度docker run -it solareenlo/custom-image:latest shして, コンテナに入る. ファイルの取り込みやポートの外部公開が必要ならオプション付きでdocker runを行う. 最後に作業内容をDockerfileに書き込む.  Reference: 効率的に安全な Dockerfile を作るには   Node.jsを動かした例 # ベースとなるイメージ FROMnode:alpine # 以降での作業ディレクトリを指定する WORKDIR/usr/app # package.jsonとpackage-lock.jsonを先にコピーする. # package*.jsonだけを先に個別コピーすることで, パッケージ変更時は`RUN npm install`が走るが # それ以外のファイル変更時は同コマンドにはキャッシュ利用で飛ばされるため, ビルド時間を短縮できる. COPY ./package.json ./ RUN npm install COPY ./ ./ # デフォルトのコマンド CMD[\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;]# イメージをビルドする docker build -t solareenlo/simple-docker-nodejs . # コンテナを走らせる docker run -d --name simple-docker-nodejs solareenlo/simple-docker-nodejs # コンテナの中に入る docker exec -it simple-docker-nodejs sh コード例: solareenlo/simple-docker-nodejs\n再起動    オプション 意味     no 再起動しない (デフォルト)   on-failure[:max-retries] プロセスが0以外のステータスで終了した場合, 最大:max_retriesの分だけ再起動を行う.   always 明示的にstopがされない限り, 終了ステータスに関係なく常に再起動を行う.   unless-stopped 最後にdocker daemonが起動していた際にステータスが終了状態だった場合は再起動しない. それ以外はalwaysと同じ.    テストを行う docker build -f Dockerfile.dev -t frontend . docker run -d -p 3000:3000 --name frontend frontend コード例: solareenlo/frontend-docker-react\nReact \u0026gt; Nginx と繋げるのをDockerfileだけで行う Dokcerfileに以下のように書き込む.\nFROMnode:alpine as builder WORKDIR\u0026#39;/app\u0026#39; COPY package.json . RUN npm install COPY . . RUN npm run build FROMnginx COPY --from=builder /app/build /usr/share/nginx/html そして,\ndocker build -t nginx-react . 1つ目のFROMでReactのイメージができ, 2つ目のFROMでReactの結果を引き継いだNginxのイメージができる. そして, 以下でコンテナを走らせる.\ndocker run -p 3001:80 nginx-react コード例: frontend-docker-react\nTravis CIに繋げてテストを実行 Travisにアカウントを作成して, GitHubと連携して, リポジトリを登録して, 登録したリポジトリの.travis.ymlに以下を書き込む.\nsudo: required services: - docker before_install: - docker build -t solareenlo/frontend-docker-react -f Dockerfile.dev . script: - docker run -e CI=true solareenlo/frontend-docker-react npm run test -- --watchAll=false そして, GitHubにpushすると自動的にtestが行われる.\nコード例: solareenlo/frontend-docker-react\nDockerfile(React, Nginx) \u0026gt; GitHub \u0026gt; Travis CI \u0026gt; AWS Elastic Beanstalkとデプロイする 大まかな流れ\n npm install -g create-react-appでcreate-react-appをインストールして簡単なページを作成する. 上記のDokerfileを作成する. こんな感じ.\nFROMnode:alpine as builder WORKDIR\u0026#39;/app\u0026#39; COPY package.json . RUN npm install COPY . . RUN npm run build FROMnginx EXPOSE80 COPY --from=builder /app/build /usr/share/nginx/html GitHub, Travis CI, AWSでそれぞれアカウントを作成する.\n GitHubにコードを1度pushする.\n AWSElastic BeanstalkでDocker(React, Nginx)用のwebアプリケーションの基盤を作成する.\n Elastic Beanstalkで作ったwebアプリケーションのファイルを保存しておくためのストレージをAWSのS3を使って作成する.\n Elastic BeanstalkにアクセスするためのアクセスキーとシークレットキーをAWSのIAMを使って作成・保存する.\n Travis CIでAWSのアクセスキーとシークレットキーを設定をする.\n .travis.ymlを作成する. こんな感じ.\nsudo: required services: - docker before_install: - docker build -t solareenlo/frontend-docker-react -f Dockerfile.dev . script: - docker run -e CI=true solareenlo/frontend-docker-react npm run test -- --watchAll=false deploy: provider: elasticbeanstalk region: \u0026#34;us-east-1\u0026#34; app: \u0026#34;frontend-docker-react\u0026#34; env: \u0026#34;FrontendDockerReact-env\u0026#34; bucket_name: \u0026#34;elasticbeanstalk-us-east-1-998768475306\u0026#34; bucket_path: \u0026#34;frontend-docker-react\u0026#34; on: branch: master access_key_id: $AWS_ACCESS_KEY secret_access_key: secure: \u0026#34;$AWS_SECRET_KEY\u0026#34; ローカルのソースコードをGitHubにpushする. 全ての連携が上手くできていれば, GitHubのpushを感知して, Travis CIでビルドとテストが行われ, テストがOKならAWSのElastic Beanstalkに自動でデプロイされ, 規定のURLにReactのサイトが表示される.\n 出来たサイト: http://frontenddockerreact-env.fbdmefkujd.us-east-1.elasticbeanstalk.com\n  コード例: solareenlo/frontend-docker-react\n"},{"idx":103,"href":"/docs/ethereum/","title":"Ethereum","content":" Ethereumとは GitHubリポジトリ: https://github.com/ethereum\n目的 ブロックチェーン上でアプリを動かして, スマートコントラクトを実行できるようにし, 経済をさらに発展させる.\nアプリの特徴: 分散型, 管理者不在, 一度デプロイすると修正不可\n特徴  分散型アプリケーション(スマートコントラクト)のプラットフォーム 各ノードにバーチャルマシーン(通称: EVM)を積んでいるのでチューリング完全なスクリプトがEthereum上で書ける. アカウントベース ブロックチェーン2.0の代表格  スケーリング方法  サイドチェーン  Plasma: Ethereumのメインチェーンとは別のプラズマチェーンと呼ばれるサイドチェーンをマークル木状にどんどん連ねることで, メインチェーンに格納される情報量を減少させる仕組み. エンドユーザーが出金したいときはルートチェーンに問い合わせる. 初心者向けプラズマ勉強法まとめノートー 0から3週間で学んだこと lightningとplasmaってなにが違うんですか？ Plasma スケーラブルな自律型スマートコントラクト  オフチェーン  Raiden Network: ブロックチェーン内の処理をブロックチェーンの外側に持っていくことで, メインチェーンの負担を軽減する仕組み. 最終的な取引結果のみをブロックチェーンで処理する.  シャーディング  トランザクション処理を各ノードで分割して行うことで, 処理速度の向上を図る仕組み. Ethereum2.0のCasperで導入されるPoSと相性が良い. Ethereumのシャーディング概論   スマートコントラクトとは  何人かが合意した内容（契約）を、ヒトがいなくても自動的に実行する仕組み  例は自動販売機   Ethereum dapps開発七つ道具  Solidity MetaMask Truffle, Ganache web3.js OpenZepplien Remix Google翻訳  と, 上記の内容を広く浅く説明してくれてるサイト\n EthereumとContracts開発を取り巻くエコシステムの概要  gethの使い方 gethとはGoで実装された完全なethereumノードを実行するためのコマンドラインインターフェースのこと.\n# gethのインストール # for Mac brew tap ethereum/ethereum brew install ethereum# ジェネシスブロックの生成の様式を作成 cd mkdir ethereum cd ethereum mkdir privnet cd privnet touch genesis.json # 以下をgenesis.jsonの中に書き込む { \u0026#34;config\u0026#34;: { \u0026#34;chainId\u0026#34;: 4649 }, \u0026#34;nonce\u0026#34;: \u0026#34;0x0000000000000042\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;0x0\u0026#34;, \u0026#34;parentHash\u0026#34;: \u0026#34;0x0000000000000000000000000000000000000000000000000000000000000000\u0026#34;, \u0026#34;extraData\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;gasLimit\u0026#34;: \u0026#34;0x8000000\u0026#34;, \u0026#34;difficulty\u0026#34;: \u0026#34;0x4000\u0026#34;, \u0026#34;mixhash\u0026#34;: \u0026#34;0x0000000000000000000000000000000000000000000000000000000000000000\u0026#34;, \u0026#34;coinbase\u0026#34;: \u0026#34;0x3333333333333333333333333333333333333333\u0026#34;, \u0026#34;alloc\u0026#34;: {} }# ジェネシスブロックを生成 geth --datadir ~/ethereum/privnet init ~/ethereum/privnet/genesis.json# ログを書き込むファイルを作成 cd cd ethereum/privnet touch geth.log# gethの起動の仕方 geth --networkid 4649 --nodiscover --datadir ~/ethereum/privnet --rpc --rpccorsdomain \u0026#34;*\u0026#34; console 2\u0026gt;\u0026gt; ~/ethereum/privnet/geth.log で, gethを起動しつつ, --rpcと--rpccorsdomainで, localhostに繋ぐ許可を出しつつ, consoleで対話型にしつつ, \u0026gt;\u0026gt; geth.logでlogをgeth.logファイルに出力している.\nそして, 別ターミナルを開いて,\n# logの見方 tail -f geth.log で, そのターミナルでlogを表示する.\n# アカウント作成する personal.newAccount(\u0026#34;passwd\u0026#34;) # アカウントを確認する eth.accounts # マイニングするノードを確認 eth.coinbase # etherの採掘スタート miner.start() # etherの採掘ストップ miner.stop() # ブロック高確認 eth.blockNumber # ブロックしてるか確認 eth.mining # ハッシュレート確認 eth.hashrate # ブロック内容確認 eth.getBlock(0) # 残高確認 eth.getBalance(eth.accounts[0]) # ロック解除 personal.unlockAccount(eth.accounts[0]) # 送金 eth.sendTransaction({from: eth.accounts[0], to: eth.accounts[1], value: web3.toWei(3, \u0026#34;ether\u0026#34;)})# solidityコードをコンパイル solc --bin --abi hello_world.sol # --bin でバイトコード生成. # --abi でabi(コントラクトとトランザクションで通信する際に必要な情報を全て格納したもの)を生成. Remixの使い方 Remixとはブラウザ上で動作するSolidityの統合開発環境（IDE）のこと.\n https://remix.ethereum.org  truffleの使い方  truffleで使うsolidityのバージョンを変えるにはtruffle-config.jsの中のcompilersのsolcのversionを変更すれば良い.  Batch Over Flow を体験してみる  ERC20のバグと誤報されたBatchOverFlowを体験してみる  Ethereumのハッキングの練習  The Ethernaut byZeppelin  オンラインでsolidityを学ぶ  CryptoZombies Zastrin ChainShot openberry Webのインターフェイスでブロックチェーンのプログラミングを学べる学習サイト5選 動画で学ぶブロックチェーン】Ethereumのスマートコントラクト開発入門 - 谷口耕平氏  "},{"idx":104,"href":"/docs/firebase/","title":"Firebase","content":" Firebaseとは  GCPのmobile Backend as a Service (mBaaS)のこと. GitHubリポジトリ: https://github.com/firebase/  ハンズオン  web Android iOS  ハンズオンプレゼン資料  Firebase Hands-on  良いところ  AUTHが自動. クライアントから直に呼べる. スケジューラが出てきた.  悪いところ  クエリができない. ので, 別のところでDBの検索をしてる. ローカルで動かせない.  "},{"idx":105,"href":"/docs/gcp/","title":"Gcp","content":" Google Cloud Platform(GCP)とは  Gogleが提供するパブリッククラウドコンピューティングのこと.  GKE  コンテナ化されたアプリケーションをデプロイするためのマネージド型の本番環境のこと. Google Kubernetes Engineの略.  Cloud Shell  ブラウザでShellが扱える. 右上のメニューに起動するためのボタンがある.  # 使うプロジェクトの設定 gcloud config set project \u0026lt;プロジェクトID\u0026gt; # 使うゾーンの設定 gcloud config set compute/zone asia-east1-c # 使うコンテナクラスタを設定 gcloud container clusters get-credentials \u0026lt;クラスタ名\u0026gt;"},{"idx":106,"href":"/docs/git/","title":"Git","content":" Gitとは  プログラムのソースコードなどの変更履歴を記録・追跡するための分散型バージョン管理システムのこと. 公式サイト: https://git-scm.com  gitの構成  作業ディレクトリ ステージングエリア（インデックス） リポジトリ（ローカル, リモート）  git補完 Reference: 「Git補完をしらない」「git statusを1日100回は使う」そんなあなたに朗報【git-completionとgit-prompt】\ngit-completion.bashをインストール git-completion.bash: gitコマンドの補完スクリプト. Tabで保管できる.\nwget https://raw.githubusercontent.com/git/git/master/contrib/completion/git-completion.bash -O ~/.git-completion.bash chmod a+x ~/.git-completion.bash echo \u0026#34;source ~/.git-completion.bash\u0026#34; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc git-prompt.shのインストール git-prompt.sh: プロンプトに各種追加情報を表示可能にするスクリプト.\nwget https://raw.githubusercontent.com/git/git/master/contrib/completion/git-prompt.sh -O ~/.git-prompt.sh chmod a+x ~/.git-prompt.sh 下記を一度にコピペしてエンターをして,\ncat \u0026lt;\u0026lt; EOF | tee -a ~/.bashrc \u0026gt; /dev/null source ~/.git-prompt.sh GIT_PS1_SHOWDIRTYSTATE=true GIT_PS1_SHOWSTASHSTATE=true GIT_PS1_SHOWUNTRACKEDFILES=true GIT_PS1_SHOWUPSTREAM=\u0026#34;auto\u0026#34; GIT_PS1_SHOWCOLORHINTS=true EOF 下記を実行する.\nsource ~/.bashrc branch local branchから新branch作成 cd ディレクトリ # 作業ディレクトリに移動 git branch -a # branchの一覧を表示 git checkout master # master branchに切り替え git checkout -b 作成するbranch名 # masterを元にして新しいbranchを作成 git branch -a git push -u origin 作成したbranch名 # branchをremoteに登録 リモートbranchから新branch作成 cd ディレクトリ git checkout -b ローカルに作成するbranch名 origin/再生元のリモートbranch名 git branch -a branchの削除 cd 作業ティレクトり git checkout -b master # 削除したいbranchとは違うbranchにまずは移動する git branch --delete 削除したいbranch名 # mergeしたbranchを削除 git branch -D 削除したいbranch名 # mergeしたかどうかは問わずに削除 remote remoteから特定のbranchを指定してcloneする git clone -b japanese git@github.com:solareenlo/documentation.git remote branch削除 git push --delete origin \u0026lt;branch name\u0026gt; # リモートブランチがローカルに残っている場合は以下も行う git fetch --prune commit 一時的に過去のcommitに戻る # 戻りたいcommitのhash値を探す git log --oneline # 過去に戻る git checkout \u0026lt;commit hash\u0026gt; # 元に戻す git checkout -f master Reference: 9. 一時的に過去のコミットに戻る\nsubmodule submoduleの追加 git submodule add -b \u0026lt;リンク付けする方のbranch名\u0026gt; \u0026lt;リンク付けする方のURL\u0026gt; \u0026lt;リンク付けされるディレクトリ名\u0026gt; # 例 git submodule add -b master git@github.com:solareenlo/hugo-book.git themes/book submoduleの削除 # コミットの参照を削除 git submodule deinit themes/book # .gitmodulesから削除 git rm themes/book submoduleも一緒にclone git clone --recurse-submodules \u0026lt;アドレス\u0026gt; submoduleのcloneをし忘れたら git clone \u0026lt;アドレス\u0026gt; cd \u0026lt;ディレクトリ名\u0026gt; git submodule update --init --recursive submoduleの更新  submodule側で更新して, pushする. 取り込む側でpullする. 取り込む側でgit submodule updateする.  fork fork元の更新を取り込む 対象のリポジトリをforkして, ローカルにcloneしているものとする.\ngit remote add upstream git@github.com:alex-shpak/hugo-book.git git fetch upstream git checkout master git merge --ff upstream/master git push origin master 基本操作 gitの設定 # ユーザー名を登録 git config --global user.name \u0026#34;solareenlo\u0026#34; # メールアドレスを登録 git config --global user.email \u0026#34;solareenlo@test.com\u0026#34; # 色づける git config --global color.ui true # commitしたときのエディタをvimに設定する git config --global core.editor vim # 設定一覧を見る git config -l # helpを見る git config --help # 大文字・小文字を区別する git config --global core.ignorecase false git config --system core.ignorecase false commit # gitの初期化 git init # 作業ディレクトリからステージングエリアへ git add index.html # ステージングエリアからリポジトリへ git commit # 変更のlogを見る git log log # logをコンパクトに見る git log --oneline # logと共に変更内容も見る git log -p # どのファイルが変更なったかを見る git log --stat 現在の状態を把握する # 現在の状態を見る git status # ファイルの変更を無かったことにする git checkout -- index.html 差分を確認する # ファイルの差分を見る git diff # ステージングされたファイルの差分を見る git diff --cached gitでのファイル操作 # 現在のディレクトリ以下全部のファイルをaddする git add . # gitでのファイル削除 git rm index.html # gitでのファイル移動 git mv index.html gitの管理に含めない方法 # .gitignoreファイルを作り, その中にgitに含めないファイルを記述する vim .gitignore *.log # .gitignoreがある場所から遡ってはignoreされない. # ので, サブディレクトリだけ.gitignoreしたい場合は, サブディレクトリ内に.gitignoreを入れておく. 直前のcommitを変更 # 1つcommitする git commit -m \u0026#39;コミットを1つ追加\u0026#39; # 直前のcommitを上書きする vim index.html git add . git commit --amend 過去のバージョンに戻る（１） # 作業ディレクトリもステージングエリアも直前のcommitへ戻す git reset --hard HEAD # 2つ前のcommitに戻る git reset --hard HEAD^ # 指定したidにcommitを戻す git reset --hard hash値(最低7桁) 過去のバージョンに戻る（２） # commit変更したけど, やっぱり変更前のcommitに戻りたいときは git reset --hard ORIG_HEAD # ORIG_HEADには前回取り消されたHEADの情報が1つだけ入っている. branch # 現在のbranchを確認する git branch # 新しいbranch hogeを作成する git branch hoge # hoge branchに移動する git checkout hoge git branch # master branchに戻る git checkout master git branch branchをmerge # master branchにhoge branchをmergeさせたい git checkout master git merge hoge # いらなくなったhoge branchを削除する git branch -d hoge # masterにmerge済みのbranchを確認する git checkout master git branch --merged # masterにまだmergeしていないbranchを確認する git checkout master git branch --no-merged # 作業途中でmergeしたときに, まだcommitしたくないときは, stashを使って一時的に変更内容を退避させる. git stash save \u0026#39;コメント\u0026#39; # stashで退避させた情報の一覧表示 git stash list # 退避させるたびに, この一覧の上に退避データが積み上がっていく. # 対比した内容を取り出すには git stash pop # 引数をつけない場合, listで表示された一番上の内容が取り出される. mergeの衝突を解消 # branch切って, すぐにhogeに移動する git checkout -b hoge vim index.html git add . git commit -m \u0026#39;hogeで変更したよ\u0026#39; git branch master vim index.html git add . git commit -m \u0026#39;masterでも変更したよ\u0026#39; git merge hoge \u0026gt; CONFLICT (content): merge conflict in index.html vim index.html # index.htmlのいらないところを削除するだけ # hogeかmasterのどちらかの変更を残すということ. git add . git comit -m \u0026#39;conflictを解消したよ\u0026#39; tag # 直前のcommitにidに代わるわかりやすいv1.0というtagを付ける git tag v1.0 # tagを確認する git tag # tagを使ってcommit内容を確認する git show v1.0 # 特定のcommitにtagを付ける git tag v0.9 id(hash値) # tagの削除 git -d v0.9 エイリアス git config --global alias.co checkout git config --global alias.st status git config --global alias.br branch git config --global alias.ci commit git config --global alias.cm \u0026#39;commit -m\u0026#39; git config --global alias.a \u0026#39;add .\u0026#39; # エイリアスの確認 git config --global --list | grep ^alias\\. # 設定一覧 git config -l 初めての共同作業 # 共有リポジトリを作成 # 共有リポジトリには.gitを付けるのが通例 mkdir ourweb.git cd ourweb.git git init --bare # これで管理ファイルだけが管理され, commitとかはしない設定になる. # 別のリポジトリを現在のリポジトリにoriginとして登録する git remote add origin ~/path/to/ourweb.git git config -l \u0026gt; remote.origin.url=/home/path/to/ourweb.git # 登録した別のリポジトリ(origin)を削除する git remote rm origin # 現在のリポジトリ(master)の内容をremoteしたディレクトリ(origin)にpushする git push origin master # originにmasterをpushする.という意味. # ourweb.gitをmyweb2としてcloneして作業する git clone ~/path/to/ourweb.git myweb2 cd myweb2 git log vim index.html git add . git commit -m \u0026#39;line2 added\u0026#39; git push origin master # 変更内容(master)をoriginにpushした # 別のユーザーが上記の変更をpullする git pull origin master git log 共同作業でコンフリクトが起こったら # Aさんが先に変更を加えた vim index.html git commit -am \u0026#39;line 3 added\u0026#39; git push origin master # Bさんも後から同様の場所に変更を加えた vim index.html git commit -am \u0026#39;line third added\u0026#39; git push origin master \u0026gt; CONFLICT (content): Merge conflict in index.html # pushする前にpullしてまずはconflictを解消する git pull origin master vim index.html git commit -am \u0026#39;conflict fixed\u0026#39; git push origin master git rev-parse 機能がたくさんあるが, ここではHEADのダイジェスト返してくれる方法.\ngit rev-parse HEAD"},{"idx":107,"href":"/docs/github/","title":"Github","content":" GitHubとは  ソフトウェア開発のプラットフォーム兼ソースコードなどのホスティングサービス. https://github.com  GitHubとGitLab同時にpush 先ずは普通にGitHubとGitLabにリポジトリを作成し, リモートリポジトリを追加する.\n# GitLabのリポジトリをリモートに追加 git remote set-url --add origin git@gitlab.com/solareenlo/リポジトリ名.git # 確認 git remote -v \u0026gt; origin git@github.com:solareenlo/リポジトリ名.git (fetch) \u0026gt; origin git@github.com:solareenlo/リポジトリ名.git (push) \u0026gt; origin git@gitlab.com:solareenlo/リポジトリ名.git (push) # 以下を行うとGitHubとGitLabに同時にpushされる. git push -u origin master リポジトリに他のリポジトリをリンク付けする git submodule add -b \u0026lt;リンク付けする方のブランチ名\u0026gt; \u0026lt;リンク付けする方のURL\u0026gt; \u0026lt;リンク付けされるディレクトリ名\u0026gt; リポジトリをforkして更新する fork -\u0026gt; clone -\u0026gt; remote -\u0026gt; fetch -\u0026gt; marge -\u0026gt; push\nssh接続ができなくなったときは ~/.ssh/configの中身を\nHost github github.com Hostname github.com Port 22 User git IdentityFile ~/.ssh/id_git_rsa のように, Hostのところにgithub.comを追加してみる.\nスライドショー  hiroppy/fusuma hakimel/reveal.js gnab/remark gitpitch/gitpitch  チートシート  Git Cheat Sheets  GitHub Pagesとは  GitHubの静的サイトホスティングサービスのこと.  静的サイトを公開する cd 作業ディレクトリ名 git checkout -b gh-pages vim index.html // index.htmlを作成 git push -u origin gh-pages gh-pagesという名前のブランチにindex.htmlファイルを作っておけば, それが静的サイトとして「https://ユーザー名.github.io/リポジトリ名」として公開される.\nサブドメインを割り当てる  GitHub Pagesでサブドメインを割り当てる時はCNAMEを使用する.     ホスト名 TYPE TTL VALUE     docs.iotajapan.com CNAME 3600 iotajapan.github.io    "},{"idx":108,"href":"/docs/haskell/","title":"Haskell","content":" Haskellとは  純粋な関数型プログラミング言語の1つ. 公式サイト: https://www.haskell.org  静的サイトジェネレーター  HAKYLL  "},{"idx":109,"href":"/docs/hugo/","title":"Hugo","content":" Hugoとは  静的なhtmlを生成する事ができる静的サイトジェネレータの1つ. Go言語で書かれてる. 記事を書くだけならGo言語を知らなくても良い. 記事はMarkdownで書ける. GitHubリポジトリ: https://github.com/gohugoio/hugo  .mdを削除した時に.htmlも同様に削除するオプション hugo server -D --cleanDestinationDir MacでHugoとGitHub Pagesを使ってのサイトの作り方 こちら\nHugoのコードの色選択  https://help.farbox.com/pygments.html Chroma Style Gallery  全文検索 Search for your Hugo Website\n見た目変更 このサイトだと/サイトのディレクトリ/themes/book-fork/assets/の中の.scssファイルを操作する.\nイラストの追加  このサイトだと/ブログのディレクトリ/layouts/shortcodes/fontawesome.htmlに\n\u0026lt;span class=\u0026#34;inline-svg\u0026#34; \u0026gt; {{- $fname:=print \u0026#34;fontawesome/\u0026#34; ( .Get 0 ) \u0026#34;.svg\u0026#34; -}} {{- $path:=\u0026#34;\u0026lt;path\u0026#34; -}} {{- $fill:=\u0026#34;\u0026lt;path fill=\\\u0026#34;currentColor\\\u0026#34;\u0026#34; -}} {{ replace (readFile $fname) $path $fill | safeHTML }} \u0026lt;/span\u0026gt; を追加する.\n svgファイルをどこからかダウンロードしてくる. オススメはFontawesomeのGitHubリポジトリから目当てのsvgファイルを見つけて, curlとかで/ブログのディレクトリ/content/fontawesome/にダウンロードしてくる.\n# GitHubのイラストだとこんな感じ. curl -O https://raw.githubusercontent.com/FortAwesome/Font-Awesome/master/svgs/brands/github.svg このサイトだと/ブログのディレクトリ/thems/book-fork/assets/custom.scssに\n.inline-svg { display: inline-block; height: 1.15rem; width: 1.15rem; top: 0.15rem; position: relative; } を追加する.\n .mdファイルの中で\n{{\\% fontawesome github %}} と使う.\n Reference: Using Font Awesome Icons in Hugo\n  "},{"idx":110,"href":"/docs/javascript/","title":"Javascript","content":" JavaScriptとは  Webページを構成する全てのオブジェクトを操作できるプログラミング言語. 人間の顔に例えると以下のようなイメージ.  骨格がhtml お化粧がcss 表情がJavaScript   フレームワーク 比較  2019年イチ押しのJavaScriptフレームワークオーバービュー JavaScript: フレームワーク React/Vue/Angularについて 2018 JavaScript Rising Stars  "},{"idx":111,"href":"/docs/jenkins/","title":"Jenkins","content":" Jenkinsとは  オンプレミスのCI/CDツール. Jenkinsが全てのビルドプロセスの自動化を行うものではない. テストやデプロイなどの各フェーズはそれぞれ専用のツールで自動化を行い, Jenkinsはどういったタイミングでどのツールを呼び出すのかを指示し, エラーが出たら即座にフィードバックを行う処理をする. 公式サイト: https://jenkins.io  "},{"idx":112,"href":"/docs/kubernetes/","title":"Kubernetes","content":" Kubernetesとは  Dockerコンテナのクラスタ管理を始めとしたオーケストレーションを行うサービスのこと. ホスト間の連携やデプロイについても総括的に管理できる(ここがDocker Composeと違うところ). Kubernetesの大きな特徴の1つに宣言的設定がある.  宣言的設定とは, イミュータブルなインフラを作るための基本的な考え方で, 「システムのあるべき姿」を設定ファイルに宣言する！という考え方.  Kubernetesは設定ファイルに書いたとおりのインフラを維持するように設計されている.  ので, 設定ファイル(yamlファイル)をたくさん書く事になる.  Reference: Docker Compose利用者から見た Kubernetes 開発環境構築入門 GitHubリポジトリ: https://github.com/kubernetes  他のオーケストレーションと違うところ ① 様々なOSSと組み合わせることにより, 柔軟に機能拡張なところ.\n コンテナ運用を更に効率化 / 高速化  詳細なメトリック監視と可視化・・・Prometheus + Grafana コンテナのログの転送収集・・・Fluentd / Fluent Bit ネットワークトラフィックの制御・・・ Istio + Envoy  Kubernetesの適応領域の拡大  機械学習プラットフォーム・・・Kubeflow 分散ストレージ・・・Rook 分散型データベース・・・Vitess   ② 本格的な宣言的オペレーションとInfrastructure as Codeを実現可能\n③ クラスター上にデプロイするシステムの構成をコード(マニフェストファイル)によって定義できる\n 運用オペレーションはコードの変更によって実施し, 作業を簡素化する. 複数Kubernetesクラスターでの相互運用を実現する  Reference: Kubernetesの基礎\nDocker Composeとの違い Docker Composeは動作させるコンテナを意識するだけでほとんど良かったが, Kubernetesではそれに加えて動作させるホスト(Node)やコンテナのグループ化(Pod), その複製(ReplicaSet)と公開(Service, Ingress)といったインフラレベルで意識していたことも全て設定ファイルの1つとして管理できる.\nReference: Docker Compose利用者から見た Kubernetes 開発環境構築入門\n   項目 Docker Compose → Kubernetes     Image 各エントリーは, イメージを構築するためにオプションでdocker-composeを取得できる. → すべてのイメージがすでに構築されているとする.   Container 各エントリーが作成したいコンテナを表す. → 作成したいオブジェクト(Kubernetesクラスタ上で機能する構成要素のこと. Pod, Service, Volume, Namespace, Controllerのこと.)ごとに1つの設定ファイル   Network 各エントリーがネットワーク要件を定義する. → 手動ですべてのネットワークを設定する必要がある.    用語集    用語 説明     Node コンテナが動作するサーバのこと.\nMaster(Master Node): 全Nodeを管理する.Node(Woker Node): 各リソースを動かす.   Pod 関連したコンテナの集まりを1つにしたもの.   ReplicaSet 対象Podのクラスタ全体における生成・管理を行う.\nPodTemplateと呼ばれるPodのテンプレートをもとに、Podを指定された数(レプリカ数)に調整・管理を行う仕組み.\nそうすることで, Podのセルフヒーリングを行う.   Deployment ReplicaSetの生成・管理を行う.\nローリングアップデートやロールバックといったデプロイ管理の仕組みを提供する.   Service Podへのアクセス経路を提供する.\nOSI参照モデルのL4層まで扱える.\n- クラスタ内部のみで利用できるService(ClusterIP)や,\n- クラスタ外部からアクセス可能なService(NodePort)などを作成することができる.   Ingress Serviceの上位リソース.\nOSI参照モデルのL7層レベルまで扱える.   ConfigMap 環境変数のような設定値, また設定ファイル情報そのものを管理する.\nKey-Value形式.   Secret パスワードのような秘匿情報を扱う際に利用する.   PersistentVolume ボリューム領域を定義する.\nEBSやNFSのような外部ストレージも定義できる.   PersistentVolumeClaim 利用するボリューム領域の要求を定義する.\nPersistentVolumeとPodを紐付けるために利用する.   Namespace 仮想的なKubernetesクラスタの分離機能.\ndefault: デフォルトのNamespacekube-system: Kubernetesクラスタのコンポーネントやaddonが展開されるNamespacekube-public: 全ユーザが利用できるConfigMapなどを配置するNamespace     References:  Kubernetes: Deployment の仕組み Docker Compose利用者から見た Kubernetes 開発環境構築入門   yaml内の用語集    用語 意味     apiVersion リソースで利用するAPIのバージョンを指定.   kind リソースの種別を指定.\n(Deployment, Serviceとか)   metadata リソースへ付与可能なメタデータ.\n主に名称やラベルを付与する.   spec リソース固定の設定を指定.   data ConfigMapやSecretなどの設定データを記述するリソースで使用される.   label Kubernetes上のオブジェクト(Podなど)に付けることができるKey/Valueペアの文字列で, オブジェクトに任意のメタ情報のようなものを持たせることができる.   selector Labelの集合をもとにKubernetesオブジェクトをフィルタリングすることができる.    apiVersionの調べ方 kubectl api-resources # リソースとAPIGROUPの対応を調べる kubectl api-versions # APIGROUPで利用可能なversionを調べる    APIGROUPあるなし  書き方     APIGROUPがあるとき → apiVersion: (APIGROUP)/(APIVERSION)   APIGROUPがないとき(= Core groupに属する) → apiVersion: v1    Reference: Kubernetesの apiVersion に何を書けばいいか\nServiceのType4種類  ClusterIp  クラスタ内のIPにServiceを公開する. この値ではServiceはクラスタ内からのみアクセス可能. デフォルトはこれ.  NodePort  各ノードのIP上のServiceを静的ポート(NordPort)に公開する. NodePort ServiceがルーティングするClusterIP Serviceが自動的に作成される. NodeIp: NordPortを要求することで, クラスタ外からNordPort Serviceにアクセスできる.  LoadBalancer  クラウドプロバイダのロードバランサを使用して外部にServiceを公開する. 外部ロードバランサがルーティングするNordPort ServiceとClusterIP Serviceが自動的に作成される.  ExternalName  値を含むCNAMEレコードを返すことにより, ServiceをexternalNameフィールドのコンテンツ(たとえば, foo.bar.example.com)にマッピングする. この場合, どのような種類のプロキシも設定されない. この型を使うには, バージョン1.7以上のkube-dnsが必要.   Reference: Kubernetesの Service についてまとめてみた\nPersistentVolumeClaimのaccessModes3種類  PeadWriteOnce  1つのノードが読み書き可能  ReadOnlyMany  複数のノードが読み込みだけ可能  ReadWriteMany  複数のノードから読み書き可能   StorageClassの一覧  The StorageClass Resource  volumeMountsのsubPath subPathを指定してあげるとvolumeをルートディレクトリからマウントしないで, サブディレクトリからマウントする. volumeをそんなに使わない時にオススメ.\nReference: 永続ストレージのサブディレクトリにマウントする方法\nMacのローカル環境で動かす  https://brew.sh からbrewをインストールする. brew install kubernetes-cliをターミナルで実行する.  kubectlはKubernetesのmasterを動かすもの.  https://www.virtualbox.org からMac用のVirtualBoxをインストールする.  VirtualBoxはコンテナ群を動かす環境.  brew cask install minikubeをターミナルで実行する.  minikubeはコンテナをVM上で動かすもの.  minikube startをターミナルで実行する.   References:  https://kubernetes.io/docs/tasks/tools/install-kubectl/ https://www.virtualbox.org/wiki/Downloads https://kubernetes.io/docs/tasks/tools/install-minikube/   Ubuntuのローカル環境で動かす  kubectlをインストールする. VirtualBoxをインストールする. minikubeをインストールする.   References:  https://kubernetes.io/docs/tasks/tools/install-kubectl/ https://www.virtualbox.org/wiki/Downloads https://kubernetes.io/docs/tasks/tools/install-minikube/   minikubeの使い方 minikube status # 動いているか確認 minikube start # minikubeをスタート minikube ip # ipを確認 minikube dashboard # ダッシュボード出現 minikube docker-env # 環境変数を出力 kubectlの使い方 kubectl apply -f client-pod.yaml # オブジェクトの新規作成・差分反映 kubectl get pods # 動いているpodを確認 kubectl get deployments # 動いているdeploymentを確認 kubectl describe \u0026lt;object type\u0026gt; \u0026lt;object name\u0026gt; # オブジェクトの詳細表示 kubectl delete -f client-pod.yaml # オブジェクトが存在すれば削除 kubectl delete deployment client-deployment # deploymentの削除 kubectl delete pod client-node-port # podの削除 kubectl api-resources # リソースとAPIGROUPの対応を調べる kubectl api-versions # APIGROUPで利用可能なversionを調べる kubectl get storageclass # 管理者が提供するストレージのクラスを表示 kubectl get pv # PersistentVolumeの一覧を表示 kubectl get pvc # PersistentVolumeClaimの一覧を表示 # 以下3つはパスワードを設定する時に使用 kubectl create secret generic pgpassword --from-literal PGPASSWORD=******** # パスワードを生成 kubectl create secret generic \u0026lt;secret_name\u0026gt; --from-literal \u0026lt;key=value\u0026gt; # パスワードを生成 kubectl get secret # secret一覧を表示 # 以下2つはGKEでユーザーの権限を与える時に使用 kubectl create serviceaccount --namespace kube-system tiller # tillerというサービスアカウントを作成 kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-ad min --serviceaccount=kube-system:tiller 自分のPCからVMにアクセスしてDockerコンテナを見る方法 eval $(minikube docker-env) docker ps 1度デプロイしたイメージのバージョンアップ方法 Kubernetesではlatestタグイメージの運用は適切なロールバックを行うことが難しいので推奨されていない.\nので, できる限りVsersion, もしくはdigestでイメージ指定を行うようにする.\n以下のようにDocker Hubにバージョンを指定してpushし,\ndocker build -t solareenlo/multi-client:v5 docker push solareenlo/multi-client:v5 以下のようにコマンドラインからイメージのバージョンアップを行う.\nkubectl set image deployment/client-deployment client=solareenlo/multi-client:v5 イメージのバージョンにgitのshaを使う 以下の様に.travis.ymlに$SHAを設定して,\nsudo: required services: - docker env: global: - SHA=$(git rev-parse HEAD) 以下の様にbuild, push, setを行うと良い.\ndocker build -t solareenlo/multi-client:latest -t solareenlo/multi-client:$SHA -f ./client/Dockerfile ./client docker build -t solareenlo/multi-server:latest -t solareenlo/multi-server:$SHA -f ./server/Dockerfile ./server docker build -t solareenlo/multi-worker:latest -t solareenlo/multi-worker:$SHA -f ./worker/Dockerfile ./worker docker push solareenlo/multi-client:latest docker push solareenlo/multi-server:latest docker push solareenlo/multi-worker:latest docker push solareenlo/multi-client:$SHA docker push solareenlo/multi-server:$SHA docker push solareenlo/multi-worker:$SHA kubectl apply -f k8s kubectl set image solareenlo/server-deployment server=solareenlo/multi-server:$SHA kubectl set image solareenlo/client-deployment client=solareenlo/multi-client:$SHA kubectl set image solareenlo/worker-deployment worker=solareenlo/multi-worker:$SHA ローカルで動かした例  solareenlo/complex-k8s-local  GKEで動かした例  solareenlo/multi-k8s-gke  TLS  jetstack/cert-manager  良書  Cloud Native Infrastructure Kubernetes Up \u0026amp; Running Managing Kubernetes  Helm  Kubernetesのパッケージ管理ツール. デフォルトで使用可能なChartはkubernetes/chartsのstableディレクトリで確認可能. GitHubリポジトリ: https://github.com/helm/helm     用語 意味 役割     helm 船のかじ Kubernetesのパッケージマネージャー.   chart 海図 Kubernetesのマニフェストのテンプレートをまとめたもの.   tiller 舵柄 デプロイを担うサーバーコンポーネント.   package - 1つのアプリケーションとして成り立つchartの単位.\nこの単位でデプロイを行う.   release - packageがデプロイされて, k8s上でpodとして実際に動作しているもの.   repository - chartの置き場所. yumのリポジトリのようなイメージ.     Reference:  Kubernetes: パッケージマネージャHelm helm覚書 helmの過去、現在、未来 Helmの概要とChart(チャート)の作り方   "},{"idx":113,"href":"/docs/linter-formatter/","title":"Linter Formatter","content":" Linterとは  コードの間違いを指摘するもの.  Formatterとは  コードのスタイルを統一/調整するもの.  Prettier  JavaScript(including ES2017), JSX, Angular, Vue, Flow, TypeScrip,t CSS, Less, SCSS, HTML, JSON, GraphQL, Markdown, GFM, MDX, YAMLをフォーマットしてくれる. GitHubリポジトリ: prettier/prettier  vimでの使い方  こちらの.vimrcの様にvim-prettierを設定する. 当該のディレクトリで,\nyarn add prettier --dev --exact コードを開いて, コードの一番上に// @formatを記入して,\n:w で, 自動でコードをフォーマットしてくれる.\n Reference: prettier/vim-prettier\n  "},{"idx":114,"href":"/docs/nodejs/","title":"Nodejs","content":" Node.jsとは  サーバーサイドJavaScript環境のこと. サーバーサイドもJavaScripで記述できるようにした. シングルスレッドでノンブロッキングI/Oを行う. GitHubリポジトリ: https://github.com/nodejs  インストール Mac: https://nodejs.org/en/\nUbuntu: Official Node.js binary distributions\nテストツールの種類  テストの環境を提供する（Mocha, Jasmine, Jest, Karma） テストの構造を提供する（Mocha, Jasmine, Jest, Cucumber） アサーション機能を提供する（Chai, Jasmine, Jest, Unexpected） 生成, 表示, テスト結果をウォッチする（Mocha, Jasmine, Jest, Karma）\n以前の実行時からの変更が意図されたものであることを確認するために, コンポーネントやデータ構造を生成し, スナップショットを比較する（Jest, Ava） モック, スパイ, スタブを提供する（Sinon, Jasmine, enzyme, Jest, testdouble) コードカバレッジのレポートを生成する（Istanbul, Jest) シナリオ実行の管理ができるブラウザ, または疑似ブラウザの環境を提供する（Protractor, Nightwatch, Phantom, Casper）  Reference: 2017年JavaScriptのテスト概論\n日付を扱う  moment/moment iamkun/dayjs date-fns/date-fns  引数で判定 引数1つでok. それ以外は強制終了する.\nif(process.argv.length !== 3) { console.log(`csvファイル名を入力してください.`); process.exit(1); // 正常に強制終了する }  mapの中で非同期処理  Node 高階関数内での非同期処理（async/await）をどう書くか async/awaitやPromiseで簡単に配列のイテレーションできるようにする toniov/p-iteration  CSVを扱う  csv.jsを使えば簡単. CSVの生成/読み取り/変換/書き出しができる. stream/コールバック/同期的にデータを処理ができる.  stream 以下を行ってから\nnpm init -y npm i --save csv touch index.js index.jsに以下を書き込んで\nconst csv = require(\u0026#39;csv\u0026#39;); const generator = csv.generate({seed: 1, columns: 2, length: 3}); const parser = csv.parse(); const transformer = csv.transform(data =\u0026gt; { return data.map(value =\u0026gt; {return value.toUpperCase()}); }); const stringifier = csv.stringify(); // CSVを生成して generator.on(\u0026#39;readable\u0026#39;, () =\u0026gt; { while(data = generator.read()){ parser.write(data); } }); // CSVを読み込んで parser.on(\u0026#39;readable\u0026#39;, () =\u0026gt; { while(data = parser.read()){ transformer.write(data); } }); // データを変換して transformer.on(\u0026#39;readable\u0026#39;, () =\u0026gt; { while(data = transformer.read()){ stringifier.write(data); } }); // 文字列に変換して stringifier.on(\u0026#39;readable\u0026#39;, () =\u0026gt; { while(data = stringifier.read()){ // 標準出力する.  process.stdout.write(data); } });  以下を実行する.\nnode index.js pipeでstream 以下を行ってから\nnpm init -y npm i --save csv touch index.js index.jsに以下を書き込んで\nconst csv = require(\u0026#39;csv\u0026#39;); // CSVを生成して csv.generate ({seed: 1, length: 3}).pipe( // CSVを読み込んで csv.parse ()).pipe( // データを変換して csv.transform (record =\u0026gt; { return record.map(value =\u0026gt; { return value.toUpperCase() })})).pipe( // 文字列にして csv.stringify ()).pipe( // 標準出力する. process.stdout);  以下を実行する.\nnode index.js コールバック 以下を行ってから\nnpm init -y npm i --save csv touch index.js index.jsに以下を書き込んで\nconst csv = require(\u0026#39;csv\u0026#39;); // CSVを生成して csv.generate({seed: 1, columns: 2, length: 3}, (err, data) =\u0026gt; { // CSVを読み込んで  csv.parse(data, (err, data) =\u0026gt; { // データを変換して  csv.transform(data, data =\u0026gt; { return data.map(value =\u0026gt; {return value.toUpperCase()}); }, (err, data) =\u0026gt; { // 文字列に変換して  csv.stringify(data, (err, data) =\u0026gt; { // 標準出力する.  process.stdout.write(data); }); }); }); });  以下を実行する.\nnode index.js 同期処理 以下を行ってから\nnpm init -y npm i --save csv-generate csv-parse stream-transform csv-stringify touch index.js index.jsに以下を書き込んで\nconst generate = require(\u0026#39;csv-generate/lib/sync\u0026#39;); const parse = require(\u0026#39;csv-parse/lib/sync\u0026#39;); const transform = require(\u0026#39;stream-transform/lib/sync\u0026#39;); const stringify = require(\u0026#39;csv-stringify\u0026#39;); // CSVを生成して const csvFile = generate({ seed: 1, objectMode: true, columns: 2, length: 2 }); // CSVを読み込んで const input = parse(csvFile, { columns: true, skip_empty_lines: true }); // データを変換して const records = transform(input, record =\u0026gt; { record.push(record.shift()) return record }); // 文字列に変換して const moji = stringify(records, (err, output) =\u0026gt; { // 出力する.  console.log(output); });  以下を実行する.\nnode index.js Streamとは  データストリーム(データの転送単位がブロックより細かいバイト単位で行う方式)を扱うオブジェクト. Streamオブジェクトはデータをストリームとして(データを流れる様にして)扱いたい時に使う. References:  Node.js Stream を使いこなす Stream API入門   // ブロッキングでファイルを読み書きする. // データを読み込んでる間は全ての処理がストップする. const text = fs.readFileSync(\u0026#39;src.txt\u0026#39;, \u0026#39;utf8\u0026#39;); fs.writeFileSync(\u0026#39;dest.txt\u0026#39;, text); // 非ブロッキングI/Oでファイルを読み書きする. // データを読み込んでる間も他の処理はできるが, 書き込みは読み込みが終わってから. fs.readFile(\u0026#39;src.txt\u0026#39;, \u0026#39;utf8\u0026#39;, (err, data) =\u0026gt; { fs.writeFile(\u0026#39;dest.txt\u0026#39;, data); }); // 一定量だけデータを読み込んで書き込みを行う. // 大きなファイルだと大活躍. const src = fs.createReadStream(\u0026#39;src.txt\u0026#39;, \u0026#39;utf8\u0026#39;); const dest = fs.createWriteStream(\u0026#39;dest.txt\u0026#39;, \u0026#39;utf8\u0026#39;); src.on(\u0026#39;data\u0026#39;, chunk =\u0026gt; dest.write(chunk)); src.on(\u0026#39;end\u0026#39;, () =\u0026gt; dest.end()); // pipeも使える. const src = fs.createReadStream(\u0026#39;src.txt\u0026#39;, \u0026#39;utf8\u0026#39;); const dest = fs.createWriteStream(\u0026#39;dest.txt\u0026#39;, \u0026#39;utf8\u0026#39;); src.pipe(dest);  Streamの種類    名称 意味     stream.Readable 読み取りだけができるストリーム   stream.Writable 書き込みだけができるストリーム   stream.Duplex 読み取りも書き込みもできるストリーム   stream.Transform 読み取ったデータを変換して出力するストリーム    公式Reference  Stream  yarn  こちらもNode.jsのパッケージ管理ツール. GitHubリポジトリ: https://github.com/yarnpkg/yarn  パッケージを最新バージョンへ yarn outdated # 新しいバージョンを確認 yarn upgrade # パッケージのアップグレード yarn upgrade-interactive # 上記2つを一緒に行う"},{"idx":115,"href":"/docs/npm/","title":"Npm","content":" NPM  Node.jsのパッケージ管理ツール. 公式サイト: https://npmjs.com  インストール npm自体のインストール  Downloading and installing Node.js and npm  npm自体のupdate npm update -y npm # もしくは npm install npm@latest -g npm自体のバージョン管理 Reference: How to Update Node.js to Latest Version (Linux, Ubuntu, OSX, Others)\nパッケージのインストール npm i \u0026lt;パッケージ名\u0026gt; # 本番環境へインストール npm i -D \u0026lt;パッケージ名\u0026gt; # 開発環境へインストール パッケージの脆弱性確認 npm audit パッケージを最新へ npm outdated # 新しいバージョンを確認 npm install -g npm-check-updates # アップデートマネージャーをインストール ncu # 新しいバージョンを確認 ncu -u # package.jsonを更新 npm update # パッケージを更新 便利なパッケージ npm-run-all  複数のnpmを実行するためのコマンドラインツール GitHubリポジトリ: mysticatea/npm-run-all  インストール npm i -D node-run-all 簡単な使い方 run-s \u0026lt;1つ目のタスク\u0026gt; \u0026lt;2つ目の処理\u0026gt; # 順次処理 run-p \u0026lt;1つ目のタスク\u0026gt; \u0026lt;2つ目の処理\u0026gt; # 並列処理 ダウンロード数比較  johnmpotter/npm-trends  "},{"idx":116,"href":"/docs/password-manager/","title":"Password Manager","content":" パスワードマネージャーとは  パスワードを管理するアプリケーションのこと.  オープンソースのパスワードマネージャー  KeePass Bitwarden  "},{"idx":117,"href":"/docs/platex-book/","title":"Platex Book","content":" pLaTeXで本を作成する方法  総合開発環境を使う方法とコマンドラインを使う方法の2種類がある.  Mac編  TexShopというlatexの総合開発環境を使うのが簡単.  Ubuntu編  Ubuntuでは総合開発環境を使わずに, TeX Live(TeXのディストリビューション)とzathura(pdfビューア)を使って, コマンドラインで作成していく.  TeX Liveのインストール # ミラーサイトからinstall-tl-unx.tar.gzをダウンロードする # wget を使用する場合 wget http://mirror.ctan.org/systems/texlive/tlnet/install-tl-unx.tar.gz # curl を使用する場合 curl -O http://mirror.ctan.org/systems/texlive/tlnet/install-tl-unx.tar.gz # install-tl-unx.tar.gzを展開する tar xvf install-tl-unx.tar.gz # 展開したディレクトリに移動する cd install-tl* # root権限でインストーラを実行する # Iを入力してインストールを開始する sudo ./install-tl -no-gui -repository http://mirror.ctan.org/systems/texlive/tlnet/ # インストールが途中でストップした場合は, 以下のコマンドで再開する sudo ./install-tl -no-gui -profile installation.profile # インストールが終了したら /usr/local/bin ディレクトリ配下にシンボリックリンクを追加する # ????はバージョンを入力する sudo /usr/local/texlive/????/bin/*/tlmgr path add  Reference: https://texwiki.texjp.org/?Linux  Tex Liveのアップデート sudo tlmgr update --self --all pdfビューアのインストール  ここではpwmt/zathuraをインストールする. zathuraはvimのキーバインドで操作できる軽量なpdfビューアで, 印刷はできない. zathuraをインストールする  sudo apt update sudo apt upgrade -y sudo apt install zathura  zathuraをソースコードからビルドしてインストールする方法  TeX Liveの使い方 # texからdviを作成する latex book.tex platex book.tex # dviからpdfを作成する dvipdfmx book.dvi zathuraの使い方 zathura bool.pdf # バックグラウンドでpdfを表示する zathura --frok book.pdf  操作方法はvimのキーバインド.  zathurarcの設定  zathurarcにzathuraの設定をすることができる.\n# zathurarcのhelpを表示する man zathurarc # zoomとscrollとclipboardを設定する cat ~/.config/zathura/zathurarc set zoom-step 30 set scroll-step 100 set selection-clipboard clipboard  vimプラグイン  lervag/vimtex lervag/vimtexが良い  "},{"idx":118,"href":"/docs/programming-language-docs/","title":"Programming Language Docs","content":" プログラミング言語の日本語訳ドキュメント  Angular: https://github.com/angular/angular-ja React: https://ja.reactjs.org/ ionic: https://github.com/ionic-jp/ionic-docs  "},{"idx":119,"href":"/docs/programming-language/","title":"Programming Language","content":" プログラミング言語とは  コンピュータに解釈できるようにつくられた人工言語. コンピュータへの指令であるプログラムを書くのに使われる. いろんな特徴を持っている.  いろんな指標によるランキング  TIOBE Index (TOIBEによる検索エンジンによる各種プログラミング言語の話題度ランキング) RedMonk (RedMonkによるランキング) Interactive: The Top Programming Languages 2018 (IEEEによる2018年度のランキング) PYPL PopularitY of Programming Language (PYPLによるGoogleによるチュートリアル検索ランキング)  プログラミング言語の型 代表的なもの3つ\n   種類 説明     オブジェクト指向型 「モノ」を組み立てるように表現して, コンピュータに動作をさせる.   続き型 上から下まで単調なルールで文章を読むように動作する.   関数型プログラミング 数学の関数のイメージでデータに何かしらの処理をして答えを取得するように動作する.    オブジェクト指向プログラミング いろんな特徴.\n   原則 説明     カプセル化 自由なアクセスからデータを保護する仕組み   継承 再利用性を高めて, 冗長性を避けるための強力なツール   ポリモーフィズム メッセージの送信側とメッセージの受信側が動的に決まる仕組み     オブジェクトは, オブジェクトに含まれるデータを操作する関数を有している. クラスはオブジェクトのインスタンスを作成するために使用されるテンプレート. OOPは冗長だが, 他のコーディングパラダイムに比べて読みやすい.  "},{"idx":120,"href":"/docs/programming/","title":"Programming","content":" プログラミングとは  コンピュータプログラムを作成することにより, 人間の意図した処理を行うようにコンピュータに指示を与える行為のこと. その為の便利なツールがたくさんある.  プログラミングをするのに役立つツール  プログラミング言語 (C, Java, JavaScript, Pythonなど)  手続き型, オブジェクト指向型, 関数型, 静的型付け, 動的型付けなどいろんな種類がある. 最終的にバイナリデータになって, コンピュータが処理する.  テキストエディタ (Visual Studio Code, Vimなど)  コードを書くのに役に立つエディタ.  統合開発環境 (Visual Studio, Jet Brainsなど)  コンパイル, テキストエディタ, デバッガなどを1つのソフトで行えるようにしたもの.  バージョン管理システム (gitなど)  ファイルの変更履歴を管理する為のシステム.  ホスティングサービス (GitHub, GitLabなど)  上記gitを使って様々なプログラムをweb上に公開したり, それを通じて交流したりすることができるサービス. 無償・有償がある.  Linter/Formatter  コードのエラー指摘やスタイル調整をしてくれる.   勉強する  repl.it (オンラインIDE) hackr.io (コースやチュートリアルの紹介サイト)  ディベロッパーロードマップ  フロントエンド - https://roadmap.sh/frontend バックエンド - https://roadmap.sh/backend DevOps - https://roadmap.sh/devops  2019年前期における必須スキル  コード管理にはGitを用いる. コードレビューを行う. LinterやFormatterを使う. パッケージマネージャを使う. 単体テストや総合テストを行う. Dockerを活用する. CI/CDを行う. 新技術をどんどん活用する.  "},{"idx":121,"href":"/docs/react-static/","title":"React Static","content":" React Staticとは  React Staticは, Reactとそのエコシステムをベースにした, 高速, 軽量, そして強力なプログレッシブ静的サイトジェネレータ. これは, Create React Appなどのツールで慣れていたシンプルさと開発者の経験に似ており, パフォーマンス, 柔軟性, およびユーザー/開発者の経験のために慎重に設計されている. GitHubリポジトリ: nozzle/react-static  エラー処理 Error: ENOSPC: System limit for number of file watchers reached, watchと出たら echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf \u0026amp;\u0026amp; sudo sysctl -p"},{"idx":122,"href":"/docs/react/","title":"React","content":" Reactとは  Facebookとコミュニティによって開発されているUIに特化したJavaScriptライブラリ. Facebookはコアの部分だけを作成して, コミュニティがその周りをどんどん作っている. Virtual DOM(仮想DOM)と呼ばれるレンダリング機構を採用している. Virtual DOMを採用しているので, ページに表示されている広いエリアの情報をJavaScriptで管理しておき、なにか変更があった場合に変更箇所のみを再描画するUIなどに向いている. GitHubリポジトリ: https://github.com/facebook/react/ Reference: Reactとは? – React入門  用語    名前 意味     Virtual DOM DOMを作るために必要な情報を持っているオブジェクト.Virtual DOMの内容を元にHTMLを作成してブラウザに描画する.   JSX Virtual DOMの元となる構文.Babelがscript要素の内容をブラウザが解釈できるように変換を行う.JSV -\u0026gt; JavaScriptと変換される.基本的にはHTMLと同じ記法.   コンポーネント 個々の部品HTMLのパーツをコンポーネント単位で管理し組み合わせてUIの作成を行う.   props 親コンポーネントから渡されたプロパティ不変のデータ   state そのコンポーネントが持っている状態可変のデータ    Reduxとは  Reactが扱うUIのstateを管理するためのフレームワーク. ReactはFluxを採用しているが, ReduxはFluxの概念を拡張してより扱いやすくしたもの. Reduxはstateを管理するフレームワークなのでReact以外にもAngularやjQueryとも併用できるがReactが一番相性が良い.  3大原則  Single source of truth (信頼できる唯一の情報源) State in read-only (stateは常に読み取り専用にする) Changes are made with pure functions (actionがstateを変更する際にreducerを通して行う)  要素    名前 機能     Action 入力内容を元にデータを作成する   ActionCreator    Store データを貯める   State    Reducer 前の状態から新しい状態への純粋な関数    図解 Flux\nRedux\n References:  UNIDIRECTIONAL USER INTERFACE ARCHITECTURES たぶんこれが一番分かりやすいと思います React + Redux のフロー図解   "},{"idx":123,"href":"/docs/redis/","title":"Redis","content":" Redisとは  ネットワーク接続された永続化可能なインメモリデータベースのひとつ. インメモリデータベースとは, メモリ上にデータを保存するタイプのデータベースのこと. メモリはCPUから直接アクセスできるため, （RDBなどの）ストレージにデータを保存するオンディスクDBに比べ, とても高速に動作することができる. GitHubリポジトリ: https://github.com/antirez/redis  "},{"idx":124,"href":"/docs/rust/","title":"Rust","content":" Rustとは  Mozillaが支援するオープンソースのシステムプログラミング言語のこと. 速度, 安全性, 平行性の3つのゴールにフォーカスしている. 主にC, C++に置き換わるものとされている. GitHubリポジトリ: https://github.com/rust-lang/rust  Rustの特徴 概要  C++に匹敵する実行速度や詳細なメモリ管理が実現できる. 不正なメモリ領域を指すポインタなどを許容しないといったメモリ安全性を保証している. マルチスレッドによる並列実行時のデータ競合をコンパイル時に排除する. 関数型言語由来の便利な機能, 代数的データ型とパターンマッチ, 型クラスによる多相関数, コンパイラによる型推論などを取り入れている. ガーベージコレクタのような複雑なランタイムをもっていない. 多言語関数インターフェースを用いて, 他のプログラミング言語との間で相互に関数を呼び出せる.  速度面  マシンコードへコンパイル  コンパイラがプログラムをマシンコード(プロセッサが理解できる機械語)へ変換する.  静的型付け言語  静的型付け言語は, 変数および関数の引数や戻り値などすべての値について, その型をコンパイル時に決定する. 動的型付け言語は, プログラムの実行時に実際の値を見て型を決定する.  ゼロコスト抽象化  ゼロコスト抽象化とは, プログラム言語が持つ抽象化(対象から注目すべき要素を重点的に抜き出して, 他は無視する手法)の仕組みが実行時のコスト(実行速度やメモリ使用量など)なしに動作すること.  ガーベージコレクションを行わない軽量なランタイム  安全面  Rustはコンパイル時の静的解析により以下の安全性を保証している. 型安全性  型安全性とは, 正しく型付けされたプログラムが不正な動作(未定義動作とも言う)をしないよう言語が定義されていること.  メモリ安全性  RustはCのようにメモリ内容への柔軟なアクセスができるが, Cと違い以下のようなメモリ安全性を保証する. データの転記の際のメモリ領域あふれを防ぐ. ポインタによる誤ったメモリ境域へのアクセスを防ぐ. 初期化前のメモリ領域へのアクセスを防ぐ. 解放後のメモリ領域へのアクセスを防ぐ.  マルチスレッドプログラミングにおけるデータ競合の回避  Rustでは型安全性とメモリ安全性に用いられるコンパイラの静的解析機能を使い, データ競合の可能性を検出できる. 故にコンパイルに成功したら, そのプログラムにはデータ競合が無いことが保証される. Rustではスレッド間でデータを受け渡したり共有したりするために, チャネル・ロック・配列などの範囲・イミュータブルな参照などの方法が用意されている.  アンセーフなコードのサポート  FFI(多言語関数インターフェース)経由で多言語の関数を呼び出した時, コンパイルはその多言語の関数の安全性を確認できない. 内向きのミュータビリティのような, 安全性の検査をコンパイル時ではなく実行時に延期する仕組みがライブラリとして実行されてる. これらに対するサポートも用意されている.   生産性を高めるモダンな機能  以下はRustのモダンな機能の一部     機能 概要     強力な型推論 Rustコンパイルには強力な型推論が備わっており, 変数を導入するlet文だけでなく, 途中の式で型が決まる状況なら, 型を明示しなくて良い.   代数的データ型 代数的データ方はHaskellなどの関数型言語にみられる機能でリッチなデータ構造が表現できる.\nRustの列挙型(enum)はその名前とは裏腹に, 代数的データ型を構成する列挙型, 直積型, 直和型のすべてを表現できる.   パターンマッチ 多くの言語に存在するswitch文の代わりに, 関数型言語由来で表現力の高いmatch式を持つ.\n列挙型のバリアントの判定と同時に各データフィールドの値を複数の変数に分配できる.   トレイトによるポリフォーリズム トレイトは型が持つべき性質(実装すべきメソッド)を定義する.\n一見するとJavaのinterfaceeに似ているが, 実際にはHaskellの型クラスに近く, 柔軟性が高い.    シングルバイナリ・クロスバイナリ  アプリケーションをビルドするとシングルバイナリ(単一の実行可能ファイル)が生成される. Rustはクロスコンパイルをして幅広いプラットフォームに向けたバイナリも生成できる. Rustは以下のプラットフォームに対応したバイナリを生成できる.     プロセッサ・アーキテクチャ オペレーティングシステム     x86系 Linux, macOX, Windows, BSD系(FreeBSD, NetBSD, OpenBSDなど), Solaris, RedoxOS, Fuchsia   ARM系 Android, iOS, Linux, Fuchsia   WebAssembly, asm.js WebブラウザやNode.jsのようなJavaScriptランタイム   マイコン(ARM Cortex-Mシリーズなど) ベアメタル(OSなし)   汎用GPU NVIDIA PTX中間命令   MIPS, S390x, PowerPC Linux   SPARC Solaris    他言語との連携が用意  FFI(他言語関数インターフェース)が用意されている. GCなどの複雑なランタイムを持っていないので, Python, Ruby, Node.jsなどのランタイムからでもRustの関数を簡単に呼び出せる.  インストール ツールチェーンのインストール # 以下でstable版のrustがインストールされる curl https://sh.rustup.rs -sSf | sh リンカのインストール sudo apt install gcc # Ubuntu デバッガのインストール sudo apt install lldb # Ubuntu # Macのデバッガはディベロッパーツールにインストールされてる ツールチェーン ツールチェーンとは  Rustで書かれたソースコードをコンパイルするのに使われるプログラミングツール群のこと.  構成要素  rustcコマンド(Rustのコンパイラ) cargoコマンド(Rustのビルドマネージャ兼パッケージマネージャ) std(Rustの標準ライブラリ)  リンカ リンカとは  正式にはリンケージエディタ. rustcや他の言語のコンパイラが出力したオブジェクトファイルやライブラリを結合して, ターゲット環境のABI(Application Binary Interface)に準拠した実行可能ファイルを生成するもの.  トレイト境界 トレイト境界とは  トレイト境界(trait bound)の役割は, ジェネリクスの型パラメータとして受け取れる型の範囲に境界を定めること. ある型がトレイト境界の範囲を超えていなければ型パラメータの実引数として受け取れ, 超えているなら受け取らない.  rustup rustupとは  rustupとはRustプロジェクトが公式にサポートしているコマンドラインツールのこと.  機能  複数バージョンのRustツールチェーンのインストールと管理 クロスコンパイル用のターゲットのインストール RLSなどの開発支援ツールのインストール  基本コマンド rustup --version # rustupのバージョンを表示する rustup show # インストール済みのツールチェーンを表示する rustup install nightly # 最新のnightly版をインストールする rustup update # インストール済みのツールチェーンとrustup自体をアップデートする rustup default \u0026lt;ツールチェーン名\u0026gt; # デフォルトのツールチェーンを指定する rustup run nightly rustc -V # nightly版のrustcを実行してバージョンを表示する rustup target add x86_64-unknown-linux-musl # クロスコンパイル用のターゲットを追加する Cargo Cargoとは  Rustのビルドマネージャ兼パッケージマネージャのこと.  基本コマンド cargo -h # 基本的なコマンドを表示する cargo --list # すべてのコマンドを表示する cargo command \u0026lt;コマンド名\u0026gt; # コマンドのヘルプドキュメントを表示する    種類 基本コマンド 機能     パッケージの作成 new テンプレートを元に新しいパッケージを作成する.   〃 init カレントディレクトリをパッケージとして初期化する.\n(Cargo.tomlの追加とVCSの初期化のみを行う.)   パッケージのビルド, テスト, 実行 check ソースコードのエラーチェックを行う.   〃 build ソースコードのエラーチェックを行い, OKならばバイナリまたはライブラ入りを生成する.   〃 run buildを実行し, OKならば生成されたバイナリを実行する.   〃 test テストを実行する.   〃 bench ベンチマークプログラムを実行する.   〃 doc このパッケージ自体と依存するクレートのドキュメントを生成する.   〃 clean targetディレクトリを削除する.   依存クレートの管理 update Cargo.lockでロックされた依存クレートのバージョンを, レジストリ(crates.io)で公開されている最新のバージョンに更新する.   クレートの検索, 公開 search レジストリに登録されたクレートを検索する.   〃 publish このパッケージ(クレート)をレジストリで公開する.   Rustバイナリの管理 install Rustバイナリをインストールする.   〃 uninstall Rustバイナリをアンインストールする.    カスタムサブコマンド  Cargoにはコマンドを追加できる. Cargoのwikiページにはサードパーティによる代表的なカスタムサブコマンドが掲載されている. 以下は代表的なカスタムサブコマンドの例.     クレート名 追加されるコマンド 機能     cargo-generate gen 自作テンプレートからパッケージを作成する.   cargo-modules modules パッケージ内のモジュールのアトリビュートや依存関係を表示する.   cargo-count count パッケージ内のソースコードの行数やunsafeなコードの割合を集計する.   cargo-expand expand マクロや#[derive]が展開された後のソースコードを表示する.   cargo-edit add, upgrade, rm Cargo.tomlに依存クレートのエントリを追加する.   cargo-license license パッケージが依存しているクレートのオープンソースライセンスを表示する   cargo-tree tree パッケージが依存してるクレートの情報をツリー形式で表示する.   cargo-outdated outdated パッケージが依存しているクレートに新しいバージョンがあるかチェックして, その情報を表示する.   cargo-kcov kcov テストカバレージ情報を収集する(コードカバレージテスターにはkcovを使用).   cargo-tarpaulin tarpaulin テストカバレージ情報を収集する(Ruby製のコードカバレージテスターを使用).   cargo-readme readme main.rsやlib.rsのdocコメントからREADME.mdファイルを生成する.   cargo-release release パッケージのリリース作業を定型化する.   cargo-xbuild xbuild クロスコンパイル用のターゲットを管理する.   cargo-asm asm, llvm-ir Rustソースコードをコンパイルして得られたアセンブリコードやLLVM-IRコードを表示する.   cargo-profiler profile callgrind, profile cachegrind valgrindを使用してバイナリ実行時のプロファイル情報を収集する.   cargo-bloat bloat 生成されるバイナリファイルの中で大きなスペースを占める関数やクレートを表示する.   cargo-local-registry local-registry ローカルのクレートリポジトリを管理する. オフラインビルドに便利.   cargo-clone clone クレートのソースコードをgit cloneで取得する.   cargo-update install-update cargo installでインストールしたRustバイナリに新しいバージョンがあったらアップグレードする.    カスタムサブコマンド追加 # cargo-editをインストールしてみる sudo apt install pkg-config libssl-dev # Ubuntuではこれらが必要 cargo install cargo-edit # cargo-editカスタムサブコマンドをインストールする cargo new hello # 新しいパッケージhelloを作成する cd hello # helloディレクトリに移動する cargo add rand@0.6 # バージョン0.6のrandクレートをインストールする Hello World! mkdir rust cd rust cargo new hello cd hello # バイナリを作成する cargo build # バイナリを走らせる ./target/debug/hello # もしくは cargo run # バイナリを削除する cargo clean// ~/rust/hello/src/main.rsの中身 fn main() { println!(\u0026#34;Hello, world!\u0026#34;); }  ターミナルからのデバッグ  デバッグにはLLVMのLDBとGNUのGDBが使える. Rust特有のデータ構造がきれいに表示されないことがあるため, Rustツールチェーンに含まれているrust-lldbとrust-gdbコマンドを使用すると良い.  cd rpn # プロジェクトディレクトリに移動する cargo build # プロジェクトをビルドする rust-lldb ./target/degub/rpn # バイナリを対象にLLDBを実行する (lldb) list # コードを10行ごとに表示する (lldb) br set -f main.rs -l 27 # main.rsの27行目にブレークポイントを設置する (lldb) br li # ブレークポイントの位置を確認する (lldb) br disable 1 # ブレークポイントをオフにする (lldb) r # プログラムを実行すると, ブレークポイントで停止する (lldb) po 変数名 # ブレークポイント時点の変数が束縛されている値を見る (lldb) c # プログラムの続きを実行する (lldb) q # lldbを終了する 所有権の解説  Rustの所有権（ownership）を語義から理解する  ドキュメントの日本語訳  Rustの日本語ドキュメント/Japanese Docs for Rust The Embedded Rust Book  rust-lang.orgの日本語化  https://pontoon.rust-lang.org  チートシート  Rust Language Cheat Sheet  RustでOSを書く  Writing an OS in Rust (Second Edition)  リンク  Rustのリンク集  "},{"idx":125,"href":"/docs/sed/","title":"Sed","content":" sedとは  入力ストリーム（ファイルまたはパイプラインからの入力）に対してテキスト変換などのデータ処理をおこなうプログラム. 名称「sed」は「ストリームエディタ」を意味する英語「stream editor」から.  .gitignoreの/distを削除 sed -i -e \u0026#34;/\\/dist/d\u0026#34; .gitignore # -i: 上書き保存 # -e: 行の削除 # d: 行目を表す(上の例だと\\distを含む行) 初めてのsed cat names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro \u0026gt; 4 hanako \u0026gt; 5 yasuda # 3行目を削除して標準出力する sed -e \u0026#39;3d\u0026#39; names.txt # 3dのところが1つしかない場合は-eを省略できる sed \u0026#39;3d\u0026#39; names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 4 hanako \u0026gt; 5 yasuda # sedして上書きしたい場合 sed -i \u0026#39;3d\u0026#39; names.txt # 上記をバックアップを取りながらしたい場合 sed -i.bak \u0026#39;3d\u0026#39; names.txt cat names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 4 hanako \u0026gt; 5 yasuda ls \u0026gt; names.txt names.txt.bak cat names.txt.bak \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro \u0026gt; 4 hanako \u0026gt; 5 yasuda mv names.txt.bak names.txt ls \u0026gt; names.txt # ファイルを読み込んでsedする vim ex1.sed 3d # と書き込む :wp sed -f ex1.sed names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 4 hanako \u0026gt; 5 yasuda # パイプとsedを用いてディレクトリ情報の初めの3行を削除して標準出力 ls -la | sed \u0026#39;1,3d\u0026#39; \u0026gt; ディレクトリ情報の初めの3行が削除された形で標準出力される # さらにリダイレクト(\u0026gt;)も使って, 上記をファイルに出力する ls -la | sed \u0026#39;1,3d\u0026#39; \u0026gt; output.txt パターンスペースについて sedはパターンスペースを用いて操作を行っている.\nどういうことかというと,\nsed '3d' names.txt'\nは, 3がaddress, dが削除commandの意味で,\n1. fileから1行目を読み込んでパターンスペースに格納\n2. addressにマッチする？ → commandを実行\n3. パターンスペースを表示\nという流れになっている.\nアドレスを使いこなす cat names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro \u0026gt; 4 hanako \u0026gt; 5 yasuda # 3行目以外を削除 sed \u0026#39;3!d\u0026#39; names.txt \u0026gt; 3 taro # 1行目と3行目を削除 sed \u0026#39;1d;3d\u0026#39; names.txt \u0026gt; 2 koji \u0026gt; 4 hanako \u0026gt; 5 yasuda # 1行目から3行目までを削除 sed \u0026#39;1,3d\u0026#39; names.txt \u0026gt; 4 hanako \u0026gt; 5 yasuda # 1行目を削除してから2行飛ばしで削除. # つまり, 奇数行目を削除. sed \u0026#39;1~2d\u0026#39; names.txt \u0026gt; 2 koji \u0026gt; 4 hanako # 最後の行を削除 sed \u0026#39;$d\u0026#39; names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro \u0026gt; 4 hanako # 3行目から最後の行までを削除 # $が最後の意味 sed \u0026#39;3,$d\u0026#39; names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji # iで終わる行は削除 sed \u0026#39;/i$/d\u0026#39; names.txt \u0026gt; 3 taro \u0026gt; 4 hanako \u0026gt; 5 yasuda # addressは省略もできるのでaddressを書かないと全削除 sed \u0026#39;d\u0026#39; names.txt p/a/iコマンドを使う cat names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro \u0026gt; 4 hanako \u0026gt; 5 yasuda # 3行目を2回表示する sed \u0026#39;3p\u0026#39; names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro \u0026gt; 3 taro \u0026gt; 4 hanako \u0026gt; 5 yasuda # 3行目だけを表示する sed -n \u0026#39;3p\u0026#39; names.txt \u0026gt; 3 taro # 3行目で処理を終わる sed \u0026#39;3q\u0026#39; names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro # 1行目の前に文字列をinsertする sed \u0026#39;1i\\--- start ---\u0026#39; names.txt \u0026gt; --- start --- \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro \u0026gt; 3 taro \u0026gt; 4 hanako \u0026gt; 5 yasuda # 最終行にも文字列を挿入する sed -e \u0026#39;1i\\--- start ---\u0026#39; -e \u0026#39;$a\\--- end ---\u0026#39; names.txt \u0026gt; --- start --- \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro \u0026gt; 3 taro \u0026gt; 4 hanako \u0026gt; 5 yasuda \u0026gt; --- end --- # 最終行の空の文字列を削除する # /^$/ は正規表現で空行を表す sed \u0026#39;/^$/d\u0026#39; names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro \u0026gt; 3 taro \u0026gt; 4 hanako \u0026gt; 5 yasuda 1文字ずつの文字置換にはyコマンドを使う cat names.txt \u0026gt; 1 taguchi \u0026gt; 2 koji \u0026gt; 3 taro \u0026gt; 4 hanako \u0026gt; 5 yasuda # 1文字置換はyを使い, # tをTに置換する. sed \u0026#39;y/t/T/\u0026#39; names.txt \u0026gt; 1 Taguchi \u0026gt; 2 koji \u0026gt; 3 Taro \u0026gt; 4 hanako \u0026gt; 5 yasuda # 複数個の文字を1文字ずつ置換する # t -\u0026gt; T, o -\u0026gt; O # という風に1文字ずつ対応して置換してくれる. sed\u0026#39;y/to/TO/\u0026#39; names.txt \u0026gt; 1 Taguchi \u0026gt; 2 kOji \u0026gt; 3 TarO \u0026gt; 4 hanakO \u0026gt; 5 yasuda 文字列置換にはsコマンドを使う cat items.txt \u0026gt; 1 taguchi Apple, apple, apple, grape \u0026gt; 2 fkoji Banana, apple, Apple, lemon \u0026gt; 3 dotinstall Grape, apple, strawberry \u0026gt; 4 takahashi cherry, pear, kiwi \u0026gt; 5 yasuda cherrry, Cherry # 上記のitems.txtのappleをAppleに置換する # ただし, 初めの1つにだけしか効きません sed \u0026#39;s/apple/Apple\u0026#39; items.txt \u0026gt; 1 taguchi Apple, Apple, apple, grape \u0026gt; 2 fkoji Banana, apple, Apple, lemon \u0026gt; 3 dotinstall Grape, Apple, strawberry \u0026gt; 4 takahashi cherry, pear, kiwi \u0026gt; 5 yasuda cherrry, Cherry # なので, 全てのappleをAppleに変えたいときは # gというフラグを用いる sed \u0026#39;s/apple/Apple/g\u0026#39; items.txt \u0026gt; 1 taguchi Apple, Apple, Apple, grape \u0026gt; 2 fkoji Banana, Apple, Apple, lemon \u0026gt; 3 dotinstall Grape, Apple, strawberry \u0026gt; 4 takahashi cherry, pear, kiwi \u0026gt; 5 yasuda cherrry, Cherry # 2番目にマッチするものを置換するときは # 2というフラグを用いる sed \u0026#39;s/apple/Apple/2\u0026#39; items.txt \u0026gt; 1 taguchi Apple, apple, Apple, grape \u0026gt; 2 fkoji Banana, Apple, Apple, lemon \u0026gt; 3 dotinstall Grape, Apple, strawberry \u0026gt; 4 takahashi cherry, pear, kiwi \u0026gt; 5 yasuda cherrry, Cherry # 大文字小文字を区別させないときは # iというフラグを用いる # フラグは組み合わせることもできる sed \u0026#39;s/apple/Ringo/ig\u0026#39; items.txt \u0026gt; 1 taguchi Ringo, Ringo, Ringo, grape \u0026gt; 2 fkoji Banana, Ringo, Ringo, lemon \u0026gt; 3 dotinstall Grape, Ringo, strawberry \u0026gt; 4 takahashi cherry, pear, kiwi \u0026gt; 5 yasuda cherrry, Cherry # 正規表現も使えます sed \u0026#39;s/[aA]pple/Ringo/ig\u0026#39; items.txt \u0026gt; 1 taguchi Ringo, Ringo, Ringo, grape \u0026gt; 2 fkoji Banana, Ringo, Ringo, lemon \u0026gt; 3 dotinstall Grape, Ringo, strawberry \u0026gt; 4 takahashi cherry, pear, kiwi \u0026gt; 5 yasuda cherrry, Cherry \u0026amp;や\\1を使って置換する cat items.txt \u0026gt; 1 taguchi Apple, apple, apple, grape \u0026gt; 2 fkoji Banana, apple, Apple, lemon \u0026gt; 3 dotinstall Grape, apple, strawberry \u0026gt; 4 takahashi cherry, pear, kiwi \u0026gt; 5 yasuda cherrry, Cherry # 検索した結果は\u0026amp;に入る sed \u0026#39;s/[0-5]/【\u0026amp;】/\u0026#39; items.txt \u0026gt; 【1】 taguchi Apple, apple, apple, grape \u0026gt; 【2】 fkoji Banana, apple, Apple, lemon \u0026gt; 【3】 dotinstall Grape, apple, strawberry \u0026gt; 【4】 takahashi cherry, pear, kiwi \u0026gt; 【5】 yasuda cherrry, Cherry # 複数個検索した結果を用いる場合は # ()で包んでから, \\1, \\2...を使う sed \u0026#39;s/\\([0-5]\\) \\(.*\\)/\\2 【\\1】/\u0026#39; items.txt # 1-5までの数字は\\1に, 文字列は\\2に入っている \u0026gt; taguchi Apple, apple, apple, grape【1】 \u0026gt; fkoji Banana, apple, Apple, lemon【2】 \u0026gt; dotinstall Grape, apple, strawberry【3】 \u0026gt; takahashi cherry, pear, kiwi 【4】 \u0026gt; yasuda cherrry, Cherry 【5】 ホールドスペースを使う ホールドスペースとはパターンスペースのさらに奥にある裏バッファーのようなもの\n h(hold): パターンスペースの内容をホールドスペースにコピー g(get): ホールドスペースの内容をパターンスペースにコピー x(exchange): パターンスペースとホールドスペースの内容を交換  パターンスペースは1行ずつどんどん更新されていく.\nホールドスペースに一時的に情報を格納しておく.\nそうすることでより複雑な文字列操作を行う.\ncat style.css \u0026gt; main { \u0026gt; color: red; \u0026gt; font-weight: bold; \u0026gt; font-size: 14px; \u0026gt; background: green; \u0026gt; } vim ex2.sed i # color change /color: / { h // holdが起こり, ホールドスペースに color: red; がコピーされる s/color: /background: / // 置換が起こり, パターンスペースで, color: red; が background: red; に置換される x // exchangeが起こり, ホールドスペースに background: red; が, パターンスペースに color: red; が格納される } // パターンスペースの color: red; が表示される /background: / { g // getが起こり, ホールドスペースにある background: red; が, パターンスペースにコピーされる } // パターンスペースの backgroud: red; が表示される ESC :wq sed -f ex2.sed style.css \u0026gt; #main { \u0026gt; color: red; \u0026gt; font-weight: bold; \u0026gt; font-size: 14px; \u0026gt; background: red; \u0026gt; }"},{"idx":126,"href":"/docs/sendgrid/","title":"Sendgrid","content":" SendGridとは  メール配信のSaas. APIライブライのGitHubリポジトリ: https://github.com/sendgrid APIライブライはコミュニティが作ってるので正規のサポート対象外.  mailテンプレートのテンプレート  https://www.dyspatch.io/resources/templates/ How to send an email with Dynamic Transactional Templates  "},{"idx":127,"href":"/docs/shell-script/","title":"Shell Script","content":" シェルスクリプトとは  シェルとはOSと対話するためのインターフェースであり, それのスクリプトがシェルスクリプト.\n シェルスクリプトモードで実行するのとfilename.shを作って, bash bash filename.sh  で実行する2パターンあります.  チェック  ShellCheck  シェルスクリプトモードに突入 /bin/sh $ または\nsh $ Hello World sh $ echo Hello World Hello World $ シェルスクリプトモードから脱出 CTLとdを押す.\n初めてのシェルスクリプト # まず, bashがどこにあるか調べる which bash \u0026gt; /bin/bash  #!のことを「シェバン」もしくは「シバン」という. shell scriptファイルの頭に#! /bin/bashと書いてあげる.  vim hello i #i /bin/bash echo hello Esc :wq ls -l \u0026gt; -rw-rw-r--. 1 solareenlo solareenlo 24 日付 hello chmod +x hello ls -l \u0026gt; -rwxrwxr-x. 1 solareenlo solareenlo 24 日付 hello bash hello \u0026gt; hello 文字列を表示 # helloの中身 #!/bin/bash # コメントは#を使うと文末までコメントアウトしてくれる echo \u0026#34;hello world\u0026#34; echo \u0026#39;hello world\u0026#39; echo \u0026#34;foo\u0026#34;; echo \u0026#34;bar\u0026#34;; 上記を実行すると\nbash hello \u0026gt; hello world \u0026gt; hello world \u0026gt; foo \u0026gt; bar 変数 # 02_variabelの中身 #!/bin/bash # 変数を使う # name = \u0026#34;taguchi\u0026#34; はエラーになる. =の両脇にスペースを入れるとエラーになる. name=\u0026#34;taguchi\u0026#34; readonly name2=\u0026#34;taro\u0026#34; # 読み取り専用になる # name2=\u0026#34;hanako\u0026#34; エラーになる echo \u0026#34;morning $name\u0026#34; echo \u0026#34;hello $name\u0026#34; echo \u0026#34;by ${name}san\u0026#34; echo \u0026#39;by ${name}san\u0026#39; # シングルクォーテーションだと${name}がそのまま表示される echo \u0026#34;hello $name2\u0026#34; 上記を実行すると\nbash 02_variable \u0026gt; morning taguchi \u0026gt; hello taguchi \u0026gt; by taguchisan \u0026gt; by ${name}san \u0026gt; hello taro 特殊変数 # シェルスクリプトにおける特殊変数の定義. $1 = 第1引数 $2 = 第2引数 $0 = コマンド名 $# = 引数の個数 $@ = 全部の引数# 03_variableの中身 #!/bin/bash  # 第１引数 = $1, 第2引数 = $2, ... echo \u0026#34;hello $1\u0026#34; # ./03_variable a aa aaa echo $0 # ./03_variable echo $# # 3 # = 引数の個数 echo $@ # a aa aaa @ = 引数全部 上記を実行すると\nbash 03_variable a aa aaa \u0026gt; hello a \u0026gt; bash 03_variable \u0026gt; 3 \u0026gt; a aa aaa ユーザーに入力してもらう # 1. #!/bin/bash read name echo \u0026#34;hello $name\u0026#34; # 上記を実行すると bash 04_read taro \u0026gt; hello taro # 2. #!/bin/bash read -p \u0026#34;Name: \u0026#34; name echo \u0026#34;hello $name\u0026#34; # 上記を実行すると bash 04_read \u0026gt; Name: taro \u0026gt; hello taro # 3. #!/bin/bash read -p \u0026#34;Pick 3 colors: \u0026#34; c1 c2 c3 echo $c1 echo $c2 echo $c3 # 上記を実行すると bash 04_read \u0026gt; Pick 3 colors: red green blue \u0026gt; red \u0026gt; green \u0026gt; blue # 色を多く入力したり, 少なく入力すると # 多い場合はc3に複数個の文字列が代入され, # 少ない場合はc3が表示されない. 配列 # 05_arrayの中身 #!/bin/bash # 配列 colors=(red green blue) echo ${colors[0]} # red echo ${colors[1]} # green echo ${colors[2]} # blue echo ${colors[@]} # red green blue echo ${#colors[@]} # 3 # 配列の要素に代入 colors[1]=silver # 配列の末尾に代入 colors+=(white black) echo ${colors[@]} # red silver blue white black echo ${#colors[@]} # 5 上記を実行すると\nbash 05_array \u0026gt; red \u0026gt; green \u0026gt; blue \u0026gt; red green blue \u0026gt; 3 \u0026gt; red silver blue white black \u0026gt; 5 数値演算 #!/bin/bash  echo 5+2 # \u0026gt; 5+2 echo `expr 5 + 2` # \u0026gt; 7 echo $((5 + 2)) # \u0026gt; 7 n=5 echo $((n=n+5)) # \u0026gt; 10 # (($n=$n+5))とnに$を$を付ける必要はないです echo $n # \u0026gt; 10 # 演算子は # + - * / % ** ++ -- # bashでは実数の計算はできない. echo $((10/3)) # \u0026gt; 3 if分 #!/bin/bash  read -p \u0026#34;Name? \u0026#34; name # if test \u0026#34;$name\u0026#34; = \u0026#34;taro\u0026#34; if [ \u0026#34;$name\u0026#34; = \u0026#34;taro\u0026#34; ] then echo \u0026#34;welcome\u0026#34; elif [ \u0026#34;$name\u0026#34; = \u0026#34;hanako\u0026#34; ] then echo \u0026#34;welcome too\u0026#34; else echo \u0026#34;you are not allowed\u0026#34; fi # 以下のように; thenという書き方もあります. if [ \u0026#34;$name\u0026#34; = \u0026#34;taro\u0026#34; ]; then echo \u0026#34;welcome\u0026#34; elif [ \u0026#34;$name\u0026#34; = \u0026#34;hanako\u0026#34; ]; then echo \u0026#34;welcome too\u0026#34; else echo \u0026#34;you are not allowed\u0026#34; fi 上記を実行すると\nbash 07_if \u0026gt; Name? taro \u0026gt; welcom または\nbash 07_if \u0026gt; Name? hanako \u0026gt; welcome too または\nbash 07_if \u0026gt; Name? test \u0026gt; you are net allowed 文字列の比較 08_compare_stringsの中身をご覧ください.\n#!/bin/bash # 文字列の比較には[]も使われますが, # 最近では[[]]がよく使われる. read -p \u0026#34;Name? \u0026#34; name if [ \u0026#34;$name\u0026#34; = \u0026#34;taro\u0026#34; ]; then echo \u0026#34;welcome\u0026#34; fi # と書くところを, if [[ $name = \u0026#34;taro\u0026#34; ]]; then echo \u0026#34;welcome\u0026#34; fi # と書く. # = or == が文字列が等しいかどうかを調べる # != が文字列が等しくないかどうかを調べる # -z が文字列が0かどうかを調べる # =~ が正規表現を使う if [[ -z $name ]]; then echo \u0026#34;Name is empty ...\u0026#34; fi # 上記を実行すると, # bash 08_compare_strings # \u0026gt; Name? # ENTER # \u0026gt; Name is empty ... # となる. if [[ $name =~ ^t ]]; then echo \u0026#34;Name is starting with t...\u0026#34; fi # 上記を実行すると, # bash 08_compare_strings # \u0026gt; Name? # taro # \u0026gt; Name is starting with t... # となる. ファイルや数値の比較 #!/bin/bash # ifを使うよ # -e : 種類を問わずに対象物が存在するかどうかを判定 # -f : ファイルが存在しているかどうかを判定 # -d : ディレクトリが存在しているかどうかを判定 # このファイルが存在するのかどうかの判定 if [[ -f $0 ]]; then echo \u0026#34;file exists ...\u0026#34; fi # 出力は # file exists ... if [[ -d $0 ]]; then echo \u0026#34;dir exists ...\u0026#34; fi # 出力は何もされない. # このファイルはディレクトリでないから. # 数値の比較は read -p \u0026#34;Number? \u0026#34; n if ((n \u0026gt; 10)); then echo \u0026#34;bigger than 10\u0026#34; fi # 比較演算子は # == # != # \u0026gt; # \u0026gt;= # \u0026lt; # \u0026lt;= # が使える. # 条件を組み合わせることもできる. # \u0026amp;\u0026amp; : 積集合 # || : 和集合 # ! : not for文 10_forをご覧ください.\n#!/bin/bash  # 1 2 3 4 5 と縦に表示 for i in 1 2 3 4 5 do echo $i done # 1 2 3 4 5 と縦に表示 for i in {1..5} do echo $i done # 1 2 3 4 5 と縦に表示 for i in {1..5}; do echo $i done # 1 2 3 4 5 と縦に表示 for ((i=1; i\u0026lt;=5; i++)); do echo $i done # red green blue と縦に表示 colors=(red green blue) for color in ${colors[@]}; do echo $color done # スペースで区切られた日付の要素を縦に表示 # for item in `date`; do for item in $(date); do echo $item done while文 #!/bin/bash  i=0 1 2 3 と縦に表示される while ((i \u0026lt; 3)); do ((i++)) echo $i done # continue でwhile処理をスキップ # break でwhile処理を強制終了 # 1 2 3 5 6 7 と縦に表示される while((i \u0026lt; 10));do ((i++)) if ((i == 4)); then continue fi if((i == 8)); then break fi echo $i done # : はnullコマンドと言われていて, いつでも条件が成立するコマンド # これを使って無限ループを作れる # quit と打ち込まれると終了するプログラム while : do read -p \u0026#34;Command? \u0026#34; cmd if [[ $cmd == \u0026#34;quit\u0026#34; ]]; then break else echo \u0026#34;$cmd\u0026#34; fi done catでテキストファイルの中身に文字を保存する cat \u0026gt; colors.txt red green blue # CTL + d # で保存 whileを使って, テキストファイルの中身を1行ずつ読み込む #!/bin/bash  i=1 # colors.txtの中身が1行ずつ読み込まれて標準出力に表示される while read line; do echo $i \u0026#34;$line\u0026#34; ((i++)) done \u0026lt; colors.txt catとwhileを使って, catで表示するものに行番号を付ける # 13_add_numberの中身 #!/bin/bash  i=1 while read line; do echo $i \u0026#34;$line\u0026#34; ((i++)) done 上記を実行すると\ncat colors.txt | bash 13_add_number \u0026gt; 1 red \u0026gt; 2 green \u0026gt; 3 blue caseを使って条件分岐 # 14_caseの中身 #!/bin/bash  read -p \u0026#34;Signal color? \u0026#34; color case \u0026#34;$color\u0026#34; in red) echo \u0026#34;stop\u0026#34; ;; blue|green) echo \u0026#34;go\u0026#34; ;; yellow) echo \u0026#34;caution\u0026#34; ;; *) echo \u0026#34;wrong signal\u0026#34; ;; esac 上記を実行すると\nbash 14_case \u0026gt; Signal color? blue \u0026gt; go または\nbash 14_case \u0026gt; Signal color? yellow \u0026gt; caution または\nbash 14_case \u0026gt; Signal color? red \u0026gt; stop selectを使ってメニューを作る # 15_selectの中身 #!/bin/bash  # select の中身はループになってるのでbreakで終わらせてあげる select color in red blue green yellow; do case \u0026#34;$color\u0026#34; in red) echo \u0026#34;stop\u0026#34; ;; blue|green) echo \u0026#34;go\u0026#34; ;; yellow) echo \u0026#34;caution\u0026#34; ;; *) echo \u0026#34;wrong signal\u0026#34; break esac done 上記を実行すると\nbash 15_select \u0026gt; 1) red \u0026gt; 2) blue \u0026gt; 3) green \u0026gt; 4)yello \u0026gt; #? 1 \u0026gt; stop 2 \u0026gt; go 3 \u0026gt; go 4 \u0026gt; caution 5 \u0026gt; wrong signal 関数を使う #!/bin/bash  # function hello() { # echo \u0026#34;hello ...\u0026#34; # } # function は省略することもでき hello() { echo \u0026#34;hello ...\u0026#34; } hello # \u0026gt; hello ... # function へは引数を渡すことももちろんでき hello2() { echo \u0026#34;hello $1\u0026#34; } hello2 taro # \u0026gt; hello taro # 関数の中でifももちろん使える hello3() { if [[ $1 == \u0026#34;taro\u0026#34; ]]; then return 0 # 0 がtrue else return 1 # 1 がfalse fi } # 直前の終了ステータスは$?で調べることができる hello3 taro; echo $? # \u0026gt; 0 hello3 sola; echo $? # \u0026gt; 1 変数スコープ #!/bin/bash  hello() { name=\u0026#34;taro\u0026#34; echo \u0026#34;hello ...\u0026#34; } hello # \u0026gt; hello ... echo $name # \u0026gt; taro # 関数の中の変数にアクセスできる # それをさせないようにするには hello2() { local name2=\u0026#34;sola\u0026#34; echo \u0026#34;hello world\u0026#34; } hello2 # \u0026gt; hello world echo $name2 # 何も表示されない # name2はlocalが付いているので, # hello2の関数内だけで使える"},{"idx":128,"href":"/docs/substrate/","title":"Substrate","content":" Substrateとは  カスタムブロックチェーンプログラムを開発するためのフレームワークのこと. Runtime, SRML, SKD, Client Appを作ることができる. オープンソースで提供されている. 開発元はParity Technologies. Githubリポジトリ: https://github.com/paritytech/substrate References:  第7回ブロックチェーン勉強会 なぜSubstrateでブロックチェーンを作るのか   Substrateを学んでみる  SubstrateKitties 初心者のためのPolkadot Polkadot / Substrateの必読資料をまとめた Staked Substrate/Polkadot  "},{"idx":129,"href":"/docs/terminal/","title":"Terminal","content":" ターミナルとは  GUIの上でCUIの操作をしたいときに使用するアプリケーションのこと.  コンソール/ターミナル/シェルの違い  コンソールとは入出力をつかさどる端末ハードウェア ターミナルとはGUIでCUI環境を再現するもの シェルとはCUI環境におけるOSとの対話的インターフェイス  Reference: 【初心者向け】シェル・ターミナル・コンソールの違いとは？   下地にシェルがありコンソールやターミナルから命令をOSへ伝達してくれる.\nコンソールでアクセスしてもターミナルでアクセスしても対話するものはシェルとなる.\nコンソールの場合はハードウェア的に直にアクセスしているがターミナルの場合はGUI環境でソフトウェア的にシェルを呼び出し命令を実行するようになっている.\nターミナルの色を変える ~/.bashrcの当該部分を以下の様に書き換える.\nif [ \u0026#34;$color_prompt\u0026#34; = yes ]; then PS1=\u0026#39;${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\[\\033[01;31m\\]$(__git_ps1)\\[\\033[00m\\]\\n\\[\\033[01;35m\\]-\u0026gt; \\$\\[\\033[00m\\] \u0026#39; else PS1=\u0026#39;${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ \u0026#39; fi ターミナルのJSON出力に色付けする jqを使う.\n# こんな感じ echo \u0026#39;{\u0026#34;items\u0026#34;:[{\u0026#34;item_id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;すてきな雑貨\u0026#34;,\u0026#34;price\u0026#34;:2500},{\u0026#34;item_id\u0026#34;:2,\u0026#34;name\u0026#34;:\u0026#34;格好いい置物\u0026#34;,\u0026#34;price\u0026#34;:4500}]}\u0026#39; | jq . \u0026gt; { \u0026gt; \u0026#34;items\u0026#34;: [ \u0026gt; { \u0026gt; \u0026#34;item_id\u0026#34;: 1, \u0026gt; \u0026#34;name\u0026#34;: \u0026#34;すてきな雑貨\u0026#34;, \u0026gt; \u0026#34;price\u0026#34;: 2500 \u0026gt; }, \u0026gt; { \u0026gt; \u0026#34;item_id\u0026#34;: 2, \u0026gt; \u0026#34;name\u0026#34;: \u0026#34;格好いい置物\u0026#34;, \u0026gt; \u0026#34;price\u0026#34;: 4500 \u0026gt; } \u0026gt; ] \u0026gt; } Reference: jq コマンドを使う日常のご紹介\n"},{"idx":130,"href":"/docs/test/","title":"Test","content":" テストとは  書いたコードにバグがないか確認する行為.  テストの種類  単体テスト: 入力をモック化し, 個々の関数やクラスをテストし, 出力結果が予想通りであることを確認するテスト. 統合テスト: いくつかのモジュールを組み合わせて予想通りに動作することを保証するテスト. 機能テスト: 製品自体を使って(例えばブラウザを使って), あるシナリオをテストする. 確実に想定した動作をするかといった内部構造は考慮しない. リグレッションテスト: プログラムに機能を追加したり変更を加えたことによって、今まで普通に動いていた部分が動かなくなっていないかを確認するテスト. 受け入れテスト: システム開発を外注して, 発注者の本来の目的や意図通りに稼働するかのテスト. References:  2017年JavaScriptのテスト概論 テストの種類と技法   "},{"idx":131,"href":"/docs/travis-ci/","title":"Travis Ci","content":" Travis CIとは  GitHub上のソフトウェアのビルドやテストを行う, オンラインで分散型の継続的インテグレーション(CI)サービスのこと. https://travis-ci.org が無料でオープンソースのプロジェクト用, https://travis-ci.com が有料でプライベートリポジトリ用の利用ができる.  Travis CiからAWS Elastic Beanstalkへ  AWS Elastic Beanstalk Deployment  Dokcerのテストがpassedにならない時の対処法 Travis CIでDockerのテストを以下のように設定するとpassedにならないことがある.\nscript: docker run solareenlo/react-test npm run test -- --coverage そんな時は以下のようにテストを設定する.\nscript: docker run -e CI=true solareenlo/react-test npm run test -- --watchAll=falseb 環境変数が設定できない時 Travis CIの環境変数を設定する項目では特殊文字(; \u0026amp; ( ) | ^ \u0026lt; \u0026gt; ? * [ ] $ ` \u0026lsquo; \u0026ldquo; \\ ! { } 改行 タブ スペース)がそのままの入力ではエスケープされないので, シングルクォーテーション(\u0026ldquo;)で囲む必要がある.\n# 例 =rrTDKhZYgT2Zm4\u0026amp;TF+D^pyp84Uf9[Tw7xZ9Parhx[$A83QCGRb.NKxAnqUd%7(t を\n# 例 \u0026#39;=rrTDKhZYgT2Zm4\u0026amp;TF+D^pyp84Uf9[Tw7xZ9Parhx[$A83QCGRb.NKxAnqUd%7(t\u0026#39; と入力する.\n秘密情報を暗号化 DockerでTravis CLIを使って送る.\ndocker run -it -v $(pwd):/app ruby:2.3 sh gem install travis --no-document gem install travis travis login \u0026gt; Username: solareenlo \u0026gt; Password for solareenlo: ****************************** \u0026gt; Two-factor authentication code for solareenlo: 999999 \u0026gt; Successfully logged in as solareenlo! # そして$(pwd)に秘匿情報が載ったファイル(ここではservice-account.json)を置いて, # 以下でTravis CIのsolareenlo/multi-k8s-gke用にservice-account.jsonを暗号化するし, # Travis CIの当該プロジェクトに登録もする. travis encrypt-file service-account.json -r solareenlo/multi-k8s-gke これで, service-account.jsonファイルから暗号化されたservice-account.json.encファイルが作成される.\n"},{"idx":132,"href":"/docs/typescript/","title":"Typescript","content":" TypeScriptとは  マイクロソフトによって開発されているオープンソースのプログラミング言語のこと. JavaScriptに, 静的型付け・クラスベースオブジェクト指向を加えた. GitHubリポジトリ: https://github.com/Microsoft/TypeScript  初めてのTypeScript solareenlo/Typescript-Practice/01_Getting_Started\nインストール npm i --save-dev typescript TypeScript + Node.js + Docker + Circle CI  TypeScript + Node.js プロジェクトのはじめかた2019 TypeScriptでExpress.js開発するときにやることまとめ (docker/lint/format/tsのまま実行/autoreload) bitjson/typescript-starter microsoft/TypeScript-Node-Starter  objectのkeyにstringを設定したら, object[key]でエラーになった時の対処法  tsconfigに--suppressImplicitAnyIndexErrorsを付け加える. ブラケット記法でプロパティにアクセスした時にany型を許容するのでとっても非推奨. 以下のようにkeyはstring型と明示する. 問題点はkeyが全てstring型になること.\ninterface ISomeObject { firstKey: string; secondKey: string; [key: string]: string; // \u0026lt;-この行を追加! } const obj = { firstKey: \u0026#34;a\u0026#34;, secondKey: \u0026#34;b\u0026#34;, } as ISomeObject; const key: string = \u0026#39;secondKey\u0026#39;; const secondValue: string = obj[key]; なのでこうする. が, secondValueの型がstring|boolean|number型と複数の型になる.\ninterface ISomeObject { firstKey: string; secondKey: number; thirdKey: boolean [key: string]: string|boolean|number; //\u0026lt;-or条件で型を指定 } const key: string = \u0026#39;secondKey\u0026#39;; const secondValue = obj[key]; // secondValue =\u0026gt; string|boolean|number型 keyofを使う.\ninterface ISomeObject { firstKey: string; secondKey: number; thirdKey: boolean; } const obj = { firstKey: \u0026#34;a\u0026#34;, secondKey: 2, thirdKey: false } as ISomeObject; const key: keyof ISomeObject = \u0026#39;secondKey\u0026#39;; // ここを変更 const secondValue = obj[key]; // secondValueがnumber型に! ジェネリクスを使って、type safeにブラケット記法が使える関数を作ると以下の感じになる.\nconst accessByBracket = \u0026lt;S, T extends keyof S\u0026gt;(obj: S, key: T) =\u0026gt; { return obj[key]; }; const obj = { firstKey: \u0026#34;a\u0026#34;, secondKey: 2, thirdKey: false } as ISomeObject; const value = accessByBracket(obj, \u0026#39;secondKey\u0026#39;); // value =\u0026gt; 2  Reference: Typescript ブラケット記法(Object[key])でno index signatureエラーをtype safeに解決したい。\n"},{"idx":133,"href":"/docs/ubuntu/","title":"Ubuntu","content":" Ubuntuとは  コミュニティにより開発されているオペレーティングシステムのこと. 無料で提供されている. Linuxディストリビューションの1つ. 公式サイト: https://www.ubuntu.com  Raid0作成  Reference: How To Create RAID Arrays with mdadm on Ubuntu 18.04  ターミナルの色を変える ~/.bashrcの当該部分を以下の様に書き換える.\nif [ \u0026#34;$color_prompt\u0026#34; = yes ]; then PS1=\u0026#39;${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\[\\033[01;31m\\]$(__git_ps1)\\[\\033[00m\\]\\n\\[\\033[01;35m\\]-\u0026gt; \\$\\[\\033[00m\\] \u0026#39; else PS1=\u0026#39;${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ \u0026#39; fi 再起動 sudo shutdown -r now // or sudo reboot mountしているSSDのlabel名を変更する Ubuntuのディスクプリで当該のSSDをmountする.\ndf -Th \u0026gt; Filesystem Type Size Used Avail Use% Mounted on \u0026gt; /dev/nvme2n1p1 ext4 234G 61M 222G 1% /media/solareenlo/ssd021 でSSDのFilesystem名(この場合は/dev/nvme2n1p1)を確認する.\nsudo umount /dev/nvme2n1p1 で一度SSDをunmountする.\nSSDのTypeがext2/ext3/ext4の場合は,\nsudo e2label /dev/nvme2n1p1 ssd02 とし, label名をssd021からssd02に変更する.\nそして, Ubuntuのディスクアプリで当該のSSDをmountする.\nsnapでのupdate snapとはLinuxのパッケージ管理システムの1つ.\nsnap refresh バージョン確認 cat /etc/os-release aptチートシート    コマンド 内容     sudo apt update リポジトリ一覧を更新\n(リポジトリ追加・削除時には必ず実行すること)   sudo apt upgrade パッケージを更新\n(通常のパッケージ更新時はこのコマンドを使用する)   sudo apt full-upgrade パッケージを更新\n(保留されているパッケージを更新するときに使用する)   sudo apt autoremove 更新に伴い必要なくなったパッケージを削除\n(apt実行時にこのコマンドを実行するよう表示されたら実行する)   sudo apt install {パッケージ名やdebファイルのパス} パッケージやdebファイルをインストール   sudo apt remove {パッケージ名} パッケージを削除   sudo apt remove \u0026ndash;purge {パッケージ名} パッケージを完全削除   sudo apt show {パッケージ名} パッケージの詳細情報を表示   sudo apt list {パッケージ名} パッケージを検索(完全一致)   sudo apt search {パッケージ名} パッケージを検索(部分一致)   sudo dpkg -l インストール済みのパッケージ一覧を表示   sudo dpkg -L {パッケージ名} パッケージのインストール先を表示   cat /var/log/apt/history.log aptコマンドの使用履歴を表示   sudo apt autoclean キャッシュされているが, インストールはされていないdebファイルを削除   sudo apt clean キャッシュされている全てのdebファイルを削除   echo \u0026ldquo;{パッケージ名} hold\u0026rdquo; dpkg \u0026ndash;set-selections   echo \u0026ldquo;{パッケージ名} install\u0026rdquo; dpkg \u0026ndash;set-selections    Referecne: aptコマンドチートシート\nアプリがインストールされてる場所  Ubuntuソフトウェアおよびターミナルからインストールした場合は/usr/libにインストールされてる. webからアプリをインストールした場合は/optにインストールする.  PATHの確認 echo $PATH | tr -s \u0026#34;:\u0026#34; \u0026#34;\\n\u0026#34;"},{"idx":134,"href":"/docs/vim/","title":"Vim","content":" Vimとは  viから派生したテキストエディタ. プラグインを導入したり, .vimrcの設定を変更したりして, 自分好みにカスタマイズがどんどんできる. GitHubリポジトリ: https://github.com/vim/vim  ソースからインストール スクラッチからインストール git clone git@github.com:vim/vim.git cd vim ./configure make sudo make install インストールし直す cd vim make distclean rm src/auto/config.cache ./configure make sudo make install clipboard機能とclientserver機能を付けてインストール cd /mnt/md0/github git clone git@github.com:vim/vim.git cd vim make distclean rm src/auto/config.cache # 必要なパッケージをインストール sudo apt install \\  lua5.2 \\  liblua5.2-dev \\  luajit \\  libluajit-5.2 \\  ruby-dev \\  xorg-dev # /usr/include/lua5.2/の中身を/usr/include/lua5.2/include/へコピーする cd /usr/include/lua5.2 sudo mkdir include cp *.h include/ # libluaのシンボリックリンクを張る sudo ln -s /usr/lib/x86_64-linux-gnu/liblua5.3.so /usr/local/lib/liblua.so cd /mnt/md0/github/vim # 必要なオプションを付けて./configureを行う ./configure \\  --with-features=huge \\  --with-x \\  --enable-multibyte \\  --enable-luainterp=dynamic \\  --enable-gpm \\  --enable-cscope \\  --enable-fontset \\  --enable-fail-if-missing \\  --prefix=/usr/local \\  --enable-pythoninterp=dynamic \\  --enable-python3interp=dynamic \\  --enable-rubyinterp=dynamic \\  --enable-gui=auto \\  --enable-gtk2-check \\  --disable-darwin \\  --with-lua-prefix=/usr/local # --disable-darwin は, macOSでmakeするときに必要. # macOSの場合, 最後の \u0026#39;--with-lua-prefix\u0026#39; を指定しないとconfigure時に \u0026#39;configure: error: could not configure lua\u0026#39; が出てしまう. # makeする make # インストールする sudo make install vim --version References  vimtex on macOS でハマったときのメモ Linuxでのビルド方法 WSLにVim8を入れてみる vimでclipboardを+にしたいけどならない人向け Mac上のVimを最新にした際のメモ(LuaJIT対応) Vim can\u0026rsquo;t build the athena GUI on macOS High Sierra #2444  .vimrcの例  .vimrcとはvimの設定を書いてあるファイル. solareenlo/vim-config よく使われているvimrcの設定ランキング  使い方 削除    コマンド 動作     D カーソル以降を削除    置換    コマンド 動作     :%s/old/new/c ファイル上のoldを1つずつ確認しながらnewに置換   :%s/old/new/g ファイル上の全てのoldをnewに置換   :s/old/new/g カーソル行の全てのoldをnewに置換   :10,20s/old/new/g 10~20行目の全てのoldをnewに置換   :'\u0026lt;,'\u0026gt;s/old/new/g ビジュアルモードで選択中の範囲の全てのoldをnewに置換.\n'\u0026lt;,'\u0026gt;の部分は, 範囲を選択中に:を押すと自動的に出る.    外部コマンド実行 :!を使う.\nvim # vimモードに突入 :!ls # lsを表示してくれる 新規にファイル作成 :eを使う.\nvim # vimモードに突入 :e test.txt # test.txtが作られる References  さっさと帰りたい怠け者エンジニアは vim をマスターしましょう その2 - 編集 さっさと帰りたい怠け者エンジニアは vim をマスターしましょう その1 - 基本と移動 新人達を1ヶ月でガチvimmerにした方法  オススメのプラグイン  よく使われているvimのプラグイン top20 オレ的vimプラグイン10選  プラグインマネージャー たくさんのプラグインを簡単にインストールできるマネージャー.\ndein.vim  Shougo/dein.vim  curl https://raw.githubusercontent.com/Shougo/dein.vim/master/bin/installer.sh \u0026gt; installer.sh # For example, we just use `~/.cache/dein` as installation directory sh ./installer.sh ~/.cache/dein そして, vimを開いて,\n:call dein#install() # プラグインをインストール :call dein#update() # プラグインをアップデート コメントアウト tcomment  tomtom/tcomment_vim  # 複数行コメントアウト # SHIFT + V で複数行を選択してから, gc # 1行コメントアウト gcc シンボル置換 surround.vim  tpope/vim-surround  \u0026ldquo;Hello World!\u0026rdquo;\n# 単語の終始の置換(\u0026#39;→\u0026#34;) cs\u0026#39;\u0026#34; # 単語の終始の\u0026#34;削除 ds\u0026#34; ツリー表示 NERDTree  scrooloose/nerdtree  ファイル操作    o(enter) ファイルを開く     go ファイルを開き、カーソルはツリーに保持する   t タブで開く   T タブで開き、移動はしない   i 水平分割して開く   gi 水平分割して開き、移動はしない   s 垂直分割して開く   gs 垂直分割して開き、移動はしない    ディレクトリ操作    コマンド 説明     o(enter) フォルダを開く   O 再帰的にディレクトリをすべて開く   x 親ディレクトリを閉じる   X 再帰的にすべての子ディレクトリを閉じる   e 新しいツリーを生成する    ツリー操作    コマンド 説明     P ルートディレクトリへ移動   p 親ディレクトリへ移動   K 一番上へ移動   J 一番下へ移動   Ctrl+k 一つ上へ移動   Ctrl+j 一つ下へ移動    ファイルシステム    コマンド 説明     C ツリーのルートを選択したディレクトリに変更   u ツリーのルートを上の階層にする   U 変更前のツリーの状態を保持して、ツリーのルートを上の階層にする   r 選択したディレクトリをリフレッシュする   R ツリーのルートをリフレッシュする   m メニューを表示する   cd 選択したディレクトリにcwdを変更する   CD cwdをツリールートに変更する    その他    コマンド 説明     I 隠しファイルの表示、非表示   B ブックマークの表示・非表示   F ファイルの表示・非表示    アイコン表示 vim-devicons  ryanoasis/vim-devicons  手順  Nerdフォント(アイコンが含まれているフォント)をダウンロードして設定  LinuxだとGitHubから好きなフォントをダウンロード MacだとHomebrewを使ってフォントをダウンロードが簡単  Homebrewでインストールしたフォントだとhack-nard-fontを設定する   vim-deviconsプラグインをダウンロード\u0026amp;インストール  プラグインランキング  VimAwesome  Vim Script  モテる男のVim script短期集中講座  "},{"idx":135,"href":"/docs/vimium/","title":"Vimium","content":" Vimiumとは  Google Chromeをvimのキーバインドで操作できるChromeの拡張機能. GitHubリポジトリ: philc/vimium  操作方法 現在のページ ? show the help dialog for a list of all available keys h scroll left j scroll down k scroll up l scroll right gg scroll to top of the page G scroll to bottom of the page d scroll down half a page u scroll up half a page f open a link in the current tab F open a link in a new tab r reload gs view source i enter insert mode -- all commands will be ignored until you hit Esc to exit yy copy the current url to the clipboard yf copy a link url to the clipboard gf cycle forward to the next frame gF focus the main/top frame 新しいページ o Open URL, bookmark, or history entry O Open URL, bookmark, history entry in a new tab b Open bookmark B Open bookmark in a new tab 検索 / enter find mode -- type your search query and hit enter to search, or Esc to cancel n cycle forward to the next find match N cycle backward to the previous find match 履歴 H go back in history L go forward in history タブ J, gT go one tab left K, gt go one tab right g0 go to the first tab g$ go to the last tab ^ visit the previously-visited tab t create tab yt duplicate current tab x close current tab X restore closed tab (i.e. unwind the \u0026#39;x\u0026#39; command) T search through your open tabs W move current tab to new window \u0026lt;a-p\u0026gt; pin/unpin current tab マーク ma, mA set local mark \u0026#34;a\u0026#34; (global mark \u0026#34;A\u0026#34;) `a, `A jump to local mark \u0026#34;a\u0026#34; (global mark \u0026#34;A\u0026#34;) `` jump back to the position before the previous jump -- that is, before the previous gg, G, n, N, / or `a 追加機能 ]], [[ Follow the link labeled \u0026#39;next\u0026#39; or \u0026#39;\u0026gt;\u0026#39; (\u0026#39;previous\u0026#39; or \u0026#39;\u0026lt;\u0026#39;) - helpful for browsing paginated sites \u0026lt;a-f\u0026gt; open multiple links in a new tab gi focus the first (or n-th) text input box on the page gu go up one level in the URL hierarchy gU go up to root of the URL hierarchy ge edit the current URL gE edit the current URL and open in a new tab zH scroll all the way left zL scroll all the way right v enter visual mode; use p/P to paste-and-go, use y to yank V enter visual line mode"},{"idx":136,"href":"/docs/vps/","title":"Vps","content":" VPS(バーチャル・プライベート・サーバ)とは  一台の物理的なサーバコンピュータ上で仮想的なサーバコンピュータを何台も起動する技術によってつくられた仮想的なサーバコンピュータのこと. 暗号通貨のフルノードを立てることができる.  世界のVPSの値段比較サイト  VPSCOMP  "},{"idx":137,"href":"/docs/white-paper/","title":"White Paper","content":" ホワイトペーパーとは  問題に対する解決策を提示した文章のこと. 元々は政府や公的機関による年次報告書(白書)を意味したが現在ではマーケティング用語として使われている. 暗号通貨/暗号資産プロジェクトにおいてもよく使われている.  ホワイトペーパーの日本語訳一覧  Bitcoin: ビットコイン： P2P 電子通貨システム Ethereum: [Japanese] White Paper  Plasma: Plasma スケーラブルな自律型スマートコントラクト  IOTA: The Tangle Byteball: Byteball:価値の蓄積と移転のための分散型システム Nano: ナノ：手数料不要で分散された仮想通貨ネットワーク NEO: NEO：スマートな経済のための分散型ネットワーク Enigma: Enigma: プライバシーが保証された分散型コンピューティングプラットフォーム IPFS: IPFS POLKADOT: POLKADOT: VISION FOR A HETEROGENEOUS MULTI-CHAIN FRAMEWORK DRAFT 1  "},{"idx":138,"href":"/docs/zathura-install/","title":"Zathura Install","content":" zathuraのインストール方法  以下zathuraインストールに必要なものをどんどんインストールしていきます. まだ未完.  mesonをインストール  mesonはオープンソースビルドシステムのこと.\n# python3やもろもろをインストールする sudo apt-get install python3 python3-pip python3-setuptools python3-wheel ninja-build # pipを使ってmersonをインストールする pip3 install --user meson # PATHを通す(bash向け) PATH=\u0026#34;${PATH}:$(python -c \u0026#39;import site; print(site.USER_BASE);\u0026#39;)/bin\u0026#34;  cmakeをインストール sudo apt remove cmake git clone git@gitlab.kitware.com:cmake/cmake.git cd cmake ./bootstrap \u0026amp;\u0026amp; make \u0026amp;\u0026amp; sudo make install libmount-devをインストール sudo apt update sudo apt upgrade -y sudo apt install libmount-dev glibをインストール git clone https://gitlab.gnome.org/GNOME/glib.git cd glib meson build ninja -C build sudo ninja -C build install# もしくは sudo apt update sudo apt upgrade -y sudo apt install libglib2.0-dev gtkをインストール git clone https://gitlab.gnome.org/GNOME/gtk.git # まだ依存関係を調査中# または sudo apt update sudo apt upgrade -y sudo apt install libgtk-3-dev giraraをインストール git clone git@github.com:pwmt/girara.git cd girara meson build \u0026amp;\u0026amp; cd build ninja sudo ninja install# または sudo apt update sudo apt upgrade -y sudo apt install libgirara-gtk3-3 mupdfをインストール git clone --recursive git://git.ghostscript.com/mupdf.git cd mupdf git submodule update --init make prefix=/usr/local install# または sudo apt update sudo apt upgrade -y sudo apt install libmupdf-dev mupdf mupdf-tools zathuraをインストール git clone git@github.com:pwmt/zathura.git cd zathura meson build \u0026amp;\u0026amp; cd build ninja sudo ninja install zathura-pdf-mupdfをインストール git clone git@github.com:pwmt/zathura-pdf-mupdf.git cd zathura-pdf-mupdf meson build \u0026amp;\u0026amp; cd build ninja sudo ninja install zathura-pdf-popplerをインストール git clone git@github.com:pwmt/zathura-pdf-poppler.git cd zathura-pdf-poppler meson build \u0026amp;\u0026amp; cd build ninja sudo ninja install"},{"idx":139,"href":"/docs/zeit-now/","title":"Zeit Now","content":" ZEIT Nowとは  サーバーレスデプロイのためのクラウドプラットフォームサービスのこと.  サブドメインの割り当て方  まずはメインドメインをNowに登録する.\nnow domains add iotajapan.com サブドメインのエイリアスを登録しようとする.\n# 以下を実行すると, now alias https://my-docs.test.now.sh docs.iotajapan.com # 以下のようなエラーが返ってくる. Error! We could not alias since the domain iotajapan.com could not be verified due to the following reasons: a) Nameservers verification failed since we see a different set than the intended set: Intended Nameservers Current Nameservers c.zeit-world.co.uk 01.dnsv.jp ☓ d.zeit-world.org 02.dnsv.jp ☓ e.zeit-world.com 03.dnsv.jp ☓ f.zeit-world.net 04.dnsv.jp ☓ b) DNS TXT verification failed since found no matching records. name type value _now TXT abc...xyz Once your domain uses either the nameservers or the TXT DNS record from above, run again `now domains verify \u0026lt;domain\u0026gt;`. We will also periodically run a verification check for you and you will receive an email once your domain is verified. Read more: https://err.sh/now-cli/domain-verification お名前.comのNameserverを使用するとして, 返ってきたエラーの内容でDNS TXTレコードを登録する.\n   ホスト名 TYPE TTL VALUE     _now.iotajapan.com TXT 3600 abc\u0026hellip;xyz    ドメインの所有者認証を確かめる.\n# 以下を実行し, now domains veryfy iotajapan.com # 以下のように返ってきたら認証されてる. Success! Domain iotajapan.com was verified using DNS TXT record. [500ms] You can verify with nameservers too. Run `now domains inspect iotajapan.com` to find out the intended set. DNS CNAMEレコードを登録する.\n   ホスト名 TYPE TTL VALUE     docs.iotajapan.com CNAME 3600 alias.zeit.co    now.jsonを以下のように設定する.\n{ \u0026#34;version\u0026#34;: 2, \u0026#34;alias\u0026#34;: \u0026#34;docs.iotajapan.com\u0026#34; } nowにデプロイする.\nnow --target production References\n Now インスタンスに独自ドメインを設定する ZEITのnow(v2)でデプロイしたらドメインaliasを最新のデプロイに追従させる   "},{"idx":140,"href":"/docs/bitcoin/","title":"Bitcoin","content":" Bitcoinとは GitHubリポジトリ: https://github.com/bitcoin\n目的 匿名性を自分で選択できつつ, 安全に価値の移転と保存に特化したシステムを構築すること.\n特徴  非中央集権 自律分散 トラストレス 耐改ざん性 オープンソース 匿名性を選択できる 二重支払いができない 払い(価値の保存と移転)に特化したとても堅牢なシステム(チューリング不完全/マルチシグ/HDウォレット/ニーモニック/Base58とか)  技術  電子署名 公開鍵暗号  楕円曲線DSA  暗号学的ハッシュ関数  現像計算困難性 (ハッシュ値から元のメッセージを復元できない) 第二現像計算困難性 (同じハッシュ値になる任意のメッセージがない) 衝突安全性 (任意のメッセージのハッシュ値が衝突しない)  ネットワーク  P2P Proof of Work  スタックマシン  ブロック スクリプト オペコード  マークル木 コンセンサスアルゴリズム  プレイヤー  コア開発者 マイナー ユーザー 投資家・投機家 法律  スケーリング方法  コンセンサスアルゴリズムを速くする（分散性のために1ブロック生成にわざと10分かけてる） ブロックに含まれるトランザクションを増やす（Block weightが4MB以下/segwit導入により） オフチェーン（Lightning networkなど） サイドチェーン シャーディング Reference: ブロックチェーンとスケーラビリティ  フルノード フルノードの立て方  ビットコインのフルノードを立てる方法 Bitcoin ClockUpMemo bitcoindのブロック保存先ディレクトリを指定する Bitcoin.conf Configuration File  フルノードの分布図  BITNODES  マイナーとノードの違い  マイナーも1つのノードではあるが, マイナーの主な役割はプルーフオブワーク（PoW）を行い取引をブロックに収納しネットワークに送信すること. マイナー以外のユーザーがノードを立ち上げる主な目的は, 取引が正しくブロックに取り込まれたかを検証しブロックチェーンに追加する. マイナーには新規発行のビットコインの取得という経済的インセンティブがある. ノードを立ち上げるユーザーには, 自身で取引の正当性を検証することができることと, ノードが増えることで非中央集化するネットワークのセキュリティを強化するというインセンティブがある. Reference: ノードの分布状況から紐解く、世界に広がるビットコインのネットワーク  bitcoindとbitcoin-cliの違い  bitcoind: Bitcoinの一通りの機能を実装したしたサーバーのこと.  Bitcoinネットワーク(P2Pネットワーク)との通信のフル機能 ウォレット機能 マイニングプール マイニング JSON-RPC APIサーバー  bitcoin-cli: JSON-RPCを使って, bitcoindと通信し, 様々な操作を行えるツールのこと. References: Bitcoinウォレットの比較  bitcoindにcurlでアクセス # getblockinfo curl --data-binary \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;1.0\u0026#34;,\u0026#34;id\u0026#34;:\u0026#34;curltext\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;getblockchaininfo\u0026#34;,\u0026#34;params\u0026#34;:[]}\u0026#39; -H \u0026#39;content-type:text/plain;\u0026#39; http://solareenlo:solareenlo@127.0.0.1:8332/ | jq bitcoin-cliとxargsの使用例 # ブロック高が一番高いブロックの内容を出力する例 bitcoin-cli getbestblockhash | xargs bitcoin-cli getblock # 最新ブロックのcoinbase txのトランザクションIDを取得する例 bitcoin-cli getblockhash 1 | xargs -IXXX bitcoin-cli getblock XXX 2 | jq \u0026#34;.tx[0].txid\u0026#34; # 最新ブロックの一番初めのトランザクション内容を表示する例 bitcoin-cli getbestblockhash | xargs bitcoin-cli getblock | jq \u0026#34;.tx[0]\u0026#34; | xargs bitcoin-cli getrawtransaction | xargs bitcoin-cli decoderawtransaction References: 開発によく使うbitcoin 関連cliツール\nbitcoin-cliを使ってUTXOを集める  Output Descriptorとscantxoutsetを使ってUTXOセットをスキャンする  Blockchainの中身の見方  blk.dat  アドレス 一般的なアドレス生成の流れ  秘密鍵からECDSAで公開鍵を生成 公開鍵をハッシュ関数SHA-256に通しハッシュ値を得る そのハッシュ値をさらにハッシュ関数RIPEMD-160に通しハッシュ値を得る ハッシュ値の先頭にプレフィックスとして00を加える ハッシュ関数SHA-256に通す もう一度ハッシュ関数SHA-256に通す 4バイトのチェックサムを一番後ろに加える Base58のフォーマットでエンコーディングする  Reference: 秘密鍵から公開鍵そしてアドレスが生成されるまでの流れ【仮想通貨】\n一般的なアドレス生成の図 Reference: 秘密鍵から公開鍵とビットコインアドレスを生成する方法\n秘密鍵/公開鍵/アドレスの関係 Reference: 公開鍵、秘密鍵、ビットコインアドレスの関係\n秘密鍵/WIF/公開鍵/アドレスの関係 Reference: 暗号通貨(Bitcoin, Monacoin)のプロトコルを理解する: 公開鍵と秘密鍵\nHDウォレットにおけるアドレス生成の手順 Reference: bips/bip-0032.mediawiki\nEntropy (BIP39, 128bit, 160bit, 192bit, 224bit, 256bitの長さ)\n↓\nMnemonic (BIP39, 2048(11bit)個の単語群から選んだ、12個, 15個, 18個, 21個, 24個の単語群)\n↓\nMaster Node (BIP39, 512bit(=64byte))\n↓\n左半分: Master Key(BIP32), 右半分: Chain Code(BIP32)\n↓ (Master Key + Chain Code)\n拡張鍵 (BIP32)\n↓\nHD Wallet (BIP32)\n↓\nアドレス\nEntropyのターミナルでの作成方法 # entropyの生成はmacのターミナルで $ cat /dev/urandom |LC_ALL=C tr -dc \u0026#39;a-f0-9\u0026#39; | fold -w 64 | head -n 1 # entropyの生成はlinuxの端末で $ cat /dev/urandom |tr -dc a-f0-9|head -c${1:-64} アドレスの種類 Reference: Address\nプレフィックス    Decimal prefix Hex Example use Leading symbol(s)     0 00 Pubkey hash (P2PKH address) 1   5 05 Script hash (P2SH address) 3   128 80 Private key (WIF, uncompressed pubkey) 5   128 80 Private key (WIF, compressed pubkey) K or L   4 136 178 30 0488B21E BIP32 pubkey xpub   4 136 173 228 0488ADE4 BIP32 private key xprv   111 6F Testnet pubkey hash m or n   196 C4 Testnet script hash 2   239 EF Testnet Private key (WIF, uncompressed pubkey) 9   239 EF Testnet Private key (WIF, compressed pubkey) c   4 53 135 207 043587CF Testnet BIP32 pubkey tpub   4 53 131 148 04358394 Testnet BIP32 private key tprv     Bech32 pubkey hash or script hash bc1     Bech32 testnet pubkey hash or script hash tb1    List of address prefixes\n単位 0.00000001 BTC = 1 Satoshi\n1 BTC = 100000000 Satoshi\nScript  TransactionとScriptとLightning Networkについて分かりやすいスライド  スクリプトから理解するライトニングネットワーク  サトシは後に, 以下の2つの理由でP2PK ではなくP2PKHを使うことを決めた.  楕円曲線暗号（公開鍵や秘密鍵に使われれている暗号）が, 楕円曲線上の離散対数問題を解くために改良されたショアのアルゴリズムによって解かれてしまうから. 簡単に言うとそれが意味するのは, 理論上, 量子コンピューターがそう遠くない未来に公開鍵から秘密鍵を導出できてしまうということ. ビットコインを使うときだけ公開鍵を公開することによって, そういった攻撃を無力化することができる（一度使われたビットコインアドレスを二度と使わない前提だが）. ハッシュサイズがより小さくなるので（20バイトになる）, 印刷するにも小さくできるしQRコードのような小さい記録媒体に埋め込むことがより簡単になる. Reference: P2PKH (Pay to Public Key Hash)   ScriptSig ScriptSigはInputにあって, [$ \\sf{ScriptSig} \\fallingdotseq \\sf{Unlock Script}] ScriptSigにはSigとPubKeyがある. そうすることでP2PKHでは, ScriptPubKeyにあるhash化されたPubKeyとScriptSigにあるPubKeyを見比べてTrueを得た後に, さらにScriptSigにあるSigとPubKeyを見比べてTrueを得ることができる.\nScriptPubKey ScriptPubKeyはOutputにあって, [$ \\sf{ScriptPubKey} \\fallingdotseq \\sf{Lock Script}] Lockしないと誰でもBTCを取り出せてしますから.\nP2SHのScriptPubKey # P2SHのScriptPubKey OP_HASH160 [20-byte-hash-value] OP_EQUAL オンラインでBitcoin Scriptの挙動を確認できるサイト  Bitcoin Script Online Debugger  トランザクション トランザクション生成と検証の仕方が分かりやすいスライド\n Bitcoinを技術的に理解する の32ページ目から Bitcoinのtransactionの署名検証をscriptから理解する  Segwit  SegWitの分かりづらい点とその理由  スクリプト構造 # P2WPKH witness : \u0026lt;signature\u0026gt; \u0026lt;pubkey\u0026gt; scriptSig : (empty) scriptPubKey : 0 \u0026lt;20-byte SHA160(pubkey)\u0026gt; (0x0014{20-byte SHA160(pubkey)}) # P2WSH witness : 0 \u0026lt;signature1\u0026gt; \u0026lt;1 \u0026lt;pubkey1\u0026gt; \u0026lt;pubkey2\u0026gt; 2 CHECKMULTISIG\u0026gt; scriptSig : (empty) scriptPubKey : 0 \u0026lt;32-byte sha256(witness script)\u0026gt; (0x0020{32-byte sha256(witness script)}) Base32 Reference: https://bc-2.jp/materials/0105_Bech32.pdf\nTransaction Fee  PREDICTING BITCOIN FEES FOR TRANSACTIONS. Bitcoin Avg. Transaction Fee historical chart  References  bitcoinのしくみ Programming The Blockchain C# 日本語 Blockchain Core Camp season1のビデオ資料 Blockchain Core Camp season2のビデオ資料 Bitcoin Resources  "},{"idx":141,"href":"/docs/ci-cd/","title":"CI/CD","content":" CI/CDとは  ソフトウェアのビルド・テスト・デプロイを自動化することで, 1つ1つの工程が小さくなり, リスクマネージメントを容易にしたり, 変更に対するフィードバックを素早く得られたりする開発手法のこと.  CIとは  Continuous Integrationl（継続的インテグレーション）の略. ソフトウェア開発におけるビルドやテストを自動化したこと. ホスティングサービスへソースコードがコミットされると, CIによって自動的に「コードにエラーがないか」/「既存の機能を破壊していないか」といったテストが行える.  CDとは  Continuous Delivery（継続的デリバリー）の略. CIによってテストされたコードのマージや, 本番環境向けのビルドの作成を自動化したこと. 運用環境へのデプロイが明示的な承認なしで自動的に行われる「継続的デプロイ」とは異なる.  References  「CI/CD」とは CI/CDのエキスパートが解説：CI/CDとは何か？ なぜ今、必要とされるのか？  "},{"idx":142,"href":"/docs/db/","title":"DB","content":" データベースとは  大量のデータを集めて, コンピューターでデータの追加, 削除, 検索をしやすい形に整理したもの. 有料/無料, オープンソース/非オープンソース, SQL型, NoSQL型, オブジェクト型, ドキュメント型, キー・バリュー型, グラフ型などいろんな種類がある.  NoSQLとSQLの違い    項目 NoSQL SQL     代表的なもの MongoDB, CouchDB MySQL, MS SQL   データ構造 データ構造を強制しない 厳密なデータ構造を適応   関係性 関係性にはフォーカスしていない 関係性がコアの機能   要素の在り方 独立したドキュメント レコードを関連付ける   用途 ログ, 注文, メッセージ ショッピングカート, コンタクト, ネットワーク    DBの使用率ランキング  DB-Engines Ranking  "},{"idx":143,"href":"/docs/","title":"Docs","content":""},{"idx":144,"href":"/docs/iota/","title":"IOTA","content":" IOTAとは Githubリポジトリ: https://github.com/iotaledger\n目的  オープンIoTでブロックチェーンの良さ(分散性/耐改ざん性/オープン性)を使えるようにしつつ(スケーリング・マイニングコスト・トランザクションの承認の遅さを解決しつつ)インダストリー4.0を推し進めること. IOTA財団の目的は, オープンソースガバナンスを使用して, IOTAをゴールドスタンダード（主要組織や標準化団体と協力して, エンタープライズ対応DLT）にすること.  特徴  小さなデータの保存と交換に特化した設計. 平衡三進数を使用. 量子コンピュータ耐性のために電子署名にはWinternitz One Time Signatureを使用.  署名は使い捨てなので送金に使ったアドレスにもう1度入金すると盗まれる可能性特大. というか多額のIOTAを盗まれた実績有. 今はそうならないようにwalletが上手に管理してくれてる.  スケーリングのためにブロックは生成せずに各々のトランザクションがDAG形式で自分より前のトランザションを承認していく.  まだ発展途上なのでチェック機能が存在する. トランザクションはInput/Output/Remainderの3種類が1まとめになったBundleとしてTangle内を流れてる.  UTXOを採用.  CfBによる技術的特徴  IoTは, インターネットを介して通信するものではありません.  この誤解は, インターネット用の既存のソリューションを別の名前で販売しようとしている企業によって生み出されました. モノは, インターネットよりもはるかに大きい, 独自のネットワークを形成します. そのようなネットワークは, すべてのトラフィックが少数の組織によって制御されている少数のサーバーを通過するアーキテクチャを使用して拡張することはできません.  Tangleは1つだけであり, それだけです.  いくつかのIOTAフォークを実行しても, それらはすべて単一のTangleで機能し, 理論的には後でマージすることができます. IOTAを実行している異なるクラスターは, Tangleに絡み合って異なるサブタングルを形成します. これは, モバイルのモノがあるクラスタから別のクラスタに移動するときに便利な機能です.  IOTAを実行しているノードのネットワークは, 1/3未満の要素の障害が重要ではないシステムです.  もしそうならノードソフトウェアはこの機能を念頭に置いて開発されるべきです. 特に, グリッチが発生した場合は, ノードを再起動し, 必要に応じてストレージをクリアすることができます. IOTA上に構築されたソフトウェアは, そのノードが常に信頼できる状態で動作すると想定してはいけません. ソフトウェアは少なくとも3つのノードに接続し, それらのクォーラム(67％+)によって提供される情報に依存します.  IOTAプロトコルは不変なものです.  バージョニングを必要としません. すべての改良はプロトコルの上でされなければなりません. さもなければIOTAは物理的にアップグレードすることができないモノの多くによって採用されることができません.  IOTAはデータ保存用ではなく, データ配信用です.  あるデータがTangleに格納されている場合, そのデータが24時間の間ずっとTangleで見つかることを期待しないでください. データ片のハッシュを含むMerkleツリーのルートが常に更新されるようなトリックを使用してください. データが欲しい場合は後でデータの所有者または専門のサービス（いわゆるpermanode）へ要求することができます.  IOTAはナノペイメントを可能にするもので, これを最大限に活用する必要があります.  IOTAのために売られるものは何でも, 小さな塊で売られて, 支払いがネットワークによって受け入れられるといういくらかの保証が得られるのと同じくらい速く配達されるべきです. たとえ彼らが「より遅い」売り手に対する競争上の優位性を成功させたとしても, 数セントの二重支払いで悩まされる人はほとんどいないでしょう.  P.S正式にはIOTAは頭字語ではありませんが, 私は常に「黙示録」が「啓示」を意味する「モノのインターネット黙示録(Internet-Of-Things Apocalypse)」の略であると言ってきました. Reference: Internet-of-Things Apocalypse  trit, tryte  bit := trit  bit = (0, 1) trit = (-1, 0, 1)  byte := tryte  byte = 2^8 = 256 tryte = 3^3 = 27   単位変換  IOTA Converters  GitHubリポジトリ: hyperreality/iota-tools   ICC Network Visualisation  http://88.99.60.78:8080/  devnet  https://nodes.devnet.iota.org https://devnet.thetangle.org/nodes https://faucet.devnet.iota.org (devnetの蛇口)  DBのある保存場所  https://db.iota.partners/iri-mainnet-snapshot.tar.gz https://x-vps.com/iota.db.tgz https://dbfiles.iota.org  Academic Papers  Academic Papers  C#  https://patriq.gitbook.io/iota/  様々なプロジェクト  Coodicide: Coodinatorを削除する方法 Trinity: 公式ウォレット Qubic: IOTA Tangle上のスマコン・オラクル・アウトソーシングなど Data Marketplace: 情報の売買場 International Trade: トレーサビリティ Certification: 証明書発行 Eco System: コミュニティの交流場 eCl@ss: データの規格 IOTA Tangle Utils：エクスプローラーとかデータ変換とか便利なツール群 Troika: 3進数用のハッシュ関数 IOTA Area Codes: タグにエリアコードを埋め込む規格 IOTA IPFS: IOTAでIPFS Discord：Discordへの招待 IOTA QR Codes：Trinityが読み取れるQRコード作成  Coordicide  公式サイト: https://coordicide.iota.org Coodinatorを削除する方法のこと. Coordicideの機能をモジュール化した.  そうすることで将来のアップデートを容易にした.  コアCoordicideモジュールは, 改良されたコンセンサスメカニズム, つまり分散化とセキュリティを最大限にするためのチップ選択アルゴリズムを補完する投票方式です. コンセンサスアルゴリズムには, セルラーコンセンサスと高速確率的コンセンサスがある. Coodicide White Paper モジュール1: ノードIDとマナ  ノードにIDを振り分け, マナというノードのレピュテーションシステムを導入する. トランザクションはノードがトランザクションを伝搬してくれたら, マナというトークンをノードに上げる. マナは, 評判を得るのは難しいが, 失うのは簡単だという考えに依存している. レピュテーションシステムの重要な側面は, 以前に与えられたレピュテーションを取り消すことによって悪いノードを罰する側面.  モジュール2: セキュアなオートピアリング  自動でネイバーを接続させて, 特定のノードに攻撃が起こらないようにする. スモールワールドネットワーク(ほとんどのノードが互いに隣接していないタイプの数学的グラフ)を構築する.  モジュール3: スパムプロテクション  最近発行されたトランザクションの数及びマナのような異なる要因に基づいてノード当たりのPoWの難しさを知的に変化させる適応レート制御メカニズムを設置する. マナの量が多いノードは, 評判の悪いノードと同じPoW要件なしに, より多くのトランザクションを発行することができる. ノードのマナに関係なく, PoWの難易度はトランザクションレートとともに増加もする. すなわち, 短い時間間隔でより多くの取引を発行するためには, ノードは暗号パズルの難易度を上げなければならないが, 一方, 低い取引レートでは, はるかに低い難易度で十分となる. スパムをさらに防ぐために, ノードあたりの最大トランザクションレートの制御も行う.  対象はIoT.   モジュール4: チップ選択アルゴリズム  累積荷重を廃止して, Tangleの優先部分を識別するための投票層を追加する. 累積荷重の悪い点  正直なトランザクションでも累積荷重が無いと取り残された. 攻撃者は累積荷重を悪用して, パラサイトチェーンやTangle分裂を行おうとする. トランザクションの累積荷重を計算することは比較的費用がかかり, 特にハイスループットのシナリオではプロトコルのスケーラビリティに問題を引き起こす.   モジュール5: 積極的な矛盾解決  累積荷重を止めるために, ノードが投票によって意見を交換する追加のセキュリティ層を提案する. 投票者モデルについては, 長年にわたりかなりの研究が行われてきた. 確率モデルでは, ノードは複数のラウンドにわたって少数の他のノードの意見を要求し, そしておそらくはそれ自身の意見も変える. 投票メカニズムを導入するメリット  どんどん発行されるトランザクションから状況を解決するまで待つのではなく, ノードが互いに対話して状況を予防的に解決できるようになる. ノードの投票は, それが持つマナの量に応じて重み付けされる. したがって, 優秀な関係者はネットワークに大きな影響を与えることができる. 正直なノードは, たとえ現在トランザクションを発行していなくても, 投票によってネットワークを保護できる. 提案されたシビル保護メカニズム(マナ)と組み合わされて, これは, PoWに依存することなく, ブロックチェーンにおける一定の正直なハッシング力を置き換える. コンセンサスプロセスは, チップ選択やTangleの構造など, 他の側面から切り離されている. これにより, 将来の要件に合わせて簡単に調整できるモジュラDLTが実現できる. また, ホワイトペーパーに記載されているパラサイトチェーン攻撃などの最も危険な攻撃を含め, Tangleの構造を操作して合意メカニズムを破るあらゆる種類の攻撃を防ぐことができる.  新たにShimmerという投票スキームを提案する. Shimmer内での投票交換の候補として2つの候補を提示する.  セルオートマトンの振る舞いを模した「Cellular Consensus」 確率論を使用して強力なセキュリティ保証を提供する「Fast Probabilistic Consensus」   モジュール5.1: Shimmer  いくつかの事前定義された規則に従って行動する個々の自律エージェントは, 蜂, アリ, 魚群などの自然界の多くのシステム, さらには物理学のある分野でさえ見つけることができます. 非常に単純なルールは, やがてシステムの緊急の特性として現れ, 非常に複雑な機能を作成することができます. Shimmer合意メカニズムも同様に機能します. 他のすべてのノードの意見を再構築しようとするのではなく, 非常に小さいノードのサブセットの意見だけに注意を払い, ネットワークの緊急の特性として有機的に合意が形成されるようにします.   From Hans Moog[IF] one important aspect about this whole solution is that we only vote on conflicts that are arriving more or less at the same time - that means that even an attacker that has unlimited resources (aka unlimited nodes or unlimited amounts of hashing power) - they can only decide which one of the two conflicts wins but they can not rewrite history so even if you invest 1 billion dollars you can not break the network.\nFrom David Sonstebo While IoT is undoubtedly still IOTA\u0026rsquo;s chief focus point, this approach to Coordicide enables it to also cover the regular Internet. I want to see decentralized Facebook, AWS and all. IOTA\u0026rsquo;s vision is expanding.\nRoad Map  Coordicide: The Road Ahead  "},{"idx":145,"href":"/docs/latex/","title":"LaTeX","content":" LaTeXとは  テキストベースの組版処理システムのこと. 単一のアプリケーションではなく, 膨大な数の実行形式ファイル, マクロ, フォントファイル, 周辺ユーティリティの集合体. 学術機関における論文執筆ツールとしてよく使われている. GitHubリポジトリ: https://github.com/latex3/latex3  オンラインジェネレーター  Cloud LaTeX OverLeaf  Tex Live  Tex LiveとはTEXディストリビューション(TEXを一般利用者がインストールしたり, 利用できる形にまとめ上げたもの（頒布形態）)の1つ.  "},{"idx":146,"href":"/docs/mongodb/","title":"MongoDB","content":" MongoDBとは  オープンソースで公開されているドキュメント指向データベースの1つ. GitHubリポジトリ: https://github.com/mongodb/mongo  インストール  https://docs.mongodb.com/manual/installation/  mongodb(v4.0.5)のコンソールからの使い方色々 Excel, Oracle, MongoDB, Object の大まかな比較    Excel Oracle MongoDB Object     ブック Schema Database 特になし   シート Table Collection 特になし   行 Row Document Object群   列 Column Field Key   セル Field Value Value    起動方法 $ mongod // mongodbが起動する $ CNTL-C // mongodbを停止する // か, $ sudo service mongod start $ sudo service mongod stop コンソールからのアクセス方法 $ mongo // アクセスして, \u0026gt; exit // 終了. bye dbの作成\u0026amp;中身を見る \u0026gt; use sample // sampleというdbを作成 or そこにアクセスする switched to db sample \u0026gt; show dbs // 存在するdbの種類を見せてくれる admin 0.000GB local 0.000GB sample 0.000GB // こんな感じで帰ってくる \u0026gt; db.stats() // これで中身の情報を見せてくれる Collection(ディレクトリ・フォルダみたいなもの)の作成 \u0026gt; db.createCollection(\u0026#34;products\u0026#34;) // productsというCollectionを作成する { \u0026#34;ok\u0026#34; : 1} \u0026gt; show collections products dbをコピー\u0026amp;削除する \u0026gt; db.copyDatabase(\u0026#39;sample\u0026#39;, \u0026#39;new_sample\u0026#39;) // mongodb4.0で非推奨になった { \u0026#34;ok\u0026#34; : 1} \u0026gt; show dbs admin 0.000GB local 0.000GB new_sample 0.000GB sample 0.000GB \u0026gt; use new_sample \u0026gt; db.dropDatabase() { \u0026#34;dropped\u0026#34; : \u0026#34;new_sample\u0026#34;, \u0026#34;ok\u0026#34; : 1 } \u0026gt; show dbs admin 0.000GB local 0.000GB sample 0.000GB Collectionの名前変更 \u0026gt; db.createCollection(\u0026#39;pricee\u0026#39;) { \u0026#34;ok\u0026#34; : 1 } \u0026gt; show collections pricee products \u0026gt; db.pricee.renameCollection(\u0026#39;price\u0026#39;, true) // ここのtrueは名前変更前のcollectionは削除するということ { \u0026#34;ok\u0026#34; : 1 } \u0026gt; show collections price products Collectionの削除 \u0026gt; db.price.drop() true \u0026gt; show collections products CollectionにDocumentを追加 \u0026gt; db.products.insert({name: \u0026#39;pen\u0026#39;, price: 150}) WriteResult({ \u0026#34;nInserted\u0026#34; : 1 }) オペレーターの種類    オペレーター 意味     $eq =   $gt \u0026gt;   $gte \u0026gt;=   $lt \u0026lt;   $lte \u0026lt;=   $ne !=   $regex 正規表現    Documentを表示\u0026amp;検索 \u0026gt; db.products.find() // collectionの中身のdocumentを全部表示 { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;5c2d4199c5195731b5149377\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;pen\u0026#34;, \u0026#34;price\u0026#34; : 150 } \u0026gt; db.products.find({price: {$gt: 100}}) // priceが100より大きいものを検索 { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;5c2d4199c5195731b5149377\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;pen\u0026#34;, \u0026#34;price\u0026#34; : 150 } \u0026gt; db.products.find({price: {$gt: 200}}) // priceが200より小さいものを検索 \u0026gt;\u0026gt; db.characters.find().pretty() // charactersの中身を下のように表現してくれる { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;5c280309156ceb35b1564cff\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;sola\u0026#34;, \u0026#34;age\u0026#34; : 33, \u0026#34;__v\u0026#34; : 0 } Document内容の更新 \u0026gt; db.products.update({name: {$eq: \u0026#39;pen\u0026#39;}}, {$set: {price: 200}}, {upsert: false, multi: true}) WriteResult({ \u0026#34;nMatched\u0026#34; : 1, \u0026#34;nUpserted\u0026#34; : 0, \u0026#34;nModified\u0026#34; : 1 }) \u0026gt; db.products.find() { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;5c2d4199c5195731b5149377\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;pen\u0026#34;, \u0026#34;price\u0026#34; : 200 } Documentの削除 \u0026gt; db.products.remove({name: {$eq: \u0026#39;pen\u0026#39;}}) WriteResult({ \u0026#34;nRemoved\u0026#34; : 1 }) \u0026gt; db.products.find() \u0026gt;"},{"idx":147,"href":"/docs/mysql/","title":"MySQL","content":" MySQLとは  オープンソースで公開されている関係データベース管理システム(RDBMS)の1つ. GitHubリポジトリ: https://github.com/mysql/mysql-server  MySQL(v14.14)の使い方 (Ver 14.14 Distrib 5.7.25, for Linux (x86_64))\nMySQLのデータ構造 Database -\u0026gt; 複数のTable -\u0026gt; その中にid, title, bodyを持つ表があって, -\u0026gt; 行をRecord, Row, 列をField, Columと言う. こういったDatabaseやTableやFieldやRecordを扱う言語をSQL(Structured Query Language)と言う.\nSQLの実行順番    順番 操作名 命令文     1 テーブルの指定 from   2 結合 on, join   3 取得条件 where   4 グループ化 group by   5 関数 count, sum, avg, min, max   6 having having   7 検索 select, distinct   8 順序 order by   9 limit limit    MySQLの基本的な使い方 # Ubuntuへのインストール sudo apt install mysql-server mysql-client # 起動確認 sudo service mysql status \u0026gt; mysql.service - MySQL Community Server # MySQLの基本設定を行う sudo mysql_secure_instalation \u0026gt; Securing the MySQL server deployment. # で, 色々と設定していく. # コンソールからMySQLサーバに接続 sudo mysql -u root -p \u0026gt; Enter password: # password入力して, MySQLサーバに接続 \u0026gt; mysql\u0026gt; # helpを見る mysql\u0026gt; help; # 状態を見る mysql\u0026gt; status # 現在のユーザーを表示 mysql\u0026gt; select user(); \u0026gt; +----------------+ \u0026gt; | user() | \u0026gt; +----------------+ \u0026gt; | root@localhost | \u0026gt; +----------------| \u0026gt; 1 row in set (0.00 sec) # ; を忘れると mysql\u0026gt; select user() -\u0026gt; # 続きを打てと催促されるので, 慌てずに ; を打つ. -\u0026gt;; \u0026gt; +----------------+ \u0026gt; | user() | \u0026gt; +----------------+ \u0026gt; | root@localhost | \u0026gt; +----------------| \u0026gt; 1 row in set (0.00 sec) # 現在のコマンドをキャンセルするには \\c を打つ. mysql\u0026gt; select user() -\u0026gt; \\c mysql\u0026gt; # MySQLサーバーへの接続を終了する mysql\u0026gt; quit; mysql\u0026gt; \\q \u0026gt;Bye DBを表示・新規作成・削除・操作対象にする mysql\u0026gt; の後に打ち込むコマンドをQuery(クエリ)と言う. MySQLでのクエリは大文字小文字の区別がない.\n# DBを表示する mysql\u0026gt; show databases; \u0026gt; +--------------------+ \u0026gt; | Database | \u0026gt; +--------------------+ \u0026gt; | information_schema | \u0026gt; | mysql | \u0026gt; | performance_schema | \u0026gt; | sys | \u0026gt; +--------------------| \u0026gt; 4 row in set (0.00 sec) # これらはシステムが用いているDBなのでうっかり消さないように注意する. # 新規にDBを作成する mysql\u0026gt; create database mydb01; \u0026gt; Query OK, 1 row affected (0.00 sec) # OKが出れば成功 mysql\u0026gt; create database mydb02; \u0026gt; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; create database mydb03; \u0026gt; Query OK, 1 row affected (0.00 sec) # DBを削除する mysql\u0026gt; drop database mydb03; \u0026gt; Query OK, 0 row affected (0.00 sec) # OKが出れば成功 # 操作対象のDBを確認する mysql\u0026gt; select database(); \u0026gt; +--------------------+ \u0026gt; | database() | \u0026gt; +--------------------+ \u0026gt; | NULL | \u0026gt; +--------------------| \u0026gt; 1 row in set (0.00 sec) # NULLが帰ってきたので, 操作対象のDBがないと言うこと # 操作対象のDBを選択する mysql\u0026gt; use mydb02; \u0026gt; Database changed mysql\u0026gt; select database(); \u0026gt; +--------------------+ \u0026gt; | database() | \u0026gt; +--------------------+ \u0026gt; | mydb02 | \u0026gt; +--------------------| \u0026gt; 1 row in set (0.00 sec) 作業用ユーザーを新規作成・削除する rootユーザーでうっかりをすると大変なことになるのでDBごとに作業用ユーザーを作成する.\n# userを新規作成 mysql\u0026gt; create user dbuser01@localhost identified by \u0026#39;6AVAkig2@#\u0026#39;; \u0026gt; Query OK, 0 raws affected (0.00 sec) # userにDBの権限を付与する \u0026gt;mysql grant all on mydb01.* to dbuser01@localhost; # grant は権限を与える. # all は全ての権限を与える. # mydb01.* はmydb01にあるテーブル全てに対して と言う意味. # to dbuser@localhost はdbuser@localhostに対して と言う意味. \u0026gt; Query OK, 0 raws affected (0.00 sec) # 一度rootでログアウトして, もう一度dbuser01@localhostでログインする. mysql\u0026gt; quit; \u0026gt; Bye mysql -u dbuser01 -p mydb01 \u0026gt; Enter password: 6AVAkig2@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. # で, 無事にdbuser01ユーザーでログインができた. # 一応確認. mysql\u0026gt; select user(); \u0026gt; +--------------------+ \u0026gt; | user() | \u0026gt; +--------------------+ \u0026gt; | dbuser01@localhost | \u0026gt; +--------------------| \u0026gt; 1 row in set (0.00 sec) # ユーザーがdbuser01になってる. # アクセスできるDBも確認. mysql\u0026gt; show databases; \u0026gt; +--------------------+ \u0026gt; | Database | \u0026gt; +--------------------+ \u0026gt; | information_schema | \u0026gt; | mydb01 | \u0026gt; +--------------------| \u0026gt; 2 row in set (0.00 sec) # きちんとmydb01にだけアクセスするようになってる. # ユーザーの削除 # rootユーザーでログインする mysql\u0026gt; quit; \u0026gt; Bye sudo mysql -u root -p \u0026gt; Enter password: # rootユーザーのpasswordを入力して, エンター mysql\u0026gt; drop user dbuser01@localhost; \u0026gt; Query OK, 0 raws affected (0.00 sec) 外部ファイルを実行する 先ずは, 外部ファイルcreate_myapp.sqlを作成し, rootユーザーでログインするときに外部ファイルを読み込ます方法.\nmysql -u root \u0026lt; create_myapp.sql \u0026gt; # 何も反応がないけど, きちんとできてます. もしくは, rootユーザーでログインした後に, 外部ファイルを読み込ます方法.\nsudo mysql -u root \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; source ./create_myapp.sql # もしくは mysql\u0026gt; \\. ./create_myapp.sql Tableを新規作成・一覧表示・中身表示・削除する Talbeを外部ファイルで作成して, 削除する.\nmysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. # tableを外部ファイルを使って作成する mysql\u0026gt; \\. ./create_table.sql \u0026gt; Query OK, 0 rows affected (0.00 sec) # tableの一覧を見る mysql\u0026gt; show tables; \u0026gt; tableの一覧が見れる # usersというtableの中身を見る mysql\u0026gt; desc users; \u0026gt; userというtableの中身が表示される \u0026gt; 3 rows in set (0.00 sec) # usersというtableの削除方法 mysql\u0026gt; drop table users; \u0026gt; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show tables; \u0026gt; Empty set (0.00 sec) MySQLが扱えるデータ型 number: - int # 整数型 - float # 実数型 - double # 倍精度実数型 - int unsigned # 正の整数型 string: - char # 固定長の文字列 - char(4) # 4文字固定の文字列 - varchar # 可変長の文字列 - varchar(255) # 255バイトまでの可変長文字列 - text # 可変長の文字列 data/time; - date # 日付 - time # 時間 - datetime # 日時 \u0026#39;2020-02-22 20:22:33\u0026#39;と表示することができる true/false; - boolean # booleanは1桁の整数の型であるtinyint(1)で返される true -\u0026gt; 1 # 空文字を含むNull以外は全てtrueになる false -\u0026gt; 0 # Nullがfalse Recordの挿入 insert_record.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./insert_record.sql \u0026gt; 実行結果が返ってくる. Fieldに制限をかける restricted_field.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./restricted_field.sql \u0026gt; 実行結果が返ってくる. Tableの構造を変える change_table.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. # column(field)を追加する # 任意の場所にcolmun(field)を追加する(今回はnameの後ろにemailを追加) # column(field)を削除する # column(field)名の変更する # tableの名前を変更する mysql\u0026gt; \\. ./change_table.sql \u0026gt; 実行結果が返ってくる Recordを抽出する extract_record.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./extract_record.sql \u0026gt; 実行結果が返ってくる 文字列を抽出条件にする extract_using_character.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./extract_using_character.sql \u0026gt; 実行結果が返ってくる 数字で並び替えたり, 抽出条件を制限したりする extract_using_number.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./extract_using_number.sql \u0026gt; 実行結果が返ってくる Recordを更新, 削除する update_record.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./update_record.sql \u0026gt; 実行結果が返ってくる 数値の演算を行ったり, 活用したりする calculate.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./calculate.sql \u0026gt; 実行結果が返ってくる 文字列の演算を行う calculate_using_character.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./calculate_using_character.sql \u0026gt; 実行結果が返ってくる enum型を使う enum型とは複数の文字列の中から１つだけを格納できるデータ型.\nenumを使うことで有効なデータ以外は無効なデータとして扱うことができる.\nenum.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./enum.sql \u0026gt; 実行結果が返ってくる set型を使う set型を使うと複数の選択肢から複数個選べる.\nset.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./set.sql \u0026gt; 実行結果が返ってくる if, caseの使い方 if_case.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./if_case.sql \u0026gt; 実行結果が返ってくる 抽出結果をtableにする  caseで抽出した結果で新たにtableを作成する. 既存のtableをそのままコピーして新たなtableを作成する. 既存のtableの構造だけをコピーして新たなtableを作成する. 詳しくはmake_table_using_extracted_data.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./make_table_using_extracted_data.sql \u0026gt; 実行結果が返ってくる  Dataの集計処理を行う  talbe内のnull以外のdataの個数を調べる. table内の全てのdataの個数を調べる. fieldの合計値, 最小値, 最大値, 平均値を調べる. table内の重複しない値のみを抽出する. table内の重複しない値の個数を調べる. 詳しくはaggregate_data.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./aggregate_data.sql \u0026gt; 実行結果が返ってくる  Group集計  groupごとに値を集計するには group by を用いる. group by で集計した後の data に対して条件を付ける場合には where ではなく having を用いる. having はグループ化に使った値や集計した値しか条件に使えない. where と group by を一緒に使った場合は, where の条件でデータの抽出を行った後に group by でその集計を行うことになる. 詳しくはaggregate_group.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./aggregate_group.sql \u0026gt; 実行結果が返ってくる  Sub Queryを使う  一時的にしか使わない tabale だと sub query を用いて, 新たな table を作らずに表示できる. 詳しくはsub_query.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./sub_query.sql \u0026gt; 実行結果が返ってくる  Viewを使う  抽出条件に名前を付けて table の用に扱える view. 詳しくはview.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./view.sql \u0026gt; 実行結果が返ってくる  Transactionを使う  複数の処理をひとまとめにできる transaction. 詳しくはtransaction.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./transaction.sql \u0026gt; 実行結果が返ってくる  Indexを使う  index(索引)の設定をしておくと data の抽出が速くなる. でも, index は data の追加や更新処理を行うたびに作り直されるので, あまり index を付けすぎると処理が遅くなる. 詳しくはindex.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./index.sql \u0026gt; 実行結果が返ってくる  Inner join(内部結合)を使う  inner join = 2つの table に共通の data だけを取得する方法 詳しくはinner_join.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./inner_join.sql \u0026gt; 実行結果が返ってくる  Outter join(外部結合)を使う  outer join (外部結合) = 2つの table で一致しない data も含めて data を取得する方法 2つの内どちらを軸にするかを決める必要がある. 詳しくはoutter_join.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./outter_join.sql \u0026gt; 実行結果が返ってくる  Foreign keyを使う  外部キー制約(foreign key)を使うと先に作られた table の field にない data の挿入を許さない書き方ができる. 紐付ける値同士の型は一致していないといけない. 外部キー制約に合わないものはエラーになって table に書き込まれない. 外部キー制約を設定すると, 関連する data がある場合には data の削除や更新が簡単にはできなくなる. 詳しくはforeign_key.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./foreign_key.sql \u0026gt; 実行結果が返ってくる  last_insert_id()を使う  last_insert_id() を使うと直前に挿入した record の id を引っ張ってきてくれる. 詳しくはlast_insert_id.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./last_insert_id.sql \u0026gt; 実行結果が返ってくる  triggerを使う  ある table で何らかの処理が行われたら, それを trigger にして, またべつの処理を走らせることができる機能を trigger という. insert, delete, updateなどの処理に対して trigger を発動できる. after, before で設定できる. field を縦表示するにはshow triggers \\Gのように, 後ろに\\Gを付けてあげれば良い. 詳しくはtrigger.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./trigger.sql \u0026gt; 実行結果が返ってくる  triggerで複数の処理を行う  trigger で複数の処理を行うには begin end を使えば良い. 詳しくはtrigger2.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./trigger2.sql \u0026gt; 実行結果が返ってくる  current_timestampを使う  on update current_timestamp で更新時にその時の日時で field を自動更新してくれる. 詳しくはcurrent_timestamp.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./current_timestamp.sql \u0026gt; とりあえずの table が表示される. mysql\u0026gt; update posts set title = \u0026#39;updated\u0026#39; where id = 2; mysql\u0026gt; select * from posts; \u0026gt; +----+---------+--------+---------------------+---------------------+ \u0026gt; | id | title | body | created | updated | \u0026gt; +----+---------+--------+---------------------+---------------------+ \u0026gt; | 1 | title 1 | body 1 | 2019-02-28 15:31:16 | 2019-02-28 15:31:16 | \u0026gt; | 2 | updated | body 2 | 2019-02-28 15:31:16 | 2019-02-28 15:38:20 | \u0026gt; | 3 | title 3 | body 3 | 2019-02-28 15:31:16 | 2019-02-28 15:31:16 | \u0026gt; +----+---------+--------+---------------------+---------------------+  日付を扱う  MySQLで日付を扱うには日付っぽい書式を使えば自動で認識してくれる. 日付の変更, 日付の条件指定, 日付の計算, 日付の書式変更 詳しくはdate.sqlをご覧ください.\n# まずDBにアクセス mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./date.sql \u0026gt; 実行結果が返ってくる  Backupを行い復元できるようにする  backup を作成する方法はいろいろありますが, 簡単な方法は mysqldump を使うこと.\n# まず backup する data を作成する. mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; \\. ./date.sql # とかで data を作ってあげて, mysql\u0026gt; quit; # 一度 mysql を抜ける.# backupを取る. mysqldump -u myapp_user -p myapp \u0026gt; 201902_myapp.backup.sql \u0026gt; Enter password: 2VNAhigo@# # これで backup が取れたことになる.# 次に一番はじめに作成した data を更新してから, 先程 backup した data で復元を行ってみる. mysql -u myapp_user -p myapp \u0026gt; Enter password: 2VNAhigo@# \u0026gt; Welcome to the MySQL monitor. Commands end with ; or \\g. mysql\u0026gt; select * from posts; \u0026gt; +----+---------+--------+---------------------+---------------------+ \u0026gt; | id | title | body | created | updated | \u0026gt; +----+---------+--------+---------------------+---------------------+ \u0026gt; | 1 | title 1 | body 1 | 2019-02-28 16:26:27 | 2019-02-28 16:26:27 | \u0026gt; | 2 | title 2 | body 2 | 2016-12-31 10:10:10 | 2019-02-28 16:26:27 | \u0026gt; | 3 | title 3 | body 3 | 2019-02-28 16:26:27 | 2019-02-28 16:26:27 | \u0026gt; +----+---------+--------+---------------------+---------------------+# うっかり table の data を消す. mysql\u0026gt; delete from posts where id \u0026gt; 1; mysql\u0026gt; select * from posts; \u0026gt; +----+---------+--------+---------------------+---------------------+ \u0026gt; | id | title | body | created | updated | \u0026gt; +----+---------+--------+---------------------+---------------------+ \u0026gt; | 1 | title 1 | body 1 | 2019-02-28 16:26:27 | 2019-02-28 16:26:27 | \u0026gt; +----+---------+--------+---------------------+---------------------+# backup data を読み込む. mysql\u0026gt; \\. ./201902_myapp.backup.sql # たくさん \u0026gt; Query OK, が出る.mysql\u0026gt; select * from posts; \u0026gt; +----+---------+--------+---------------------+---------------------+ \u0026gt; | id | title | body | created | updated | \u0026gt; +----+---------+--------+---------------------+---------------------+ \u0026gt; | 1 | title 1 | body 1 | 2019-02-28 16:26:27 | 2019-02-28 16:26:27 | \u0026gt; | 2 | title 2 | body 2 | 2016-12-31 10:10:10 | 2019-02-28 16:26:27 | \u0026gt; | 3 | title 3 | body 3 | 2019-02-28 16:26:27 | 2019-02-28 16:26:27 | \u0026gt; +----+---------+--------+---------------------+---------------------+ # backup の復元完了. mysql\u0026gt; quit;  "},{"idx":148,"href":"/docs/nem/","title":"NEM","content":" NEMとは  暗号資産の1つ. コア開発者とNEM財団は全くの別物. GitHubリポジトリ: https://github.com/nemtech  ドキュメント  https://nemtech.github.io/ja/  "},{"idx":149,"href":"/docs/ssh/","title":"SSH","content":" SSH(Secure Shell)とは  暗号や認証の技術を利用して, 安全にリモートコンピュータと通信するためのプロトコルのこと. VPSに接続するときは必須.  SSHの流れ Reference: SSH通信って、結局何してるの？\n[local]1.通信用の秘密鍵・公開鍵の作成する. [local]2.サーバーに公開鍵を渡す. [server]A.サーバーにユーザーを登録する(sudo権限). [server]B.サーバーに登録されているユーザーと, 渡された公開鍵を紐づける. ※この状態で初めて作成したユーザーによるサーバーへのログインが可能となる. [local]3.作成したユーザーでログインする. [server]C.ログイン時に乱数を生成する. [server]D.Cで生成した乱数から, ハッシュ値を生成する. ※このハッシュ値は認証で使うのでサーバー側で保持しておく. [server]E.受け取った公開鍵 + Cで生成した乱数を用いて暗号を生成する. [server]F.Dで作成した暗号をローカルに送る. [local]4.1で作成した秘密鍵を用いて, 送られてきた暗号を解読し乱数を復元する. [local]5.乱数からハッシュ値を計算し, そのハッシュ値をサーバーに送る. [server]G.送られてきたハッシュ値と、Dで生成したハッシュ値を比較する. 一致していれば認証成功. 以後全ての通信は暗号化される. scp scpとはSSHを用いてファイルを秘匿化してコピーする技術のこと.\n# sshのconfigファイルを用いて通信する方法 scp file_name.txt -F ~/.ssh/config iota3:~/github scp \u0026lt;渡したいファイルの名前\u0026gt; -F \u0026lt;コンフィグファイルの名前\u0026gt; \u0026lt;渡し先のマシン名\u0026gt;:\u0026lt;渡し先のディレクトリ\u0026gt; Mac -\u0026gt; Ubuntu を公開鍵暗号方式で接続する UbuntuをSSH接続可にする Ubuntu側で\nsudo apt-get install openssh-server で, Ubuntu側へSSHで接続できるようになる.\nMacで秘密鍵と公開鍵のペアを作成する まずMacで秘密鍵と公開鍵のペアを作成する.\nssh-keygen -t rsa \u0026gt; Generating public/private rsa key pair. \u0026gt; Enter file in which to save the key (/Users/solareenlo/.ssh/id_rsa): # ここでエンターを押せば/User/solareenlo/.ssh/id_rsaで保存される. \u0026gt; Enter passphrase (empty for no passphrase): # パスフレーズを入力 \u0026gt; Enter same passphrase again: # 再度パスフレーズを入力 \u0026gt; Your identification has been saved in /Users/solareenlo/.ssh/id_rsa. \u0026gt; Your public key has been saved in /Users/solareenlo/.ssh/id_rsa.pub. \u0026gt; The key fingerprint is: \u0026gt; SHA256:a7CbAlk8ns2XVz8roZ8kkN42EFEgXcE+oftgUcFCQ38 solareenlo@solareenlo-mbp13.local \u0026gt; The key\u0026#39;s randomart image is: \u0026gt; +---[RSA 2048]----+ \u0026gt; | .+**=o | \u0026gt; | .o+= | \u0026gt; | . .=..E | \u0026gt; | + ooo.. | \u0026gt; | + =. S+ o . | \u0026gt; | o o o+*=. . o | \u0026gt; | . .o++=... o | \u0026gt; | . + .o+... | \u0026gt; | .o .o. | \u0026gt; +----[SHA256]-----+ これで秘密鍵はid_rsaに, 公開鍵はid_rsa.pubに作成された.\nMacの公開鍵をUbuntuへ渡す scpを使って公開鍵をUbuntuへ持っていく.\ncd ~/.ssh scp id_rsa.pub solareenlo@111.222.333.444:~/. これでユーザー名solareenlo, IPアドレスが111.222.333.444のUbuntuのホームディレクトリに先ほど作った公開鍵が渡った.\nUbuntuでMacの公開鍵を設置する mkdir .ssh mv id_rsa.pub .ssh cd ~/.ssh touch authorized_keys cat id_rsa.pub \u0026gt;\u0026gt; authorized_keys rm id_rsa.pub sudo chmod 700 ~/.ssh sudo chmod 600 ~/.ssh/authorized_keys UbuntuでSSH接続での公開鍵認証を有効にする sudo cd /etc/ssh sudo cp -p sshd_config sshd_config.org sudo vi sshd_config /* viで以下をコメントアウトかつ変更 PubkeyAuthentication yes # 公開鍵認証の許可 AuthorizedKeysFile .ssh/authorized_keys #公開鍵ファイルのパス PasswordAuthentication no # パスワード認証禁止 */ sudo service sshd restart # sshdを再起動 Configファイルを作成する cd ~/.ssh vi config ~~~ viで以下をconfigに書き込む ~~~ Host ubuntu HostName 111.222.333.444 Port 22 User solareenlo IdentityFile ~/.ssh/id_rsa ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ MacからUbuntuへSSH接続する ssh ubuntu # もしくは ssh -i ~/.ssh/id_rsa solareenlo@111.222.333.444 References  RSA公開鍵認証によるssh接続設定について（Macbook -\u0026gt; VPS） インフラエンジニアじゃなくても押さえておきたいSSHの基礎知識  "},{"idx":150,"href":"/","title":"はじめに","content":" はじめに ここは何？  山田太郎のブログ, Tech系の備忘録, Tips, 知の体系化のアウトプット. 情報が古くなっていることがありますので, 最新/正確な情報は公式ドキュメントをご参照ください.  スタンス  集合知への貢献. 専門外はみんな初心者. 全ての人に成長するチャンスを. アウトプットは成長するチャンス.  その他のリンク   \u0026nbsp;   \u0026nbsp;   \u0026nbsp;   \u0026nbsp;   \u0026nbsp;   \u0026nbsp;   \u0026nbsp;   \u0026nbsp;   \u0026nbsp;   \n免責事項 当ウェブページの閲覧者が当ウェブページの情報を用いて行う一切の行為について, 理由の如何に関わらず, 如何なる責任を負いかねますので御了承ください.\n"},{"idx":151,"href":"/docs/bitcoin-fullnode/","title":"フルノード","content":" フルノードとは  Bitcoinネットワークにおけるすべてのブロックとトランザクションをダウンロードして検証するノードのこと.  Bitcoinフルノードへのアクセス方法 bitcoin-cliを使ってアクセス cURLを使ってアクセス POSTを使ってアクセス "}];window.bookSearch={pages:pages,idx:lunr(function(){this.ref("idx");this.field("title");this.field("content");pages.forEach(this.add,this);}),}})();